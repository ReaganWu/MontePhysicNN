{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Dataggenerator"]},{"cell_type":"markdown","metadata":{},"source":["## Training Datagenerator"]},{"cell_type":"code","execution_count":150,"metadata":{},"outputs":[],"source":["'''Training Generator V2'''\n","import numpy as np\n","import tensorflow as tf\n","\n","# def calculate_f(x):\n","#     x = tf.constant(x, dtype=tf.float32)\n","#     return -160 * tf.constant(np.pi**2, dtype=tf.float32) * tf.reduce_prod(tf.sin(4 * np.pi * x))\n","\n","def calculate_fx(x):\n","    f_x = -160 * tf.constant(np.pi, dtype=tf.float32)**2 * tf.reduce_prod(tf.math.sin(4 * tf.constant(np.pi, dtype=tf.float32) * x), axis=-1)\n","    return f_x\n","\n","def generate_training_data_v2(num_samples):\n","    input_parameters = []  # 存储输入参数的列表\n","    target_values = []  # 存储目标值的列表\n","    \n","    for _ in range(num_samples):\n","        a = np.random.uniform(-1, 1)\n","        b = np.random.uniform(-1, 1)\n","        c = np.random.uniform(-1, 1)\n","        d = np.random.uniform(-1, 1)\n","        e = np.random.uniform(-1, 1)\n","        f = np.random.uniform(-1, 1)\n","        g = np.random.uniform(-1, 1)\n","        h = np.random.uniform(-1, 1)\n","        i = np.random.uniform(-1, 1)\n","        j = np.random.uniform(-1, 1)\n","\n","        # 判断边界点\n","        is_boundary_point = (a == -1 or a == 1 or\n","                             b == -1 or b == 1 or\n","                             c == -1 or c == 1 or\n","                             d == -1 or d == 1 or\n","                             e == -1 or e == 1 or\n","                             f == -1 or f == 1 or\n","                             g == -1 or g == 1 or\n","                             h == -1 or h == 1 or\n","                             i == -1 or i == 1 or\n","                             j == -1 or j == 1)\n","\n","        # 边界条件\n","        if is_boundary_point:\n","            target_value = 0 \n","        else:\n","            target_value = calculate_fx(np.array([a, b, c, d, e, f, g, h, i, j])) \n","\n","\n","        input_parameters.append(np.array([a, b, c, d, e, f, g, h, i, j]))\n","        target_values.append(target_value)\n","\n","    return np.array(input_parameters), np.array(target_values)\n"]},{"cell_type":"code","execution_count":142,"metadata":{},"outputs":[],"source":["'''Training Generator V3'''\n","def calculate_fx(x):\n","    f_x = -160 * tf.constant(np.pi, dtype=tf.float32)**2 * tf.reduce_prod(tf.math.sin(4 * tf.constant(np.pi, dtype=tf.float32) * x), axis=-1)\n","    return f_x\n","\n","def is_boundary(x):\n","    return tf.reduce_any(tf.math.logical_or(x == -1, x == 1))\n","\n","def generate_training_data_v3(num_samples):\n","    input_parameters = []  # 存储输入参数的列表\n","    target_values = []  # 存储目标值的列表\n","    \n","    for _ in range(num_samples):\n","        random_values = np.random.uniform(-1, 1, 10)\n","        is_boundary_point = is_boundary(random_values)\n","\n","        if is_boundary_point:\n","            target_value = 0 \n","        else:\n","            target_value = calculate_fx(random_values) \n","\n","        input_parameters.append(random_values)\n","        target_values.append(target_value)\n","\n","    return np.array(input_parameters), np.array(target_values)\n"]},{"cell_type":"code","execution_count":143,"metadata":{},"outputs":[],"source":["# 从生成的数据中提取输入特征和目标值\n","# input_parameters, target_values = generate_training_data_v3(1000)\n","input_parameters, target_values = generate_training_data_v3(2000)\n","\n","\n","X = input_parameters  # 输入特征 (a, b, c, d, e, f, g, h, i, j)\n","Y = target_values  # 目标值 (-∇u(x) 或 f(x))\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(5000, 10)\n","(5000,)\n"]}],"source":["print(X.shape)\n","print(Y.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Testing Datagenertor"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_858052/2665354547.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;34m'''Test Datagenertor V2'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_858052/2665354547.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(num_samples)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# 边界条件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_boundary_point\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtarget_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mtarget_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0minput_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_858052/2665354547.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mf_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m160\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2799\u001b[0m   \"\"\"\n\u001b[1;32m   2800\u001b[0m   \u001b[0mkeepdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m   return _may_reduce_to_scalar(\n\u001b[1;32m   2802\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2803\u001b[0;31m       gen_math_ops.prod(\n\u001b[0m\u001b[1;32m   2804\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m           name=name))\n","\u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   7163\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7164\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7165\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7166\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7167\u001b[0;31m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7169\u001b[0m       return prod_eager_fallback(\n\u001b[1;32m   7170\u001b[0m           input, axis, keep_dims=keep_dims, name=name, ctx=_ctx)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# '''Test Datagenertor V2'''\n","# import numpy as np\n","# import tensorflow as tf\n","\n","# # def calculate_f(x):\n","# #     x = tf.constant(x, dtype=tf.float32)\n","# #     return -160 * tf.constant(np.pi**2, dtype=tf.float32) * tf.reduce_prod(tf.sin(4 * np.pi * x))\n","\n","# def calculate_fx(x):\n","#     f_x = -160 * tf.constant(np.pi, dtype=tf.float32)**2 * tf.reduce_prod(tf.math.sin(4 * tf.constant(np.pi, dtype=tf.float32) * x), axis=-1)\n","#     return f_x\n","\n","# def generate_test_data(num_samples):\n","#     input_parameters = []  # 存储输入参数的列表\n","#     target_values = []  # 存储目标值的列表\n","    \n","#     for _ in range(num_samples):\n","#         a = np.random.uniform(-1, 1)\n","#         b = np.random.uniform(-1, 1)\n","#         c = np.random.uniform(-1, 1)\n","#         d = np.random.uniform(-1, 1)\n","#         e = np.random.uniform(-1, 1)\n","#         f = np.random.uniform(-1, 1)\n","#         g = np.random.uniform(-1, 1)\n","#         h = np.random.uniform(-1, 1)\n","#         i = np.random.uniform(-1, 1)\n","#         j = np.random.uniform(-1, 1)\n","\n","#         # 判断边界点\n","#         is_boundary_point = (a == -1 or a == 1 or\n","#                              b == -1 or b == 1 or\n","#                              c == -1 or c == 1 or\n","#                              d == -1 or d == 1 or\n","#                              e == -1 or e == 1 or\n","#                              f == -1 or f == 1 or\n","#                              g == -1 or g == 1 or\n","#                              h == -1 or h == 1 or\n","#                              i == -1 or i == 1 or\n","#                              j == -1 or j == 1)\n","\n","#         # 边界条件\n","#         if is_boundary_point:\n","#             target_value = 0 \n","#         else:\n","#             target_value = calculate_fx(np.array([a, b, c, d, e, f, g, h, i, j])) \n","\n","\n","#         input_parameters.append(np.array([a, b, c, d, e, f, g, h, i, j]))\n","#         target_values.append(target_value)\n","\n","#     return np.array(input_parameters), np.array(target_values)\n","\n","\n","# num_test_samples = 4**10  \n","# test_input, test_target = generate_test_data(num_test_samples)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Quick loader"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["'''Pickle Store'''\n","import pickle \n","\n","# pickle_out = open(\"/home/reaganwu/Projects/Match/Reagan_Method/Datasets/Test_Dataset_10dim_Data.pickle\",\"wb\")\n","# pickle.dump(test_input, pickle_out)\n","# pickle_out.close()\n","\n","# pickle_out = open(\"/home/reaganwu/Projects/Match/Reagan_Method/Datasets/Test_Dataset_10dim_Lable.pickle\",\"wb\")\n","# pickle.dump(test_target, pickle_out)\n","# pickle_out.close()\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["'''Pickle load'''\n","import pickle\n","pickle_in = open(\"/home/reaganwu/Projects/Match/Reagan_Method/Datasets/Test_Dataset_10dim_Data.pickle\",\"rb\")\n","X_test = pickle.load(pickle_in)\n","pickle_in = open(\"/home/reaganwu/Projects/Match/Reagan_Method/Datasets/Test_Dataset_10dim_Lable.pickle\",\"rb\")\n","X_label = pickle.load(pickle_in)"]},{"cell_type":"markdown","metadata":{},"source":["# Training and Setting"]},{"cell_type":"markdown","metadata":{},"source":["## Define Deeplearning Model"]},{"cell_type":"markdown","metadata":{},"source":["### FCN for PINN"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_12 (Dense)            (None, 100)               1100      \n","                                                                 \n"," dense_13 (Dense)            (None, 100)               10100     \n","                                                                 \n"," dense_14 (Dense)            (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 11,301\n","Trainable params: 11,301\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["def swish(x):\n","    return x * tf.keras.backend.sigmoid(x)\n","\n","def isru(x, alpha=1.0):\n","    return x / tf.keras.backend.sqrt(1 + alpha * tf.keras.backend.square(x))\n","\n","def scaled_tanh(x, alpha=0.8, beta=1.0):\n","    return beta * tf.keras.backend.tanh(alpha * x)\n","\n","# Tanh Activation Function\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(100, activation='tanh', input_shape=(10,)),\n","    tf.keras.layers.Dense(100, activation='tanh'),\n","    tf.keras.layers.Dense(1) \n","])\n","\n","# model = tf.keras.Sequential([\n","#     tf.keras.layers.Dense(100, activation=scaled_tanh, input_shape=(10,)),\n","#     tf.keras.layers.Dense(100, activation=scaled_tanh),\n","#     tf.keras.layers.Dense(1)  \n","# ])\n","\n","\n","# model = tf.keras.Sequential([\n","#     tf.keras.layers.Dense(100, activation='sigmoid', input_shape=(10,)),\n","#     tf.keras.layers.Dense(100, activation='sigmoid'),\n","#     tf.keras.layers.Dense(1)  \n","# ])\n","\n","# model = tf.keras.Sequential([\n","#     tf.keras.layers.Dense(100, activation=isru, input_shape=(10,)),\n","#     tf.keras.layers.Dense(100, activation=isru),\n","#     tf.keras.layers.Dense(1)  \n","# ])\n","\n","\n","# model = tf.keras.Sequential([\n","#     tf.keras.layers.Dense(100, activation='relu', input_shape=(10,)),\n","#     tf.keras.layers.Dense(100, activation='relu'),\n","#     tf.keras.layers.Dense(1)\n","# ])\n","# model = tf.keras.Sequential([\n","#     tf.keras.layers.Dense(100, activation='gelu', input_shape=(10,)),\n","#     tf.keras.layers.Dense(100, activation='gelu'),\n","#     tf.keras.layers.Dense(1) \n","# ])\n","\n","# model = tf.keras.Sequential([\n","#     tf.keras.layers.Dense(100, activation=swish, input_shape=(10,)),\n","#     tf.keras.layers.Dense(100, activation=swish),\n","#     tf.keras.layers.Dense(1) \n","# ])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from sklearn.metrics import r2_score\n","from tensorflow.keras.callbacks import LambdaCallback\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import sys\n","\n","\n","def calculate_f(x):\n","    f_x = -160 * tf.constant(np.pi, dtype=tf.float32)**2 * tf.reduce_prod(tf.math.sin(4 * tf.constant(np.pi, dtype=tf.float32) * x), axis=-1)\n","    return f_x\n","\n","# def ca]\n","\n","\n","def calculate_fx(X):\n","    # 判断是否有1和-1的边界情况\n","    has_boundary = tf.reduce_any(tf.math.logical_or(X == -1, X == 1))\n","\n","    if has_boundary:\n","        # 如果有边界情况，将fx置零\n","        fx = tf.constant(0.0, dtype=tf.float32)\n","    else:\n","        # 否则计算正常的fx\n","        fx = -160 * tf.constant(np.pi, dtype=tf.float32)**2 * tf.reduce_prod(tf.math.sin(4 * tf.constant(np.pi, dtype=tf.float32) * X), axis=-1)\n","\n","    return fx\n","\n","\n","\n","def custom_loss(y_true, y_pred):\n","    # 偏微分方程损失\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch(X)\n","        u = model(X)\n","        u_x = tape.gradient(u, X)\n","        u_xx = tape.gradient(u_x, X)\n","        fx = calculate_fx(X)\n","        fx = tf.convert_to_tensor(fx, dtype=tf.float32)  # 将fx转换为张量\n","    u_xx_s = - tf.reduce_sum(u_xx, axis=1)  # 这将将u_xx的维度从 (5000, 10) 调整为 (5000,)\n","    # using y_true and u_xx_s to calculate pde_loss\n","    # pde_loss = tf.reduce_mean(tf.square(u_xx_s - y_true))\n","\n","    pde_loss = tf.reduce_mean(tf.square(u_xx_s - fx))\n","\n","    boundary_loss = tf.reduce_mean(tf.square(u))\n","\n","    mae = tf.keras.losses.MeanAbsoluteError()\n","    mae = mae(u_xx_s, fx)\n","\n","    total_loss = pde_loss + boundary_loss + 0.5*mae\n","    return total_loss\n","\n","class PrintValuesCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        # 在每个 epoch 结束时计算 u_xx 和 fx\n","        with tf.GradientTape(persistent=True) as tape:\n","            tape.watch(X)\n","            u = self.model(X)\n","            u_x = tape.gradient(u, X)\n","            u_xx = -tape.gradient(u_x, X)\n","        u_xx = tf.reduce_sum(u_xx, axis=1)  # 调整维度\n","\n","        # 计算 fx\n","        fx = calculate_fx(X)  # 你的 fx 计算函数\n","\n","        # 计算 R2\n","        r2 = r2_score(u_xx, fx)\n","\n","        # get mae from fx and u_xx\n","        mae = tf.keras.losses.MeanAbsoluteError()\n","        mae = mae(u_xx, fx)\n","\n","        # get mse from fx and u_xx\n","        mse = tf.keras.losses.MeanSquaredError()\n","        mse = mse(u_xx, fx)\n","\n","        # 计算 u_xx 和 u 的差值\n","        # var = np.abs(u_xx - u)\n","        # print(u_xx.shape)\n","        # print(u.shape)\n","        print(f\"_Epoch {epoch + 1} Results:\", f\"R2 Score: {r2:.8f}\", f\"MAE: {mae:.8f}\", f\"MSE: {mse:.8f}\")\n","        # print(f\"  R2 Score: {r2:.4f}\")\n","        # print(f\"  MAE: {mae:.4f}\")\n","        # print(f\"  u_xx: {u_xx}\")\n","        # print(f\"  fx: {fx}\")\n","\n","print_callback = PrintValuesCallback()\n","\n","\n","# Compile the model and use this custom loss\n","opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(optimizer=opt, loss=custom_loss, metrics=['mae'])\n","\n"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2000\n"]},{"name":"stdout","output_type":"stream","text":["1/2 [==============>...............] - ETA: 2s - loss: 9375.1084 - mae: 17.1949_Epoch 1 Results: R2 Score: -0.38242796 MAE: 67.38616180 MSE: 8081.44726562\n","\n","Epoch 1: loss improved from inf to 9047.14648, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 2s 51ms/step - loss: 9047.1465 - mae: 16.6618\n","Epoch 2/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8116.4141 - mae: 14.3969_Epoch 2 Results: R2 Score: -0.43519238 MAE: 62.42349625 MSE: 7027.42919922\n","\n","Epoch 2: loss improved from 9047.14648 to 7840.31885, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 7840.3188 - mae: 16.6541\n","Epoch 3/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7059.8770 - mae: 15.8641_Epoch 3 Results: R2 Score: -0.49495280 MAE: 58.04210281 MSE: 6152.84814453\n","\n","Epoch 3: loss improved from 7840.31885 to 6830.18896, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 6830.1890 - mae: 16.6469\n","Epoch 4/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6183.0713 - mae: 18.1818_Epoch 4 Results: R2 Score: -0.56147102 MAE: 54.24019623 MSE: 5433.49169922\n","\n","Epoch 4: loss improved from 6830.18896 to 5993.79785, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 5993.7979 - mae: 16.6406\n","Epoch 5/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5461.7847 - mae: 17.3182_Epoch 5 Results: R2 Score: -0.63411734 MAE: 50.85555649 MSE: 4845.22167969\n","\n","Epoch 5: loss improved from 5993.79785 to 5306.81396, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 5306.8140 - mae: 16.6339\n","Epoch 6/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4871.7969 - mae: 16.2126_Epoch 6 Results: R2 Score: -0.71181591 MAE: 47.85158539 MSE: 4365.45800781\n","\n","Epoch 6: loss improved from 5306.81396 to 4745.34033, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 32ms/step - loss: 4745.3403 - mae: 16.6283\n","Epoch 7/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4390.5098 - mae: 16.1455_Epoch 7 Results: R2 Score: -0.79298835 MAE: 45.22170639 MSE: 3974.11718750\n","\n","Epoch 7: loss improved from 4745.34033 to 4287.37451, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 4287.3745 - mae: 16.6229\n","Epoch 8/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3997.8352 - mae: 18.8441_Epoch 8 Results: R2 Score: -0.87561953 MAE: 42.97469711 MSE: 3654.09448242\n","\n","Epoch 8: loss improved from 4287.37451 to 3913.55151, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 106ms/step - loss: 3913.5515 - mae: 16.6179\n","Epoch 9/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3676.6731 - mae: 16.3278_Epoch 9 Results: R2 Score: -0.95743517 MAE: 41.00901413 MSE: 3391.20532227\n","\n","Epoch 9: loss improved from 3913.55151 to 3607.51587, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 76ms/step - loss: 3607.5159 - mae: 16.6136\n","Epoch 10/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3412.7876 - mae: 14.7699_Epoch 10 Results: R2 Score: -1.03619588 MAE: 39.26546097 MSE: 3173.80322266\n","\n","Epoch 10: loss improved from 3607.51587 to 3355.68506, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 3355.6851 - mae: 16.6095\n","Epoch 11/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3194.5027 - mae: 16.7000_Epoch 11 Results: R2 Score: -1.10996320 MAE: 37.74763107 MSE: 2992.44702148\n","\n","Epoch 11: loss improved from 3355.68506 to 3146.96704, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 86ms/step - loss: 3146.9670 - mae: 16.6053\n","Epoch 12/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3012.3782 - mae: 16.5237_Epoch 12 Results: R2 Score: -1.17725618 MAE: 36.44615936 MSE: 2839.61523438\n","\n","Epoch 12: loss improved from 3146.96704 to 2972.41846, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 2972.4185 - mae: 16.6020\n","Epoch 13/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2858.8882 - mae: 16.6189_Epoch 13 Results: R2 Score: -1.23708636 MAE: 35.30730820 MSE: 2709.41943359\n","\n","Epoch 13: loss improved from 2972.41846 to 2824.93188, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 71ms/step - loss: 2824.9319 - mae: 16.5991\n","Epoch 14/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2728.1169 - mae: 14.9774_Epoch 14 Results: R2 Score: -1.28887996 MAE: 34.32315063 MSE: 2597.29858398\n","\n","Epoch 14: loss improved from 2824.93188 to 2698.94946, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 2698.9495 - mae: 16.5968\n","Epoch 15/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2615.4998 - mae: 16.6701_Epoch 15 Results: R2 Score: -1.33236862 MAE: 33.44814301 MSE: 2499.71044922\n","\n","Epoch 15: loss improved from 2698.94946 to 2590.17529, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 2590.1753 - mae: 16.5950\n","Epoch 16/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2517.4707 - mae: 17.5456_Epoch 16 Results: R2 Score: -1.36748880 MAE: 32.66118622 MSE: 2413.88330078\n","\n","Epoch 16: loss improved from 2590.17529 to 2495.25195, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 86ms/step - loss: 2495.2520 - mae: 16.5929\n","Epoch 17/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2431.2480 - mae: 16.2451_Epoch 17 Results: R2 Score: -1.39431868 MAE: 31.96350861 MSE: 2337.61889648\n","\n","Epoch 17: loss improved from 2495.25195 to 2411.55347, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 2411.5535 - mae: 16.5915\n","Epoch 18/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2354.6335 - mae: 16.8106_Epoch 18 Results: R2 Score: -1.41304785 MAE: 31.33933258 MSE: 2269.16870117\n","\n","Epoch 18: loss improved from 2411.55347 to 2336.99951, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 2336.9995 - mae: 16.5895\n","Epoch 19/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2285.8711 - mae: 16.4284_Epoch 19 Results: R2 Score: -1.42396881 MAE: 30.77540970 MSE: 2207.13793945\n","\n","Epoch 19: loss improved from 2336.99951 to 2269.92725, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 89ms/step - loss: 2269.9272 - mae: 16.5881\n","Epoch 20/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2223.5586 - mae: 16.9459_Epoch 20 Results: R2 Score: -1.42747087 MAE: 30.27606010 MSE: 2150.43041992\n","\n","Epoch 20: loss improved from 2269.92725 to 2209.01440, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 2209.0144 - mae: 16.5869\n","Epoch 21/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2166.6023 - mae: 19.0435_Epoch 21 Results: R2 Score: -1.42403796 MAE: 29.82228279 MSE: 2098.19458008\n","\n","Epoch 21: loss improved from 2209.01440 to 2153.22876, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 2153.2288 - mae: 16.5859\n","Epoch 22/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2114.1411 - mae: 16.7674_Epoch 22 Results: R2 Score: -1.41424197 MAE: 29.40341187 MSE: 2049.78002930\n","\n","Epoch 22: loss improved from 2153.22876 to 2101.76245, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 2101.7625 - mae: 16.5847\n","Epoch 23/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2065.5190 - mae: 16.2428_Epoch 23 Results: R2 Score: -1.39873511 MAE: 29.01581573 MSE: 2004.69604492\n","\n","Epoch 23: loss improved from 2101.76245 to 2054.00391, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 2054.0039 - mae: 16.5837\n","Epoch 24/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2020.2437 - mae: 17.5581_Epoch 24 Results: R2 Score: -1.37824821 MAE: 28.65717506 MSE: 1962.56945801\n","\n","Epoch 24: loss improved from 2054.00391 to 2009.49170, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 2009.4917 - mae: 16.5827\n","Epoch 25/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1977.9404 - mae: 17.3810_Epoch 25 Results: R2 Score: -1.35356746 MAE: 28.32028770 MSE: 1923.10900879\n","\n","Epoch 25: loss improved from 2009.49170 to 1967.87476, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 1967.8748 - mae: 16.5819\n","Epoch 26/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1938.3145 - mae: 15.1407_Epoch 26 Results: R2 Score: -1.32549102 MAE: 28.00929642 MSE: 1886.07666016\n","\n","Epoch 26: loss improved from 1967.87476 to 1928.87170, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 1928.8717 - mae: 16.5809\n","Epoch 27/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1901.1296 - mae: 17.2853_Epoch 27 Results: R2 Score: -1.29480181 MAE: 27.73142624 MSE: 1851.26745605\n","\n","Epoch 27: loss improved from 1928.87170 to 1892.25928, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 94ms/step - loss: 1892.2593 - mae: 16.5802\n","Epoch 28/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1866.1847 - mae: 15.2212_Epoch 28 Results: R2 Score: -1.26223043 MAE: 27.47466087 MSE: 1818.49719238\n","\n","Epoch 28: loss improved from 1892.25928 to 1857.83850, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 95ms/step - loss: 1857.8385 - mae: 16.5792\n","Epoch 29/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1833.2894 - mae: 14.1990_Epoch 29 Results: R2 Score: -1.22842241 MAE: 27.23857307 MSE: 1787.59521484\n","\n","Epoch 29: loss improved from 1857.83850 to 1825.42285, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 71ms/step - loss: 1825.4229 - mae: 16.5783\n","Epoch 30/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1802.2728 - mae: 17.8623_Epoch 30 Results: R2 Score: -1.19391294 MAE: 27.02458572 MSE: 1758.40075684\n","\n","Epoch 30: loss improved from 1825.42285 to 1794.84583, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 1794.8458 - mae: 16.5778\n","Epoch 31/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1772.9750 - mae: 16.7015_Epoch 31 Results: R2 Score: -1.15911957 MAE: 26.81704140 MSE: 1730.76147461\n","\n","Epoch 31: loss improved from 1794.84583 to 1765.94751, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 1765.9475 - mae: 16.5770\n","Epoch 32/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1745.2356 - mae: 17.3878_Epoch 32 Results: R2 Score: -1.12434291 MAE: 26.61728096 MSE: 1704.53222656\n","\n","Epoch 32: loss improved from 1765.94751 to 1738.57019, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 1738.5702 - mae: 16.5766\n","Epoch 33/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1718.9100 - mae: 16.4958_Epoch 33 Results: R2 Score: -1.08978364 MAE: 26.43155670 MSE: 1679.57299805\n","\n","Epoch 33: loss improved from 1738.57019 to 1712.57239, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 43ms/step - loss: 1712.5724 - mae: 16.5759\n","Epoch 34/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1693.8621 - mae: 16.2735_Epoch 34 Results: R2 Score: -1.05556536 MAE: 26.25742531 MSE: 1655.75085449\n","\n","Epoch 34: loss improved from 1712.57239 to 1687.81848, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 1687.8185 - mae: 16.5755\n","Epoch 35/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1669.9565 - mae: 15.9783_Epoch 35 Results: R2 Score: -1.02176455 MAE: 26.08670425 MSE: 1632.93811035\n","\n","Epoch 35: loss improved from 1687.81848 to 1664.17346, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 1664.1735 - mae: 16.5752\n","Epoch 36/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1647.0626 - mae: 15.7780_Epoch 36 Results: R2 Score: -0.98842439 MAE: 25.92112732 MSE: 1611.01525879\n","\n","Epoch 36: loss improved from 1664.17346 to 1641.51025, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 1641.5103 - mae: 16.5747\n","Epoch 37/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1625.0612 - mae: 15.1643_Epoch 37 Results: R2 Score: -0.95556587 MAE: 25.75989342 MSE: 1589.87268066\n","\n","Epoch 37: loss improved from 1641.51025 to 1619.71069, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 1619.7107 - mae: 16.5746\n","Epoch 38/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1603.8424 - mae: 17.6167_Epoch 38 Results: R2 Score: -0.92320847 MAE: 25.60482979 MSE: 1569.41320801\n","\n","Epoch 38: loss improved from 1619.71069 to 1598.66907, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 88ms/step - loss: 1598.6691 - mae: 16.5742\n","Epoch 39/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1583.3098 - mae: 15.7839_Epoch 39 Results: R2 Score: -0.89137286 MAE: 25.45761490 MSE: 1549.55310059\n","\n","Epoch 39: loss improved from 1598.66907 to 1578.29224, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 1578.2922 - mae: 16.5741\n","Epoch 40/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1563.3807 - mae: 16.5155_Epoch 40 Results: R2 Score: -0.86007625 MAE: 25.31853676 MSE: 1530.22180176\n","\n","Epoch 40: loss improved from 1578.29224 to 1558.50073, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 43ms/step - loss: 1558.5007 - mae: 16.5738\n","Epoch 41/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1543.9849 - mae: 18.0293_Epoch 41 Results: R2 Score: -0.82932786 MAE: 25.17994308 MSE: 1511.35949707\n","\n","Epoch 41: loss improved from 1558.50073 to 1539.22546, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 1539.2255 - mae: 16.5738\n","Epoch 42/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1525.0581 - mae: 17.7570_Epoch 42 Results: R2 Score: -0.79913395 MAE: 25.04569817 MSE: 1492.91662598\n","\n","Epoch 42: loss improved from 1539.22546 to 1520.40686, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 1520.4069 - mae: 16.5739\n","Epoch 43/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1506.5531 - mae: 17.2734_Epoch 43 Results: R2 Score: -0.76948852 MAE: 24.91730881 MSE: 1474.85229492\n","\n","Epoch 43: loss improved from 1520.40686 to 1501.99951, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 1501.9995 - mae: 16.5737\n","Epoch 44/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1488.4298 - mae: 15.5836_Epoch 44 Results: R2 Score: -0.74036136 MAE: 24.78899765 MSE: 1457.13183594\n","\n","Epoch 44: loss improved from 1501.99951 to 1483.96436, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 94ms/step - loss: 1483.9644 - mae: 16.5735\n","Epoch 45/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1470.6504 - mae: 16.4714_Epoch 45 Results: R2 Score: -0.71170767 MAE: 24.65758514 MSE: 1439.72619629\n","\n","Epoch 45: loss improved from 1483.96436 to 1466.26501, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 1466.2650 - mae: 16.5738\n","Epoch 46/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1453.1841 - mae: 16.3370_Epoch 46 Results: R2 Score: -0.68346962 MAE: 24.52720070 MSE: 1422.61230469\n","\n","Epoch 46: loss improved from 1466.26501 to 1448.87305, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 1448.8730 - mae: 16.5737\n","Epoch 47/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1436.0103 - mae: 16.3233_Epoch 47 Results: R2 Score: -0.65558701 MAE: 24.39975357 MSE: 1405.77172852\n","\n","Epoch 47: loss improved from 1448.87305 to 1431.76904, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 1431.7690 - mae: 16.5736\n","Epoch 48/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1419.1112 - mae: 15.3266_Epoch 48 Results: R2 Score: -0.62800027 MAE: 24.27394676 MSE: 1389.19177246\n","\n","Epoch 48: loss improved from 1431.76904 to 1414.93579, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 50ms/step - loss: 1414.9358 - mae: 16.5739\n","Epoch 49/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1402.4736 - mae: 16.0994_Epoch 49 Results: R2 Score: -0.60066282 MAE: 24.15460587 MSE: 1372.86401367\n","\n","Epoch 49: loss improved from 1414.93579 to 1398.36255, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 1398.3625 - mae: 16.5740\n","Epoch 50/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1386.0913 - mae: 16.6347_Epoch 50 Results: R2 Score: -0.57353852 MAE: 24.03485870 MSE: 1356.78479004\n","\n","Epoch 50: loss improved from 1398.36255 to 1382.04224, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 1382.0422 - mae: 16.5742\n","Epoch 51/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1369.9574 - mae: 18.5697_Epoch 51 Results: R2 Score: -0.54661274 MAE: 23.92264366 MSE: 1340.95397949\n","\n","Epoch 51: loss improved from 1382.04224 to 1365.97070, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 1365.9707 - mae: 16.5744\n","Epoch 52/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1354.0754 - mae: 16.1858_Epoch 52 Results: R2 Score: -0.51989217 MAE: 23.81486130 MSE: 1325.37573242\n","\n","Epoch 52: loss improved from 1365.97070 to 1350.15259, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 1350.1526 - mae: 16.5747\n","Epoch 53/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1338.4484 - mae: 16.5624_Epoch 53 Results: R2 Score: -0.49340213 MAE: 23.71164322 MSE: 1310.05456543\n","\n","Epoch 53: loss improved from 1350.15259 to 1334.58997, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 1334.5900 - mae: 16.5748\n","Epoch 54/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1323.0804 - mae: 14.7224_Epoch 54 Results: R2 Score: -0.46718159 MAE: 23.60976982 MSE: 1294.99426270\n","\n","Epoch 54: loss improved from 1334.58997 to 1319.28760, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 1319.2876 - mae: 16.5750\n","Epoch 55/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1307.9742 - mae: 16.6504_Epoch 55 Results: R2 Score: -0.44127807 MAE: 23.50665855 MSE: 1280.19519043\n","\n","Epoch 55: loss improved from 1319.28760 to 1304.24622, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 1304.2462 - mae: 16.5752\n","Epoch 56/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1293.1285 - mae: 17.3346_Epoch 56 Results: R2 Score: -0.41574221 MAE: 23.40761948 MSE: 1265.65478516\n","\n","Epoch 56: loss improved from 1304.24622 to 1289.46631, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 1289.4663 - mae: 16.5753\n","Epoch 57/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1278.5437 - mae: 17.3615_Epoch 57 Results: R2 Score: -0.39062089 MAE: 23.30831909 MSE: 1251.36645508\n","\n","Epoch 57: loss improved from 1289.46631 to 1274.94495, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 1274.9449 - mae: 16.5754\n","Epoch 58/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1264.2107 - mae: 17.4856_Epoch 58 Results: R2 Score: -0.36596149 MAE: 23.21279335 MSE: 1237.32067871\n","\n","Epoch 58: loss improved from 1274.94495 to 1260.67371, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 157ms/step - loss: 1260.6737 - mae: 16.5757\n","Epoch 59/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1250.1223 - mae: 15.7712_Epoch 59 Results: R2 Score: -0.34179499 MAE: 23.11795044 MSE: 1223.50695801\n","\n","Epoch 59: loss improved from 1260.67371 to 1246.64429, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 1246.6443 - mae: 16.5759\n","Epoch 60/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1236.2662 - mae: 16.7683_Epoch 60 Results: R2 Score: -0.31814123 MAE: 23.01989555 MSE: 1209.91503906\n","\n","Epoch 60: loss improved from 1246.64429 to 1232.84375, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 1232.8438 - mae: 16.5761\n","Epoch 61/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1222.6305 - mae: 16.6758_Epoch 61 Results: R2 Score: -0.29500346 MAE: 22.92172623 MSE: 1196.53588867\n","\n","Epoch 61: loss improved from 1232.84375 to 1219.26147, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 1219.2615 - mae: 16.5764\n","Epoch 62/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1209.2075 - mae: 16.0302_Epoch 62 Results: R2 Score: -0.27237372 MAE: 22.82359505 MSE: 1183.36352539\n","\n","Epoch 62: loss improved from 1219.26147 to 1205.89075, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 1205.8907 - mae: 16.5767\n","Epoch 63/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1195.9915 - mae: 16.2019_Epoch 63 Results: R2 Score: -0.25023287 MAE: 22.72442818 MSE: 1170.39343262\n","\n","Epoch 63: loss improved from 1205.89075 to 1192.72546, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 1192.7255 - mae: 16.5771\n","Epoch 64/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1182.9772 - mae: 16.0485_Epoch 64 Results: R2 Score: -0.22855836 MAE: 22.62428856 MSE: 1157.62194824\n","\n","Epoch 64: loss improved from 1192.72546 to 1179.76074, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 44ms/step - loss: 1179.7607 - mae: 16.5773\n","Epoch 65/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1170.1611 - mae: 15.8796_Epoch 65 Results: R2 Score: -0.20732154 MAE: 22.52331924 MSE: 1145.04675293\n","\n","Epoch 65: loss improved from 1179.76074 to 1166.99377, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 71ms/step - loss: 1166.9938 - mae: 16.5779\n","Epoch 66/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1157.5411 - mae: 17.0272_Epoch 66 Results: R2 Score: -0.18649610 MAE: 22.42564774 MSE: 1132.66479492\n","\n","Epoch 66: loss improved from 1166.99377 to 1154.42273, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 1154.4227 - mae: 16.5781\n","Epoch 67/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1145.1157 - mae: 15.9221_Epoch 67 Results: R2 Score: -0.16605937 MAE: 22.33111000 MSE: 1120.47277832\n","\n","Epoch 67: loss improved from 1154.42273 to 1142.04565, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 1142.0457 - mae: 16.5785\n","Epoch 68/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1132.8821 - mae: 15.1576_Epoch 68 Results: R2 Score: -0.14598632 MAE: 22.23839951 MSE: 1108.46508789\n","\n","Epoch 68: loss improved from 1142.04565 to 1129.85864, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 94ms/step - loss: 1129.8586 - mae: 16.5788\n","Epoch 69/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1120.8337 - mae: 15.9464_Epoch 69 Results: R2 Score: -0.12625232 MAE: 22.14629936 MSE: 1096.63549805\n","\n","Epoch 69: loss improved from 1129.85864 to 1117.85547, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 94ms/step - loss: 1117.8555 - mae: 16.5793\n","Epoch 70/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1108.9639 - mae: 16.3668_Epoch 70 Results: R2 Score: -0.10683254 MAE: 22.05749702 MSE: 1084.97644043\n","\n","Epoch 70: loss improved from 1117.85547 to 1106.02881, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 1106.0288 - mae: 16.5796\n","Epoch 71/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1097.2661 - mae: 15.7074_Epoch 71 Results: R2 Score: -0.08770459 MAE: 21.97072983 MSE: 1073.48046875\n","\n","Epoch 71: loss improved from 1106.02881 to 1094.37280, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 104ms/step - loss: 1094.3728 - mae: 16.5801\n","Epoch 72/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1085.7324 - mae: 16.9810_Epoch 72 Results: R2 Score: -0.06885667 MAE: 21.88514137 MSE: 1062.14111328\n","\n","Epoch 72: loss improved from 1094.37280 to 1082.87878, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 1082.8788 - mae: 16.5803\n","Epoch 73/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1074.3561 - mae: 16.1406_Epoch 73 Results: R2 Score: -0.05027855 MAE: 21.79887581 MSE: 1050.95263672\n","\n","Epoch 73: loss improved from 1082.87878 to 1071.54028, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 73ms/step - loss: 1071.5403 - mae: 16.5806\n","Epoch 74/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1063.1301 - mae: 16.0146_Epoch 74 Results: R2 Score: -0.03196464 MAE: 21.71296501 MSE: 1039.91088867\n","\n","Epoch 74: loss improved from 1071.54028 to 1060.35120, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 133ms/step - loss: 1060.3512 - mae: 16.5809\n","Epoch 75/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1052.0511 - mae: 16.3262_Epoch 75 Results: R2 Score: -0.01391534 MAE: 21.62700081 MSE: 1029.01293945\n","\n","Epoch 75: loss improved from 1060.35120 to 1049.30835, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 99ms/step - loss: 1049.3083 - mae: 16.5811\n","Epoch 76/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1041.1160 - mae: 14.2025_Epoch 76 Results: R2 Score: 0.00385976 MAE: 21.54200363 MSE: 1018.25726318\n","\n","Epoch 76: loss improved from 1049.30835 to 1038.40894, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 106ms/step - loss: 1038.4089 - mae: 16.5814\n","Epoch 77/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1030.3235 - mae: 15.9484_Epoch 77 Results: R2 Score: 0.02134321 MAE: 21.45726967 MSE: 1007.64227295\n","\n","Epoch 77: loss improved from 1038.40894 to 1027.65186, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 1027.6519 - mae: 16.5817\n","Epoch 78/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1019.6718 - mae: 17.2348_Epoch 78 Results: R2 Score: 0.03851790 MAE: 21.37356758 MSE: 997.16595459\n","\n","Epoch 78: loss improved from 1027.65186 to 1017.03485, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 1017.0349 - mae: 16.5819\n","Epoch 79/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 1009.1594 - mae: 16.7326_Epoch 79 Results: R2 Score: 0.05536578 MAE: 21.29076767 MSE: 986.82611084\n","\n","Epoch 79: loss improved from 1017.03485 to 1006.55701, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 50ms/step - loss: 1006.5570 - mae: 16.5821\n","Epoch 80/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 998.7838 - mae: 17.2524_Epoch 80 Results: R2 Score: 0.07187078 MAE: 21.20626068 MSE: 976.61926270\n","\n","Epoch 80: loss improved from 1006.55701 to 996.21490, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 996.2149 - mae: 16.5822\n","Epoch 81/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 988.5404 - mae: 17.0089_Epoch 81 Results: R2 Score: 0.08802382 MAE: 21.12017059 MSE: 966.54064941\n","\n","Epoch 81: loss improved from 996.21490 to 986.00354, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 986.0035 - mae: 16.5825\n","Epoch 82/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 978.4244 - mae: 16.6219_Epoch 82 Results: R2 Score: 0.10381623 MAE: 21.03362846 MSE: 956.58514404\n","\n","Epoch 82: loss improved from 986.00354 to 975.91876, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 975.9188 - mae: 16.5828\n","Epoch 83/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 968.4314 - mae: 17.7049_Epoch 83 Results: R2 Score: 0.11924568 MAE: 20.94585228 MSE: 946.74621582\n","\n","Epoch 83: loss improved from 975.91876 to 965.95502, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 965.9550 - mae: 16.5830\n","Epoch 84/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 958.5543 - mae: 17.5724_Epoch 84 Results: R2 Score: 0.13431825 MAE: 20.85792160 MSE: 937.01763916\n","\n","Epoch 84: loss improved from 965.95502 to 956.10596, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 956.1060 - mae: 16.5831\n","Epoch 85/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 948.7875 - mae: 17.4083_Epoch 85 Results: R2 Score: 0.14904442 MAE: 20.77151299 MSE: 927.39300537\n","\n","Epoch 85: loss improved from 956.10596 to 946.36560, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 946.3656 - mae: 16.5835\n","Epoch 86/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 939.1255 - mae: 16.3444_Epoch 86 Results: R2 Score: 0.16343931 MAE: 20.68723679 MSE: 917.86682129\n","\n","Epoch 86: loss improved from 946.36560 to 936.72882, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 936.7288 - mae: 16.5837\n","Epoch 87/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 929.5630 - mae: 15.7855_Epoch 87 Results: R2 Score: 0.17752334 MAE: 20.60124016 MSE: 908.43377686\n","\n","Epoch 87: loss improved from 936.72882 to 927.18976, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 71ms/step - loss: 927.1898 - mae: 16.5840\n","Epoch 88/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 920.0927 - mae: 16.5802_Epoch 88 Results: R2 Score: 0.19131625 MAE: 20.51338577 MSE: 899.08892822\n","\n","Epoch 88: loss improved from 927.18976 to 917.74152, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 917.7415 - mae: 16.5842\n","Epoch 89/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 910.7096 - mae: 17.4786_Epoch 89 Results: R2 Score: 0.20483419 MAE: 20.42537117 MSE: 889.82885742\n","\n","Epoch 89: loss improved from 917.74152 to 908.37988, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 908.3799 - mae: 16.5845\n","Epoch 90/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 901.4113 - mae: 16.9551_Epoch 90 Results: R2 Score: 0.21809532 MAE: 20.33850670 MSE: 880.65081787\n","\n","Epoch 90: loss improved from 908.37988 to 899.10223, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 44ms/step - loss: 899.1022 - mae: 16.5847\n","Epoch 91/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 892.1954 - mae: 17.9571_Epoch 91 Results: R2 Score: 0.23111693 MAE: 20.25199509 MSE: 871.55236816\n","\n","Epoch 91: loss improved from 899.10223 to 889.90637, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 889.9064 - mae: 16.5850\n","Epoch 92/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 883.0593 - mae: 17.8897_Epoch 92 Results: R2 Score: 0.24391526 MAE: 20.16797829 MSE: 862.53198242\n","\n","Epoch 92: loss improved from 889.90637 to 880.79041, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 880.7904 - mae: 16.5852\n","Epoch 93/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 874.0025 - mae: 17.1116_Epoch 93 Results: R2 Score: 0.25650600 MAE: 20.08334160 MSE: 853.58807373\n","\n","Epoch 93: loss improved from 880.79041 to 871.75262, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 871.7526 - mae: 16.5854\n","Epoch 94/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 865.0218 - mae: 16.4158_Epoch 94 Results: R2 Score: 0.26890151 MAE: 19.99990273 MSE: 844.71960449\n","\n","Epoch 94: loss improved from 871.75262 to 862.79102, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 40ms/step - loss: 862.7910 - mae: 16.5856\n","Epoch 95/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 856.1170 - mae: 16.3247_Epoch 95 Results: R2 Score: 0.28110759 MAE: 19.91546631 MSE: 835.92498779\n","\n","Epoch 95: loss improved from 862.79102 to 853.90454, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 88ms/step - loss: 853.9045 - mae: 16.5858\n","Epoch 96/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 847.2855 - mae: 16.9542_Epoch 96 Results: R2 Score: 0.29312773 MAE: 19.83197784 MSE: 827.20324707\n","\n","Epoch 96: loss improved from 853.90454 to 845.09131, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 845.0913 - mae: 16.5860\n","Epoch 97/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 838.5273 - mae: 16.6310_Epoch 97 Results: R2 Score: 0.30496367 MAE: 19.74995804 MSE: 818.55297852\n","\n","Epoch 97: loss improved from 845.09131 to 836.35126, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 836.3513 - mae: 16.5862\n","Epoch 98/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 829.8412 - mae: 16.6866_Epoch 98 Results: R2 Score: 0.31661102 MAE: 19.66941833 MSE: 809.97375488\n","\n","Epoch 98: loss improved from 836.35126 to 827.68323, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 72ms/step - loss: 827.6832 - mae: 16.5863\n","Epoch 99/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 821.2267 - mae: 16.0213_Epoch 99 Results: R2 Score: 0.32806691 MAE: 19.58856392 MSE: 801.46429443\n","\n","Epoch 99: loss improved from 827.68323 to 819.08624, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 43ms/step - loss: 819.0862 - mae: 16.5864\n","Epoch 100/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 812.6819 - mae: 15.5070_Epoch 100 Results: R2 Score: 0.33933644 MAE: 19.50720787 MSE: 793.02349854\n","\n","Epoch 100: loss improved from 819.08624 to 810.55847, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 44ms/step - loss: 810.5585 - mae: 16.5865\n","Epoch 101/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 804.2054 - mae: 17.4031_Epoch 101 Results: R2 Score: 0.35042156 MAE: 19.42618561 MSE: 784.65124512\n","\n","Epoch 101: loss improved from 810.55847 to 802.09906, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 802.0991 - mae: 16.5867\n","Epoch 102/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 795.7975 - mae: 17.9464_Epoch 102 Results: R2 Score: 0.36132268 MAE: 19.34657288 MSE: 776.34722900\n","\n","Epoch 102: loss improved from 802.09906 to 793.70837, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 81ms/step - loss: 793.7084 - mae: 16.5869\n","Epoch 103/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 787.4585 - mae: 16.4981_Epoch 103 Results: R2 Score: 0.37203443 MAE: 19.26882935 MSE: 768.11175537\n","\n","Epoch 103: loss improved from 793.70837 to 785.38678, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 785.3868 - mae: 16.5870\n","Epoch 104/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 779.1889 - mae: 17.1940_Epoch 104 Results: R2 Score: 0.38255438 MAE: 19.19207382 MSE: 759.94561768\n","\n","Epoch 104: loss improved from 785.38678 to 777.13464, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 777.1346 - mae: 16.5871\n","Epoch 105/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 770.9891 - mae: 17.2134_Epoch 105 Results: R2 Score: 0.39288204 MAE: 19.11598396 MSE: 751.84893799\n","\n","Epoch 105: loss improved from 777.13464 to 768.95227, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 768.9523 - mae: 16.5872\n","Epoch 106/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 762.8591 - mae: 16.7474_Epoch 106 Results: R2 Score: 0.40301817 MAE: 19.04118919 MSE: 743.82238770\n","\n","Epoch 106: loss improved from 768.95227 to 760.83978, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 760.8398 - mae: 16.5872\n","Epoch 107/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 754.7997 - mae: 15.6546_Epoch 107 Results: R2 Score: 0.41296170 MAE: 18.96698952 MSE: 735.86614990\n","\n","Epoch 107: loss improved from 760.83978 to 752.79822, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 752.7982 - mae: 16.5872\n","Epoch 108/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 746.8110 - mae: 14.8439_Epoch 108 Results: R2 Score: 0.42271260 MAE: 18.89248466 MSE: 727.98010254\n","\n","Epoch 108: loss improved from 752.79822 to 744.82697, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 744.8270 - mae: 16.5874\n","Epoch 109/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 738.8923 - mae: 18.4733_Epoch 109 Results: R2 Score: 0.43227377 MAE: 18.81707191 MSE: 720.16381836\n","\n","Epoch 109: loss improved from 744.82697 to 736.92572, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 43ms/step - loss: 736.9257 - mae: 16.5875\n","Epoch 110/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 731.0430 - mae: 15.8696_Epoch 110 Results: R2 Score: 0.44164671 MAE: 18.74124527 MSE: 712.41680908\n","\n","Epoch 110: loss improved from 736.92572 to 729.09375, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 25ms/step - loss: 729.0938 - mae: 16.5875\n","Epoch 111/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 723.2628 - mae: 17.2860_Epoch 111 Results: R2 Score: 0.45083542 MAE: 18.66405487 MSE: 704.73809814\n","\n","Epoch 111: loss improved from 729.09375 to 721.33044, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 114ms/step - loss: 721.3304 - mae: 16.5876\n","Epoch 112/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 715.5502 - mae: 18.5293_Epoch 112 Results: R2 Score: 0.45984517 MAE: 18.58495903 MSE: 697.12731934\n","\n","Epoch 112: loss improved from 721.33044 to 713.63477, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 105ms/step - loss: 713.6348 - mae: 16.5877\n","Epoch 113/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 707.9048 - mae: 16.1174_Epoch 113 Results: R2 Score: 0.46868309 MAE: 18.50506783 MSE: 689.58361816\n","\n","Epoch 113: loss improved from 713.63477 to 706.00586, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 99ms/step - loss: 706.0059 - mae: 16.5879\n","Epoch 114/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 700.3260 - mae: 16.2523_Epoch 114 Results: R2 Score: 0.47735561 MAE: 18.42522049 MSE: 682.10662842\n","\n","Epoch 114: loss improved from 706.00586 to 698.44385, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 698.4438 - mae: 16.5881\n","Epoch 115/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 692.8141 - mae: 15.5790_Epoch 115 Results: R2 Score: 0.48586692 MAE: 18.34494591 MSE: 674.69635010\n","\n","Epoch 115: loss improved from 698.44385 to 690.94861, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 690.9486 - mae: 16.5883\n","Epoch 116/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 685.3688 - mae: 16.6889_Epoch 116 Results: R2 Score: 0.49422164 MAE: 18.26352119 MSE: 667.35198975\n","\n","Epoch 116: loss improved from 690.94861 to 683.51965, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 683.5197 - mae: 16.5886\n","Epoch 117/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 677.9889 - mae: 16.8801_Epoch 117 Results: R2 Score: 0.50242050 MAE: 18.18172646 MSE: 660.07348633\n","\n","Epoch 117: loss improved from 683.51965 to 676.15637, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 676.1564 - mae: 16.5889\n","Epoch 118/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 670.6747 - mae: 16.6725_Epoch 118 Results: R2 Score: 0.51046625 MAE: 18.09922981 MSE: 652.86004639\n","\n","Epoch 118: loss improved from 676.15637 to 668.85840, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 668.8584 - mae: 16.5892\n","Epoch 119/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 663.4254 - mae: 16.1184_Epoch 119 Results: R2 Score: 0.51836323 MAE: 18.01732635 MSE: 645.71057129\n","\n","Epoch 119: loss improved from 668.85840 to 661.62518, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 661.6252 - mae: 16.5896\n","Epoch 120/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 656.2404 - mae: 16.2959_Epoch 120 Results: R2 Score: 0.52611597 MAE: 17.93584061 MSE: 638.62420654\n","\n","Epoch 120: loss improved from 661.62518 to 654.45599, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 654.4560 - mae: 16.5899\n","Epoch 121/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 649.1187 - mae: 16.9538_Epoch 121 Results: R2 Score: 0.53373292 MAE: 17.85397720 MSE: 631.59936523\n","\n","Epoch 121: loss improved from 654.45599 to 647.34985, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 647.3499 - mae: 16.5903\n","Epoch 122/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 642.0585 - mae: 17.6071_Epoch 122 Results: R2 Score: 0.54121729 MAE: 17.77110481 MSE: 624.63488770\n","\n","Epoch 122: loss improved from 647.34985 to 640.30475, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 640.3047 - mae: 16.5907\n","Epoch 123/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 635.0583 - mae: 16.1823_Epoch 123 Results: R2 Score: 0.54857232 MAE: 17.68831444 MSE: 617.72912598\n","\n","Epoch 123: loss improved from 640.30475 to 633.31934, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 95ms/step - loss: 633.3193 - mae: 16.5911\n","Epoch 124/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 628.1169 - mae: 16.7321_Epoch 124 Results: R2 Score: 0.55580111 MAE: 17.60486794 MSE: 610.88073730\n","\n","Epoch 124: loss improved from 633.31934 to 626.39227, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 626.3923 - mae: 16.5914\n","Epoch 125/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 621.2326 - mae: 18.1467_Epoch 125 Results: R2 Score: 0.56290976 MAE: 17.52140999 MSE: 604.08795166\n","\n","Epoch 125: loss improved from 626.39227 to 619.52197, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 619.5220 - mae: 16.5920\n","Epoch 126/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 614.4039 - mae: 15.0805_Epoch 126 Results: R2 Score: 0.56990048 MAE: 17.43785477 MSE: 597.34924316\n","\n","Epoch 126: loss improved from 619.52197 to 612.70685, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 112ms/step - loss: 612.7068 - mae: 16.5923\n","Epoch 127/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 607.6294 - mae: 15.1891_Epoch 127 Results: R2 Score: 0.57677450 MAE: 17.35471153 MSE: 590.66314697\n","\n","Epoch 127: loss improved from 612.70685 to 605.94574, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 49ms/step - loss: 605.9457 - mae: 16.5927\n","Epoch 128/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 600.9077 - mae: 18.1480_Epoch 128 Results: R2 Score: 0.58353447 MAE: 17.27058220 MSE: 584.02813721\n","\n","Epoch 128: loss improved from 605.94574 to 599.23682, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 599.2368 - mae: 16.5932\n","Epoch 129/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 594.2367 - mae: 18.6348_Epoch 129 Results: R2 Score: 0.59018358 MAE: 17.18549156 MSE: 577.44281006\n","\n","Epoch 129: loss improved from 599.23682 to 592.57819, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 115ms/step - loss: 592.5782 - mae: 16.5938\n","Epoch 130/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 587.6149 - mae: 16.2835_Epoch 130 Results: R2 Score: 0.59672559 MAE: 17.10032463 MSE: 570.90576172\n","\n","Epoch 130: loss improved from 592.57819 to 585.96844, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 585.9684 - mae: 16.5942\n","Epoch 131/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 581.0413 - mae: 17.7141_Epoch 131 Results: R2 Score: 0.60316515 MAE: 17.01547432 MSE: 564.41552734\n","\n","Epoch 131: loss improved from 585.96844 to 579.40662, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 105ms/step - loss: 579.4066 - mae: 16.5947\n","Epoch 132/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 574.5148 - mae: 15.1774_Epoch 132 Results: R2 Score: 0.60950274 MAE: 16.93053436 MSE: 557.97094727\n","\n","Epoch 132: loss improved from 579.40662 to 572.89166, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 86ms/step - loss: 572.8917 - mae: 16.5951\n","Epoch 133/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 568.0339 - mae: 16.7664_Epoch 133 Results: R2 Score: 0.61574057 MAE: 16.84525871 MSE: 551.57110596\n","\n","Epoch 133: loss improved from 572.89166 to 566.42212, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 50ms/step - loss: 566.4221 - mae: 16.5956\n","Epoch 134/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 561.5975 - mae: 17.3774_Epoch 134 Results: R2 Score: 0.62188146 MAE: 16.75925064 MSE: 545.21490479\n","\n","Epoch 134: loss improved from 566.42212 to 559.99670, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 559.9967 - mae: 16.5961\n","Epoch 135/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 555.2046 - mae: 17.1749_Epoch 135 Results: R2 Score: 0.62792815 MAE: 16.67327881 MSE: 538.90148926\n","\n","Epoch 135: loss improved from 559.99670 to 553.61438, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 553.6144 - mae: 16.5967\n","Epoch 136/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 548.8545 - mae: 17.9674_Epoch 136 Results: R2 Score: 0.63388295 MAE: 16.58766747 MSE: 532.63012695\n","\n","Epoch 136: loss improved from 553.61438 to 547.27502, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 126ms/step - loss: 547.2750 - mae: 16.5972\n","Epoch 137/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 542.5465 - mae: 17.3528_Epoch 137 Results: R2 Score: 0.63974914 MAE: 16.50209618 MSE: 526.40045166\n","\n","Epoch 137: loss improved from 547.27502 to 540.97736, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 540.9774 - mae: 16.5977\n","Epoch 138/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 536.2803 - mae: 15.7929_Epoch 138 Results: R2 Score: 0.64552990 MAE: 16.41699028 MSE: 520.21173096\n","\n","Epoch 138: loss improved from 540.97736 to 534.72150, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 126ms/step - loss: 534.7215 - mae: 16.5982\n","Epoch 139/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 530.0554 - mae: 14.7910_Epoch 139 Results: R2 Score: 0.65122714 MAE: 16.33102417 MSE: 514.06390381\n","\n","Epoch 139: loss improved from 534.72150 to 528.50677, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 528.5068 - mae: 16.5986\n","Epoch 140/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 523.8708 - mae: 15.6676_Epoch 140 Results: R2 Score: 0.65684077 MAE: 16.24397469 MSE: 507.95675659\n","\n","Epoch 140: loss improved from 528.50677 to 522.33221, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 522.3322 - mae: 16.5991\n","Epoch 141/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 517.7264 - mae: 16.0151_Epoch 141 Results: R2 Score: 0.66237145 MAE: 16.15650177 MSE: 501.89022827\n","\n","Epoch 141: loss improved from 522.33221 to 516.19794, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 97ms/step - loss: 516.1979 - mae: 16.5997\n","Epoch 142/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 511.6225 - mae: 17.1136_Epoch 142 Results: R2 Score: 0.66782079 MAE: 16.06873703 MSE: 495.86486816\n","\n","Epoch 142: loss improved from 516.19794 to 510.10422, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 510.1042 - mae: 16.6001\n","Epoch 143/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 505.5596 - mae: 17.7175_Epoch 143 Results: R2 Score: 0.67319197 MAE: 15.98068523 MSE: 489.88088989\n","\n","Epoch 143: loss improved from 510.10422 to 504.05151, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 504.0515 - mae: 16.6006\n","Epoch 144/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 499.5379 - mae: 15.8685_Epoch 144 Results: R2 Score: 0.67848727 MAE: 15.89226341 MSE: 483.93911743\n","\n","Epoch 144: loss improved from 504.05151 to 498.04034, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 498.0403 - mae: 16.6011\n","Epoch 145/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 493.5583 - mae: 17.3537_Epoch 145 Results: R2 Score: 0.68370696 MAE: 15.80489826 MSE: 478.04055786\n","\n","Epoch 145: loss improved from 498.04034 to 492.07156, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 492.0716 - mae: 16.6016\n","Epoch 146/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 487.6223 - mae: 16.7886_Epoch 146 Results: R2 Score: 0.68885021 MAE: 15.71795368 MSE: 472.18603516\n","\n","Epoch 146: loss improved from 492.07156 to 486.14664, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 486.1466 - mae: 16.6021\n","Epoch 147/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 481.7307 - mae: 16.3889_Epoch 147 Results: R2 Score: 0.69391707 MAE: 15.63087082 MSE: 466.37680054\n","\n","Epoch 147: loss improved from 486.14664 to 480.26636, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 480.2664 - mae: 16.6025\n","Epoch 148/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 475.8844 - mae: 16.4467_Epoch 148 Results: R2 Score: 0.69890894 MAE: 15.54338932 MSE: 460.61404419\n","\n","Epoch 148: loss improved from 480.26636 to 474.43137, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 474.4314 - mae: 16.6030\n","Epoch 149/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 470.0844 - mae: 16.2901_Epoch 149 Results: R2 Score: 0.70382652 MAE: 15.45592594 MSE: 454.89877319\n","\n","Epoch 149: loss improved from 474.43137 to 468.64325, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 113ms/step - loss: 468.6432 - mae: 16.6035\n","Epoch 150/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 464.3318 - mae: 18.7631_Epoch 150 Results: R2 Score: 0.70866812 MAE: 15.36837864 MSE: 449.23208618\n","\n","Epoch 150: loss improved from 468.64325 to 462.90274, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 106ms/step - loss: 462.9027 - mae: 16.6039\n","Epoch 151/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 458.6279 - mae: 16.5648_Epoch 151 Results: R2 Score: 0.71343514 MAE: 15.28105736 MSE: 443.61517334\n","\n","Epoch 151: loss improved from 462.90274 to 457.21130, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 133ms/step - loss: 457.2113 - mae: 16.6044\n","Epoch 152/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 452.9738 - mae: 17.6277_Epoch 152 Results: R2 Score: 0.71812718 MAE: 15.19307423 MSE: 438.04873657\n","\n","Epoch 152: loss improved from 457.21130 to 451.56976, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 145ms/step - loss: 451.5698 - mae: 16.6050\n","Epoch 153/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 447.3700 - mae: 16.1363_Epoch 153 Results: R2 Score: 0.72274367 MAE: 15.10490227 MSE: 432.53338623\n","\n","Epoch 153: loss improved from 451.56976 to 445.97858, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 445.9786 - mae: 16.6055\n","Epoch 154/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 441.8172 - mae: 17.1989_Epoch 154 Results: R2 Score: 0.72728458 MAE: 15.01700115 MSE: 427.06951904\n","\n","Epoch 154: loss improved from 445.97858 to 440.43863, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 440.4386 - mae: 16.6061\n","Epoch 155/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 436.3160 - mae: 16.7061_Epoch 155 Results: R2 Score: 0.73175042 MAE: 14.93005657 MSE: 421.65756226\n","\n","Epoch 155: loss improved from 440.43863 to 434.95056, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 89ms/step - loss: 434.9506 - mae: 16.6067\n","Epoch 156/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 430.8673 - mae: 17.0676_Epoch 156 Results: R2 Score: 0.73614302 MAE: 14.84326553 MSE: 416.29769897\n","\n","Epoch 156: loss improved from 434.95056 to 429.51495, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 51ms/step - loss: 429.5150 - mae: 16.6072\n","Epoch 157/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 425.4709 - mae: 16.2888_Epoch 157 Results: R2 Score: 0.74046423 MAE: 14.75607491 MSE: 410.98986816\n","\n","Epoch 157: loss improved from 429.51495 to 424.13153, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 424.1315 - mae: 16.6077\n","Epoch 158/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 420.1263 - mae: 17.1403_Epoch 158 Results: R2 Score: 0.74471594 MAE: 14.66867352 MSE: 405.73388672\n","\n","Epoch 158: loss improved from 424.13153 to 418.79990, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 418.7999 - mae: 16.6084\n","Epoch 159/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 414.8336 - mae: 17.2403_Epoch 159 Results: R2 Score: 0.74889887 MAE: 14.58170319 MSE: 400.52938843\n","\n","Epoch 159: loss improved from 418.79990 to 413.52011, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 413.5201 - mae: 16.6089\n","Epoch 160/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 409.5926 - mae: 16.3899_Epoch 160 Results: R2 Score: 0.75301403 MAE: 14.49491024 MSE: 395.37622070\n","\n","Epoch 160: loss improved from 413.52011 to 408.29205, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 408.2921 - mae: 16.6095\n","Epoch 161/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 404.4031 - mae: 16.3143_Epoch 161 Results: R2 Score: 0.75706328 MAE: 14.40752411 MSE: 390.27383423\n","\n","Epoch 161: loss improved from 408.29205 to 403.11517, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 403.1152 - mae: 16.6102\n","Epoch 162/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 399.2641 - mae: 15.6260_Epoch 162 Results: R2 Score: 0.76104809 MAE: 14.32024765 MSE: 385.22198486\n","\n","Epoch 162: loss improved from 403.11517 to 397.98898, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 40ms/step - loss: 397.9890 - mae: 16.6108\n","Epoch 163/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 394.1758 - mae: 16.7980_Epoch 163 Results: R2 Score: 0.76497054 MAE: 14.23281860 MSE: 380.22018433\n","\n","Epoch 163: loss improved from 397.98898 to 392.91306, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 392.9131 - mae: 16.6115\n","Epoch 164/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 389.1375 - mae: 15.5040_Epoch 164 Results: R2 Score: 0.76883169 MAE: 14.14527512 MSE: 375.26800537\n","\n","Epoch 164: loss improved from 392.91306 to 387.88718, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 115ms/step - loss: 387.8872 - mae: 16.6122\n","Epoch 165/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 384.1487 - mae: 16.9305_Epoch 165 Results: R2 Score: 0.77262914 MAE: 14.05729866 MSE: 370.36486816\n","\n","Epoch 165: loss improved from 387.88718 to 382.91074, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 133ms/step - loss: 382.9107 - mae: 16.6128\n","Epoch 166/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 379.2089 - mae: 16.5585_Epoch 166 Results: R2 Score: 0.77636127 MAE: 13.96999931 MSE: 365.51055908\n","\n","Epoch 166: loss improved from 382.91074 to 377.98312, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 101ms/step - loss: 377.9831 - mae: 16.6135\n","Epoch 167/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 374.3182 - mae: 16.9411_Epoch 167 Results: R2 Score: 0.78002989 MAE: 13.88362980 MSE: 360.70462036\n","\n","Epoch 167: loss improved from 377.98312 to 373.10474, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 107ms/step - loss: 373.1047 - mae: 16.6142\n","Epoch 168/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 369.4764 - mae: 15.0575_Epoch 168 Results: R2 Score: 0.78363721 MAE: 13.79708099 MSE: 355.94680786\n","\n","Epoch 168: loss improved from 373.10474 to 368.27499, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 368.2750 - mae: 16.6149\n","Epoch 169/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 364.6827 - mae: 16.9952_Epoch 169 Results: R2 Score: 0.78718497 MAE: 13.70991611 MSE: 351.23663330\n","\n","Epoch 169: loss improved from 368.27499 to 363.49319, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 363.4932 - mae: 16.6155\n","Epoch 170/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 359.9364 - mae: 16.1477_Epoch 170 Results: R2 Score: 0.79067414 MAE: 13.62293434 MSE: 346.57369995\n","\n","Epoch 170: loss improved from 363.49319 to 358.75864, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 358.7586 - mae: 16.6164\n","Epoch 171/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 355.2373 - mae: 15.2076_Epoch 171 Results: R2 Score: 0.79410768 MAE: 13.53661728 MSE: 341.95764160\n","\n","Epoch 171: loss improved from 358.75864 to 354.07144, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 354.0714 - mae: 16.6170\n","Epoch 172/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 350.5855 - mae: 15.5584_Epoch 172 Results: R2 Score: 0.79748782 MAE: 13.45061016 MSE: 337.38796997\n","\n","Epoch 172: loss improved from 354.07144 to 349.43130, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 349.4313 - mae: 16.6178\n","Epoch 173/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 345.9803 - mae: 13.9201_Epoch 173 Results: R2 Score: 0.80081559 MAE: 13.36490917 MSE: 332.86425781\n","\n","Epoch 173: loss improved from 349.43130 to 344.83762, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 95ms/step - loss: 344.8376 - mae: 16.6185\n","Epoch 174/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 341.4212 - mae: 15.5185_Epoch 174 Results: R2 Score: 0.80409156 MAE: 13.27898026 MSE: 328.38610840\n","\n","Epoch 174: loss improved from 344.83762 to 340.28995, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 340.2899 - mae: 16.6193\n","Epoch 175/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 336.9075 - mae: 17.6782_Epoch 175 Results: R2 Score: 0.80731656 MAE: 13.19337273 MSE: 323.95306396\n","\n","Epoch 175: loss improved from 340.28995 to 335.78763, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 107ms/step - loss: 335.7876 - mae: 16.6200\n","Epoch 176/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 332.4391 - mae: 16.3817_Epoch 176 Results: R2 Score: 0.81049089 MAE: 13.10778904 MSE: 319.56484985\n","\n","Epoch 176: loss improved from 335.78763 to 331.33044, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 331.3304 - mae: 16.6208\n","Epoch 177/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 328.0155 - mae: 16.8462_Epoch 177 Results: R2 Score: 0.81361436 MAE: 13.02244663 MSE: 315.22088623\n","\n","Epoch 177: loss improved from 331.33044 to 326.91800, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 124ms/step - loss: 326.9180 - mae: 16.6216\n","Epoch 178/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 323.6364 - mae: 14.8230_Epoch 178 Results: R2 Score: 0.81668835 MAE: 12.93718433 MSE: 310.92089844\n","\n","Epoch 178: loss improved from 326.91800 to 322.54980, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 322.5498 - mae: 16.6224\n","Epoch 179/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 319.3013 - mae: 16.4288_Epoch 179 Results: R2 Score: 0.81971484 MAE: 12.85163879 MSE: 306.66439819\n","\n","Epoch 179: loss improved from 322.54980 to 318.22562, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 50ms/step - loss: 318.2256 - mae: 16.6232\n","Epoch 180/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 315.0095 - mae: 15.9950_Epoch 180 Results: R2 Score: 0.82269487 MAE: 12.76599312 MSE: 302.45132446\n","\n","Epoch 180: loss improved from 318.22562 to 313.94461, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 313.9446 - mae: 16.6241\n","Epoch 181/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 310.7610 - mae: 14.9649_Epoch 181 Results: R2 Score: 0.82562876 MAE: 12.68048191 MSE: 298.28100586\n","\n","Epoch 181: loss improved from 313.94461 to 309.70694, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 309.7069 - mae: 16.6249\n","Epoch 182/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 306.5554 - mae: 16.2846_Epoch 182 Results: R2 Score: 0.82851669 MAE: 12.59599781 MSE: 294.15304565\n","\n","Epoch 182: loss improved from 309.70694 to 305.51199, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 305.5120 - mae: 16.6257\n","Epoch 183/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 302.3926 - mae: 15.7131_Epoch 183 Results: R2 Score: 0.83136056 MAE: 12.51241493 MSE: 290.06732178\n","\n","Epoch 183: loss improved from 305.51199 to 301.35995, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 301.3600 - mae: 16.6265\n","Epoch 184/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 298.2725 - mae: 16.3688_Epoch 184 Results: R2 Score: 0.83416144 MAE: 12.42927837 MSE: 286.02340698\n","\n","Epoch 184: loss improved from 301.35995 to 297.25037, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 297.2504 - mae: 16.6273\n","Epoch 185/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 294.1944 - mae: 17.2362_Epoch 185 Results: R2 Score: 0.83691969 MAE: 12.34722233 MSE: 282.02127075\n","\n","Epoch 185: loss improved from 297.25037 to 293.18280, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 293.1828 - mae: 16.6282\n","Epoch 186/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 290.1586 - mae: 17.5671_Epoch 186 Results: R2 Score: 0.83963486 MAE: 12.26541042 MSE: 278.06060791\n","\n","Epoch 186: loss improved from 293.18280 to 289.15750, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 289.1575 - mae: 16.6290\n","Epoch 187/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 286.1643 - mae: 16.0538_Epoch 187 Results: R2 Score: 0.84230923 MAE: 12.18338680 MSE: 274.14089966\n","\n","Epoch 187: loss improved from 289.15750 to 285.17343, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 44ms/step - loss: 285.1734 - mae: 16.6297\n","Epoch 188/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 282.2109 - mae: 17.6072_Epoch 188 Results: R2 Score: 0.84494448 MAE: 12.10148621 MSE: 270.26193237\n","\n","Epoch 188: loss improved from 285.17343 to 281.23019, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 281.2302 - mae: 16.6305\n","Epoch 189/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 278.2982 - mae: 16.3897_Epoch 189 Results: R2 Score: 0.84754205 MAE: 12.02003765 MSE: 266.42330933\n","\n","Epoch 189: loss improved from 281.23019 to 277.32770, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 277.3277 - mae: 16.6313\n","Epoch 190/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 274.4261 - mae: 16.2594_Epoch 190 Results: R2 Score: 0.85010232 MAE: 11.93887424 MSE: 262.62469482\n","\n","Epoch 190: loss improved from 277.32770 to 273.46570, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 111ms/step - loss: 273.4657 - mae: 16.6322\n","Epoch 191/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 270.5942 - mae: 16.8416_Epoch 191 Results: R2 Score: 0.85262517 MAE: 11.85762691 MSE: 258.86572266\n","\n","Epoch 191: loss improved from 273.46570 to 269.64362, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 269.6436 - mae: 16.6330\n","Epoch 192/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 266.8018 - mae: 16.8602_Epoch 192 Results: R2 Score: 0.85511068 MAE: 11.77641010 MSE: 255.14604187\n","\n","Epoch 192: loss improved from 269.64362 to 265.86105, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 265.8611 - mae: 16.6337\n","Epoch 193/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 263.0487 - mae: 15.1733_Epoch 193 Results: R2 Score: 0.85755920 MAE: 11.69541645 MSE: 251.46525574\n","\n","Epoch 193: loss improved from 265.86105 to 262.11771, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 262.1177 - mae: 16.6345\n","Epoch 194/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 259.3345 - mae: 16.5552_Epoch 194 Results: R2 Score: 0.85997099 MAE: 11.61447620 MSE: 247.82305908\n","\n","Epoch 194: loss improved from 262.11771 to 258.41324, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 258.4132 - mae: 16.6353\n","Epoch 195/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 255.6590 - mae: 16.4236_Epoch 195 Results: R2 Score: 0.86234682 MAE: 11.53340244 MSE: 244.21910095\n","\n","Epoch 195: loss improved from 258.41324 to 254.74728, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 254.7473 - mae: 16.6361\n","Epoch 196/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 252.0216 - mae: 16.8354_Epoch 196 Results: R2 Score: 0.86468786 MAE: 11.45228577 MSE: 240.65299988\n","\n","Epoch 196: loss improved from 254.74728 to 251.11935, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 251.1194 - mae: 16.6368\n","Epoch 197/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 248.4220 - mae: 17.0964_Epoch 197 Results: R2 Score: 0.86699514 MAE: 11.37163734 MSE: 237.12438965\n","\n","Epoch 197: loss improved from 251.11935 to 247.52919, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 247.5292 - mae: 16.6376\n","Epoch 198/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 244.8601 - mae: 16.4186_Epoch 198 Results: R2 Score: 0.86926949 MAE: 11.29113293 MSE: 233.63278198\n","\n","Epoch 198: loss improved from 247.52919 to 243.97662, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 243.9766 - mae: 16.6384\n","Epoch 199/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 241.3353 - mae: 16.1003_Epoch 199 Results: R2 Score: 0.87151193 MAE: 11.21100616 MSE: 230.17808533\n","\n","Epoch 199: loss improved from 243.97662 to 240.46104, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 240.4610 - mae: 16.6391\n","Epoch 200/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 237.8476 - mae: 15.9868_Epoch 200 Results: R2 Score: 0.87372305 MAE: 11.13131714 MSE: 226.75990295\n","\n","Epoch 200: loss improved from 240.46104 to 236.98256, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 236.9826 - mae: 16.6399\n","Epoch 201/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 234.3966 - mae: 17.5327_Epoch 201 Results: R2 Score: 0.87590291 MAE: 11.05173969 MSE: 223.37802124\n","\n","Epoch 201: loss improved from 236.98256 to 233.54062, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 103ms/step - loss: 233.5406 - mae: 16.6406\n","Epoch 202/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 230.9818 - mae: 14.6546_Epoch 202 Results: R2 Score: 0.87805184 MAE: 10.97210407 MSE: 220.03205872\n","\n","Epoch 202: loss improved from 233.54062 to 230.13490, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 88ms/step - loss: 230.1349 - mae: 16.6413\n","Epoch 203/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 227.6030 - mae: 16.1831_Epoch 203 Results: R2 Score: 0.88016937 MAE: 10.89250374 MSE: 216.72187805\n","\n","Epoch 203: loss improved from 230.13490 to 226.76503, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 226.7650 - mae: 16.6421\n","Epoch 204/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 224.2599 - mae: 16.5502_Epoch 204 Results: R2 Score: 0.88225639 MAE: 10.81352997 MSE: 213.44718933\n","\n","Epoch 204: loss improved from 226.76503 to 223.43088, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 223.4309 - mae: 16.6428\n","Epoch 205/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 220.9527 - mae: 17.1663_Epoch 205 Results: R2 Score: 0.88431321 MAE: 10.73451900 MSE: 210.20796204\n","\n","Epoch 205: loss improved from 223.43088 to 220.13246, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 118ms/step - loss: 220.1325 - mae: 16.6436\n","Epoch 206/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 217.6808 - mae: 17.3535_Epoch 206 Results: R2 Score: 0.88633973 MAE: 10.65540218 MSE: 207.00424194\n","\n","Epoch 206: loss improved from 220.13246 to 216.86954, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 216.8695 - mae: 16.6443\n","Epoch 207/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 214.4444 - mae: 16.9966_Epoch 207 Results: R2 Score: 0.88833579 MAE: 10.57628441 MSE: 203.83615112\n","\n","Epoch 207: loss improved from 216.86954 to 213.64200, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 213.6420 - mae: 16.6451\n","Epoch 208/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 211.2436 - mae: 18.1930_Epoch 208 Results: R2 Score: 0.89030167 MAE: 10.49695969 MSE: 200.70358276\n","\n","Epoch 208: loss improved from 213.64200 to 210.45006, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 51ms/step - loss: 210.4501 - mae: 16.6457\n","Epoch 209/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 208.0782 - mae: 17.3950_Epoch 209 Results: R2 Score: 0.89223733 MAE: 10.41804314 MSE: 197.60665894\n","\n","Epoch 209: loss improved from 210.45006 to 207.29355, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 49ms/step - loss: 207.2935 - mae: 16.6465\n","Epoch 210/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 204.9486 - mae: 14.9538_Epoch 210 Results: R2 Score: 0.89414321 MAE: 10.33956337 MSE: 194.54541016\n","\n","Epoch 210: loss improved from 207.29355 to 204.17291, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 204.1729 - mae: 16.6472\n","Epoch 211/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 201.8548 - mae: 17.1460_Epoch 211 Results: R2 Score: 0.89601973 MAE: 10.26126385 MSE: 191.52026367\n","\n","Epoch 211: loss improved from 204.17291 to 201.08818, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 128ms/step - loss: 201.0882 - mae: 16.6479\n","Epoch 212/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 198.7972 - mae: 18.8048_Epoch 212 Results: R2 Score: 0.89786695 MAE: 10.18268776 MSE: 188.53129578\n","\n","Epoch 212: loss improved from 201.08818 to 198.03951, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 198.0395 - mae: 16.6486\n","Epoch 213/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 195.7755 - mae: 16.4723_Epoch 213 Results: R2 Score: 0.89968482 MAE: 10.10384560 MSE: 185.57859802\n","\n","Epoch 213: loss improved from 198.03951 to 195.02684, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 132ms/step - loss: 195.0268 - mae: 16.6493\n","Epoch 214/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 192.7900 - mae: 15.7873_Epoch 214 Results: R2 Score: 0.90147338 MAE: 10.02486324 MSE: 182.66239929\n","\n","Epoch 214: loss improved from 195.02684 to 192.05040, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 192.0504 - mae: 16.6499\n","Epoch 215/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 189.8408 - mae: 16.2583_Epoch 215 Results: R2 Score: 0.90323303 MAE: 9.94576645 MSE: 179.78273010\n","\n","Epoch 215: loss improved from 192.05040 to 189.11031, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 189.1103 - mae: 16.6506\n","Epoch 216/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 186.9281 - mae: 15.6565_Epoch 216 Results: R2 Score: 0.90496408 MAE: 9.86677742 MSE: 176.93981934\n","\n","Epoch 216: loss improved from 189.11031 to 186.20679, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 71ms/step - loss: 186.2068 - mae: 16.6513\n","Epoch 217/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 184.0521 - mae: 15.8246_Epoch 217 Results: R2 Score: 0.90666621 MAE: 9.78781605 MSE: 174.13360596\n","\n","Epoch 217: loss improved from 186.20679 to 183.33994, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 183.3399 - mae: 16.6520\n","Epoch 218/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 181.2127 - mae: 15.8341_Epoch 218 Results: R2 Score: 0.90833941 MAE: 9.70895481 MSE: 171.36418152\n","\n","Epoch 218: loss improved from 183.33994 to 180.50983, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 180.5098 - mae: 16.6526\n","Epoch 219/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 178.4102 - mae: 16.7432_Epoch 219 Results: R2 Score: 0.90998437 MAE: 9.63043118 MSE: 168.63150024\n","\n","Epoch 219: loss improved from 180.50983 to 177.71646, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 76ms/step - loss: 177.7165 - mae: 16.6533\n","Epoch 220/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 175.6445 - mae: 16.4130_Epoch 220 Results: R2 Score: 0.91160259 MAE: 9.55241871 MSE: 165.93554688\n","\n","Epoch 220: loss improved from 177.71646 to 174.95998, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 174.9600 - mae: 16.6540\n","Epoch 221/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 172.9157 - mae: 14.6456_Epoch 221 Results: R2 Score: 0.91319409 MAE: 9.47478485 MSE: 163.27621460\n","\n","Epoch 221: loss improved from 174.95998 to 172.24040, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 172.2404 - mae: 16.6546\n","Epoch 222/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 170.2237 - mae: 16.6781_Epoch 222 Results: R2 Score: 0.91475875 MAE: 9.39746666 MSE: 160.65351868\n","\n","Epoch 222: loss improved from 172.24040 to 169.55763, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 88ms/step - loss: 169.5576 - mae: 16.6552\n","Epoch 223/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 167.5685 - mae: 14.9777_Epoch 223 Results: R2 Score: 0.91629638 MAE: 9.32020283 MSE: 158.06736755\n","\n","Epoch 223: loss improved from 169.55763 to 166.91148, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 166.9115 - mae: 16.6559\n","Epoch 224/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 164.9497 - mae: 16.1422_Epoch 224 Results: R2 Score: 0.91780666 MAE: 9.24320602 MSE: 155.51759338\n","\n","Epoch 224: loss improved from 166.91148 to 164.30186, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 99ms/step - loss: 164.3019 - mae: 16.6565\n","Epoch 225/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 162.3674 - mae: 19.4106_Epoch 225 Results: R2 Score: 0.91929042 MAE: 9.16682816 MSE: 153.00405884\n","\n","Epoch 225: loss improved from 164.30186 to 161.72871, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 161.7287 - mae: 16.6571\n","Epoch 226/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 159.8216 - mae: 17.3039_Epoch 226 Results: R2 Score: 0.92074815 MAE: 9.09071064 MSE: 150.52645874\n","\n","Epoch 226: loss improved from 161.72871 to 159.19188, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 76ms/step - loss: 159.1919 - mae: 16.6577\n","Epoch 227/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 157.3118 - mae: 16.5413_Epoch 227 Results: R2 Score: 0.92218081 MAE: 9.01493263 MSE: 148.08453369\n","\n","Epoch 227: loss improved from 159.19188 to 156.69099, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 156.6910 - mae: 16.6583\n","Epoch 228/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 154.8378 - mae: 17.1108_Epoch 228 Results: R2 Score: 0.92358819 MAE: 8.93950653 MSE: 145.67814636\n","\n","Epoch 228: loss improved from 156.69099 to 154.22594, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 154.2259 - mae: 16.6589\n","Epoch 229/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 152.3994 - mae: 16.5411_Epoch 229 Results: R2 Score: 0.92497060 MAE: 8.86441994 MSE: 143.30686951\n","\n","Epoch 229: loss improved from 154.22594 to 151.79645, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 151.7964 - mae: 16.6594\n","Epoch 230/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 149.9963 - mae: 16.6917_Epoch 230 Results: R2 Score: 0.92632862 MAE: 8.79017448 MSE: 140.97044373\n","\n","Epoch 230: loss improved from 151.79645 to 149.40222, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 149.4022 - mae: 16.6601\n","Epoch 231/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 147.6285 - mae: 17.5689_Epoch 231 Results: R2 Score: 0.92766249 MAE: 8.71656036 MSE: 138.66868591\n","\n","Epoch 231: loss improved from 149.40222 to 147.04311, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 147.0431 - mae: 16.6606\n","Epoch 232/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 145.2956 - mae: 18.5618_Epoch 232 Results: R2 Score: 0.92897274 MAE: 8.64351273 MSE: 136.40090942\n","\n","Epoch 232: loss improved from 147.04311 to 144.71877, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 144.7188 - mae: 16.6612\n","Epoch 233/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 142.9969 - mae: 15.9587_Epoch 233 Results: R2 Score: 0.93026002 MAE: 8.57070827 MSE: 134.16717529\n","\n","Epoch 233: loss improved from 144.71877 to 142.42859, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 142.4286 - mae: 16.6618\n","Epoch 234/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 140.7322 - mae: 16.4721_Epoch 234 Results: R2 Score: 0.93152449 MAE: 8.49834061 MSE: 131.96696472\n","\n","Epoch 234: loss improved from 142.42859 to 140.17239, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 112ms/step - loss: 140.1724 - mae: 16.6623\n","Epoch 235/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 138.5013 - mae: 15.9610_Epoch 235 Results: R2 Score: 0.93276603 MAE: 8.42630005 MSE: 129.80014038\n","\n","Epoch 235: loss improved from 140.17239 to 137.94984, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 99ms/step - loss: 137.9498 - mae: 16.6629\n","Epoch 236/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 136.3038 - mae: 18.0403_Epoch 236 Results: R2 Score: 0.93398499 MAE: 8.35447311 MSE: 127.66625977\n","\n","Epoch 236: loss improved from 137.94984 to 135.76065, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 135.7607 - mae: 16.6634\n","Epoch 237/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 134.1394 - mae: 15.1336_Epoch 237 Results: R2 Score: 0.93518229 MAE: 8.28299809 MSE: 125.56476593\n","\n","Epoch 237: loss improved from 135.76065 to 133.60434, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 133.6043 - mae: 16.6640\n","Epoch 238/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 132.0075 - mae: 17.8155_Epoch 238 Results: R2 Score: 0.93635779 MAE: 8.21203613 MSE: 123.49537659\n","\n","Epoch 238: loss improved from 133.60434 to 131.48059, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 131.4806 - mae: 16.6645\n","Epoch 239/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 129.9079 - mae: 16.6992_Epoch 239 Results: R2 Score: 0.93751152 MAE: 8.14175606 MSE: 121.45771790\n","\n","Epoch 239: loss improved from 131.48059 to 129.38904, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 129.3890 - mae: 16.6651\n","Epoch 240/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 127.8404 - mae: 17.0443_Epoch 240 Results: R2 Score: 0.93864370 MAE: 8.07207394 MSE: 119.45142365\n","\n","Epoch 240: loss improved from 129.38904 to 127.32941, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 127.3294 - mae: 16.6656\n","Epoch 241/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 125.8044 - mae: 16.6537_Epoch 241 Results: R2 Score: 0.93975495 MAE: 8.00296593 MSE: 117.47605133\n","\n","Epoch 241: loss improved from 127.32941 to 125.30125, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 125.3012 - mae: 16.6661\n","Epoch 242/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 123.7996 - mae: 15.8957_Epoch 242 Results: R2 Score: 0.94084626 MAE: 7.93424749 MSE: 115.53140259\n","\n","Epoch 242: loss improved from 125.30125 to 123.30415, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 123.3042 - mae: 16.6666\n","Epoch 243/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 121.8256 - mae: 15.0330_Epoch 243 Results: R2 Score: 0.94191830 MAE: 7.86584616 MSE: 113.61699677\n","\n","Epoch 243: loss improved from 123.30415 to 121.33777, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 121.3378 - mae: 16.6671\n","Epoch 244/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 119.8819 - mae: 16.6006_Epoch 244 Results: R2 Score: 0.94297132 MAE: 7.79785728 MSE: 111.73252106\n","\n","Epoch 244: loss improved from 121.33777 to 119.40168, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 119.4017 - mae: 16.6676\n","Epoch 245/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 117.9684 - mae: 16.9165_Epoch 245 Results: R2 Score: 0.94400596 MAE: 7.73028326 MSE: 109.87755585\n","\n","Epoch 245: loss improved from 119.40168 to 117.49557, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 117.4956 - mae: 16.6681\n","Epoch 246/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 116.0845 - mae: 17.4018_Epoch 246 Results: R2 Score: 0.94502206 MAE: 7.66309643 MSE: 108.05170441\n","\n","Epoch 246: loss improved from 117.49557 to 115.61909, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 115.6191 - mae: 16.6686\n","Epoch 247/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 114.2300 - mae: 15.9287_Epoch 247 Results: R2 Score: 0.94601964 MAE: 7.59624195 MSE: 106.25450897\n","\n","Epoch 247: loss improved from 115.61909 to 113.77174, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 72ms/step - loss: 113.7717 - mae: 16.6691\n","Epoch 248/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 112.4042 - mae: 16.1211_Epoch 248 Results: R2 Score: 0.94699872 MAE: 7.52985668 MSE: 104.48564148\n","\n","Epoch 248: loss improved from 113.77174 to 111.95309, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 111.9531 - mae: 16.6696\n","Epoch 249/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 110.6069 - mae: 18.9455_Epoch 249 Results: R2 Score: 0.94795947 MAE: 7.46402073 MSE: 102.74459839\n","\n","Epoch 249: loss improved from 111.95309 to 110.16289, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 110.1629 - mae: 16.6701\n","Epoch 250/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 108.8377 - mae: 17.3352_Epoch 250 Results: R2 Score: 0.94890270 MAE: 7.39895725 MSE: 101.03123474\n","\n","Epoch 250: loss improved from 110.16289 to 108.40072, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 108.4007 - mae: 16.6706\n","Epoch 251/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 107.0965 - mae: 17.0169_Epoch 251 Results: R2 Score: 0.94982859 MAE: 7.33408785 MSE: 99.34491730\n","\n","Epoch 251: loss improved from 108.40072 to 106.66633, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 106.6663 - mae: 16.6711\n","Epoch 252/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 105.3825 - mae: 16.9466_Epoch 252 Results: R2 Score: 0.95073657 MAE: 7.26965284 MSE: 97.68550873\n","\n","Epoch 252: loss improved from 106.66633 to 104.95907, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 104.9591 - mae: 16.6715\n","Epoch 253/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 103.6955 - mae: 18.5400_Epoch 253 Results: R2 Score: 0.95162760 MAE: 7.20560741 MSE: 96.05255890\n","\n","Epoch 253: loss improved from 104.95907 to 103.27876, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 103.2788 - mae: 16.6720\n","Epoch 254/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 102.0351 - mae: 17.1524_Epoch 254 Results: R2 Score: 0.95250225 MAE: 7.14208937 MSE: 94.44562531\n","\n","Epoch 254: loss improved from 103.27876 to 101.62497, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 101.6250 - mae: 16.6725\n","Epoch 255/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 100.4010 - mae: 16.3490_Epoch 255 Results: R2 Score: 0.95336093 MAE: 7.07919741 MSE: 92.86443329\n","\n","Epoch 255: loss improved from 101.62497 to 99.99728, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 99.9973 - mae: 16.6729\n","Epoch 256/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 98.7927 - mae: 14.9723_Epoch 256 Results: R2 Score: 0.95420411 MAE: 7.01680517 MSE: 91.30858612\n","\n","Epoch 256: loss improved from 99.99728 to 98.39550, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 98.3955 - mae: 16.6734\n","Epoch 257/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 97.2100 - mae: 17.3392_Epoch 257 Results: R2 Score: 0.95503205 MAE: 6.95494366 MSE: 89.77780151\n","\n","Epoch 257: loss improved from 98.39550 to 96.81912, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 96.8191 - mae: 16.6738\n","Epoch 258/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 95.6527 - mae: 16.7661_Epoch 258 Results: R2 Score: 0.95584477 MAE: 6.89371634 MSE: 88.27151489\n","\n","Epoch 258: loss improved from 96.81912 to 95.26797, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 95.2680 - mae: 16.6743\n","Epoch 259/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 94.1200 - mae: 18.5213_Epoch 259 Results: R2 Score: 0.95664251 MAE: 6.83307123 MSE: 86.78961945\n","\n","Epoch 259: loss improved from 95.26797 to 93.74153, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 93.7415 - mae: 16.6747\n","Epoch 260/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 92.6121 - mae: 16.1699_Epoch 260 Results: R2 Score: 0.95742579 MAE: 6.77260828 MSE: 85.33158875\n","\n","Epoch 260: loss improved from 93.74153 to 92.23955, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 92.2395 - mae: 16.6751\n","Epoch 261/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 91.1280 - mae: 15.7183_Epoch 261 Results: R2 Score: 0.95819424 MAE: 6.71251392 MSE: 83.89727020\n","\n","Epoch 261: loss improved from 92.23955 to 90.76143, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 90.7614 - mae: 16.6755\n","Epoch 262/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 89.6677 - mae: 15.0695_Epoch 262 Results: R2 Score: 0.95894829 MAE: 6.65292788 MSE: 82.48609924\n","\n","Epoch 262: loss improved from 90.76143 to 89.30707, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 89.3071 - mae: 16.6760\n","Epoch 263/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 88.2309 - mae: 15.4243_Epoch 263 Results: R2 Score: 0.95968893 MAE: 6.59392262 MSE: 81.09777069\n","\n","Epoch 263: loss improved from 89.30707 to 87.87597, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 87.8760 - mae: 16.6764\n","Epoch 264/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 86.8170 - mae: 14.2432_Epoch 264 Results: R2 Score: 0.96041641 MAE: 6.53540230 MSE: 79.73192596\n","\n","Epoch 264: loss improved from 87.87597 to 86.46783, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 30ms/step - loss: 86.4678 - mae: 16.6768\n","Epoch 265/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 85.4259 - mae: 18.4482_Epoch 265 Results: R2 Score: 0.96113040 MAE: 6.47737885 MSE: 78.38827515\n","\n","Epoch 265: loss improved from 86.46783 to 85.08228, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 19ms/step - loss: 85.0823 - mae: 16.6772\n","Epoch 266/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 84.0571 - mae: 17.6524_Epoch 266 Results: R2 Score: 0.96183106 MAE: 6.41976357 MSE: 77.06646729\n","\n","Epoch 266: loss improved from 85.08228 to 83.71905, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 39ms/step - loss: 83.7190 - mae: 16.6776\n","Epoch 267/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 82.7103 - mae: 16.3953_Epoch 267 Results: R2 Score: 0.96251901 MAE: 6.36242247 MSE: 75.76616669\n","\n","Epoch 267: loss improved from 83.71905 to 82.37766, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 82.3777 - mae: 16.6780\n","Epoch 268/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 81.3851 - mae: 16.1893_Epoch 268 Results: R2 Score: 0.96319466 MAE: 6.30553341 MSE: 74.48701477\n","\n","Epoch 268: loss improved from 82.37766 to 81.05780, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 81.0578 - mae: 16.6784\n","Epoch 269/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 80.0812 - mae: 16.2940_Epoch 269 Results: R2 Score: 0.96385823 MAE: 6.24909258 MSE: 73.22866821\n","\n","Epoch 269: loss improved from 81.05780 to 79.75915, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 79.7591 - mae: 16.6787\n","Epoch 270/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 78.7983 - mae: 18.1364_Epoch 270 Results: R2 Score: 0.96450922 MAE: 6.19305277 MSE: 71.99090576\n","\n","Epoch 270: loss improved from 79.75915 to 78.48143, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 78.4814 - mae: 16.6791\n","Epoch 271/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 77.5361 - mae: 16.6056_Epoch 271 Results: R2 Score: 0.96514707 MAE: 6.13776970 MSE: 70.77320099\n","\n","Epoch 271: loss improved from 78.48143 to 77.22437, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 77.2244 - mae: 16.6795\n","Epoch 272/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 76.2943 - mae: 16.6110_Epoch 272 Results: R2 Score: 0.96577287 MAE: 6.08296013 MSE: 69.57549286\n","\n","Epoch 272: loss improved from 77.22437 to 75.98767, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 75.9877 - mae: 16.6799\n","Epoch 273/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 75.0727 - mae: 17.5710_Epoch 273 Results: R2 Score: 0.96638771 MAE: 6.02870035 MSE: 68.39736176\n","\n","Epoch 273: loss improved from 75.98767 to 74.77106, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 74.7711 - mae: 16.6802\n","Epoch 274/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 73.8709 - mae: 16.8109_Epoch 274 Results: R2 Score: 0.96699163 MAE: 5.97489786 MSE: 67.23856354\n","\n","Epoch 274: loss improved from 74.77106 to 73.57418, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 131ms/step - loss: 73.5742 - mae: 16.6805\n","Epoch 275/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 72.6887 - mae: 16.7368_Epoch 275 Results: R2 Score: 0.96758481 MAE: 5.92137623 MSE: 66.09873199\n","\n","Epoch 275: loss improved from 73.57418 to 72.39667, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 72.3967 - mae: 16.6809\n","Epoch 276/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 71.5254 - mae: 16.0397_Epoch 276 Results: R2 Score: 0.96816725 MAE: 5.86829567 MSE: 64.97763062\n","\n","Epoch 276: loss improved from 72.39667 to 71.23819, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 71.2382 - mae: 16.6812\n","Epoch 277/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 70.3811 - mae: 15.5893_Epoch 277 Results: R2 Score: 0.96873896 MAE: 5.81557322 MSE: 63.87489319\n","\n","Epoch 277: loss improved from 71.23819 to 70.09850, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 70.0985 - mae: 16.6816\n","Epoch 278/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 69.2553 - mae: 17.5022_Epoch 278 Results: R2 Score: 0.96930016 MAE: 5.76306629 MSE: 62.79027557\n","\n","Epoch 278: loss improved from 70.09850 to 68.97726, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 68.9773 - mae: 16.6819\n","Epoch 279/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 68.1476 - mae: 18.0827_Epoch 279 Results: R2 Score: 0.96985097 MAE: 5.71111155 MSE: 61.72350311\n","\n","Epoch 279: loss improved from 68.97726 to 67.87414, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 67.8741 - mae: 16.6822\n","Epoch 280/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 67.0580 - mae: 16.2309_Epoch 280 Results: R2 Score: 0.97039164 MAE: 5.65960693 MSE: 60.67420197\n","\n","Epoch 280: loss improved from 67.87414 to 66.78896, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 66.7890 - mae: 16.6825\n","Epoch 281/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 65.9861 - mae: 15.6820_Epoch 281 Results: R2 Score: 0.97092256 MAE: 5.60841990 MSE: 59.64223480\n","\n","Epoch 281: loss improved from 66.78896 to 65.72137, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 65.7214 - mae: 16.6828\n","Epoch 282/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 64.9315 - mae: 19.7419_Epoch 282 Results: R2 Score: 0.97144393 MAE: 5.55765343 MSE: 58.62722397\n","\n","Epoch 282: loss improved from 65.72137 to 64.67113, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 64.6711 - mae: 16.6831\n","Epoch 283/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 63.8941 - mae: 16.5760_Epoch 283 Results: R2 Score: 0.97195601 MAE: 5.50741816 MSE: 57.62894440\n","\n","Epoch 283: loss improved from 64.67113 to 63.63796, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 63.6380 - mae: 16.6834\n","Epoch 284/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 62.8736 - mae: 15.3733_Epoch 284 Results: R2 Score: 0.97245883 MAE: 5.45752192 MSE: 56.64720154\n","\n","Epoch 284: loss improved from 63.63796 to 62.62167, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 77ms/step - loss: 62.6217 - mae: 16.6837\n","Epoch 285/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 61.8698 - mae: 15.1089_Epoch 285 Results: R2 Score: 0.97295251 MAE: 5.40799332 MSE: 55.68170547\n","\n","Epoch 285: loss improved from 62.62167 to 61.62191, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 105ms/step - loss: 61.6219 - mae: 16.6839\n","Epoch 286/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 60.8823 - mae: 17.0511_Epoch 286 Results: R2 Score: 0.97343715 MAE: 5.35899734 MSE: 54.73223114\n","\n","Epoch 286: loss improved from 61.62191 to 60.63851, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 60.6385 - mae: 16.6842\n","Epoch 287/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 59.9111 - mae: 15.9348_Epoch 287 Results: R2 Score: 0.97391280 MAE: 5.31025600 MSE: 53.79854584\n","\n","Epoch 287: loss improved from 60.63851 to 59.67121, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 51ms/step - loss: 59.6712 - mae: 16.6845\n","Epoch 288/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 58.9557 - mae: 16.0780_Epoch 288 Results: R2 Score: 0.97437961 MAE: 5.26205349 MSE: 52.88024902\n","\n","Epoch 288: loss improved from 59.67121 to 58.71973, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 58.7197 - mae: 16.6847\n","Epoch 289/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 58.0159 - mae: 17.8378_Epoch 289 Results: R2 Score: 0.97483827 MAE: 5.21436024 MSE: 51.97715378\n","\n","Epoch 289: loss improved from 58.71973 to 57.78384, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 57.7838 - mae: 16.6849\n","Epoch 290/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 57.0915 - mae: 16.4362_Epoch 290 Results: R2 Score: 0.97528859 MAE: 5.16683674 MSE: 51.08906174\n","\n","Epoch 290: loss improved from 57.78384 to 56.86324, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 56.8632 - mae: 16.6852\n","Epoch 291/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 56.1822 - mae: 15.7094_Epoch 291 Results: R2 Score: 0.97573042 MAE: 5.11977816 MSE: 50.21572495\n","\n","Epoch 291: loss improved from 56.86324 to 55.95768, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 106ms/step - loss: 55.9577 - mae: 16.6854\n","Epoch 292/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 55.2878 - mae: 16.6767_Epoch 292 Results: R2 Score: 0.97616455 MAE: 5.07319212 MSE: 49.35688019\n","\n","Epoch 292: loss improved from 55.95768 to 55.06703, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 55.0670 - mae: 16.6856\n","Epoch 293/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 54.4082 - mae: 17.1126_Epoch 293 Results: R2 Score: 0.97659131 MAE: 5.02724552 MSE: 48.51224136\n","\n","Epoch 293: loss improved from 55.06703 to 54.19099, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 54.1910 - mae: 16.6859\n","Epoch 294/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 53.5430 - mae: 17.0182_Epoch 294 Results: R2 Score: 0.97701000 MAE: 4.98163509 MSE: 47.68170547\n","\n","Epoch 294: loss improved from 54.19099 to 53.32940, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 81ms/step - loss: 53.3294 - mae: 16.6861\n","Epoch 295/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 52.6921 - mae: 16.8464_Epoch 295 Results: R2 Score: 0.97742103 MAE: 4.93624353 MSE: 46.86508560\n","\n","Epoch 295: loss improved from 53.32940 to 52.48198, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 52.4820 - mae: 16.6863\n","Epoch 296/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 51.8551 - mae: 18.3956_Epoch 296 Results: R2 Score: 0.97782471 MAE: 4.89115000 MSE: 46.06207657\n","\n","Epoch 296: loss improved from 52.48198 to 51.64845, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 51.6485 - mae: 16.6865\n","Epoch 297/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 51.0318 - mae: 17.5253_Epoch 297 Results: R2 Score: 0.97822106 MAE: 4.84637213 MSE: 45.27246094\n","\n","Epoch 297: loss improved from 51.64845 to 50.82857, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 50.8286 - mae: 16.6867\n","Epoch 298/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 50.2221 - mae: 16.6938_Epoch 298 Results: R2 Score: 0.97861021 MAE: 4.80194330 MSE: 44.49591064\n","\n","Epoch 298: loss improved from 50.82857 to 50.02215, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 50.0222 - mae: 16.6869\n","Epoch 299/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 49.4256 - mae: 15.9319_Epoch 299 Results: R2 Score: 0.97899231 MAE: 4.75785303 MSE: 43.73236465\n","\n","Epoch 299: loss improved from 50.02215 to 49.22891, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 49.2289 - mae: 16.6871\n","Epoch 300/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 48.6422 - mae: 16.3188_Epoch 300 Results: R2 Score: 0.97936779 MAE: 4.71414804 MSE: 42.98153305\n","\n","Epoch 300: loss improved from 49.22891 to 48.44873, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 48.4487 - mae: 16.6873\n","Epoch 301/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 47.8716 - mae: 17.7207_Epoch 301 Results: R2 Score: 0.97973658 MAE: 4.67090702 MSE: 42.24320984\n","\n","Epoch 301: loss improved from 48.44873 to 47.68137, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 47.6814 - mae: 16.6875\n","Epoch 302/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 47.1138 - mae: 16.3512_Epoch 302 Results: R2 Score: 0.98009856 MAE: 4.62806654 MSE: 41.51714706\n","\n","Epoch 302: loss improved from 47.68137 to 46.92667, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 46.9267 - mae: 16.6877\n","Epoch 303/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 46.3684 - mae: 14.8137_Epoch 303 Results: R2 Score: 0.98045397 MAE: 4.58562660 MSE: 40.80325699\n","\n","Epoch 303: loss improved from 46.92667 to 46.18439, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 46.1844 - mae: 16.6879\n","Epoch 304/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 45.6354 - mae: 17.3559_Epoch 304 Results: R2 Score: 0.98080301 MAE: 4.54349375 MSE: 40.10146332\n","\n","Epoch 304: loss improved from 46.18439 to 45.45442, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 37ms/step - loss: 45.4544 - mae: 16.6880\n","Epoch 305/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 44.9145 - mae: 16.9813_Epoch 305 Results: R2 Score: 0.98114547 MAE: 4.50147200 MSE: 39.41157532\n","\n","Epoch 305: loss improved from 45.45442 to 44.73655, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 44.7365 - mae: 16.6882\n","Epoch 306/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 44.2056 - mae: 17.1807_Epoch 306 Results: R2 Score: 0.98148164 MAE: 4.45976686 MSE: 38.73327255\n","\n","Epoch 306: loss improved from 44.73655 to 44.03057, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 44.0306 - mae: 16.6884\n","Epoch 307/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 43.5084 - mae: 16.5024_Epoch 307 Results: R2 Score: 0.98181184 MAE: 4.41864014 MSE: 38.06636810\n","\n","Epoch 307: loss improved from 44.03057 to 43.33627, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 43.3363 - mae: 16.6885\n","Epoch 308/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 42.8228 - mae: 17.4951_Epoch 308 Results: R2 Score: 0.98213652 MAE: 4.37799835 MSE: 37.41064453\n","\n","Epoch 308: loss improved from 43.33627 to 42.65352, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 42.6535 - mae: 16.6887\n","Epoch 309/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 42.1485 - mae: 17.4600_Epoch 309 Results: R2 Score: 0.98245538 MAE: 4.33764029 MSE: 36.76600647\n","\n","Epoch 309: loss improved from 42.65352 to 41.98209, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 77ms/step - loss: 41.9821 - mae: 16.6888\n","Epoch 310/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 41.4855 - mae: 17.5471_Epoch 310 Results: R2 Score: 0.98276834 MAE: 4.29746199 MSE: 36.13228607\n","\n","Epoch 310: loss improved from 41.98209 to 41.32178, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 41.3218 - mae: 16.6889\n","Epoch 311/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 40.8334 - mae: 16.8659_Epoch 311 Results: R2 Score: 0.98307544 MAE: 4.25754166 MSE: 35.50929260\n","\n","Epoch 311: loss improved from 41.32178 to 40.67241, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 74ms/step - loss: 40.6724 - mae: 16.6891\n","Epoch 312/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 40.1922 - mae: 16.7230_Epoch 312 Results: R2 Score: 0.98337709 MAE: 4.21808004 MSE: 34.89680862\n","\n","Epoch 312: loss improved from 40.67241 to 40.03389, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 86ms/step - loss: 40.0339 - mae: 16.6892\n","Epoch 313/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 39.5616 - mae: 16.3961_Epoch 313 Results: R2 Score: 0.98367351 MAE: 4.17887449 MSE: 34.29464722\n","\n","Epoch 313: loss improved from 40.03389 to 39.40596, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 39.4060 - mae: 16.6893\n","Epoch 314/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 38.9415 - mae: 16.7523_Epoch 314 Results: R2 Score: 0.98396460 MAE: 4.13996935 MSE: 33.70270538\n","\n","Epoch 314: loss improved from 39.40596 to 38.78841, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 38.7884 - mae: 16.6894\n","Epoch 315/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 38.3317 - mae: 17.2489_Epoch 315 Results: R2 Score: 0.98425063 MAE: 4.10161209 MSE: 33.12068939\n","\n","Epoch 315: loss improved from 38.78841 to 38.18117, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 111ms/step - loss: 38.1812 - mae: 16.6896\n","Epoch 316/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 37.7321 - mae: 16.6821_Epoch 316 Results: R2 Score: 0.98453140 MAE: 4.06352568 MSE: 32.54857254\n","\n","Epoch 316: loss improved from 38.18117 to 37.58408, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 37.5841 - mae: 16.6897\n","Epoch 317/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 37.1425 - mae: 18.6922_Epoch 317 Results: R2 Score: 0.98480692 MAE: 4.02544117 MSE: 31.98631668\n","\n","Epoch 317: loss improved from 37.58408 to 36.99691, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 36.9969 - mae: 16.6898\n","Epoch 318/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 36.5627 - mae: 18.5595_Epoch 318 Results: R2 Score: 0.98507769 MAE: 3.98778009 MSE: 31.43352318\n","\n","Epoch 318: loss improved from 36.99691 to 36.41951, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 36.4195 - mae: 16.6899\n","Epoch 319/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 35.9925 - mae: 16.8235_Epoch 319 Results: R2 Score: 0.98534369 MAE: 3.95035553 MSE: 30.89009476\n","\n","Epoch 319: loss improved from 36.41951 to 35.85176, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 107ms/step - loss: 35.8518 - mae: 16.6900\n","Epoch 320/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 35.4319 - mae: 18.2530_Epoch 320 Results: R2 Score: 0.98560491 MAE: 3.91332579 MSE: 30.35586548\n","\n","Epoch 320: loss improved from 35.85176 to 35.29347, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 35.2935 - mae: 16.6901\n","Epoch 321/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 34.8806 - mae: 15.9003_Epoch 321 Results: R2 Score: 0.98586139 MAE: 3.87639594 MSE: 29.83083534\n","\n","Epoch 321: loss improved from 35.29347 to 34.74448, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 34.7445 - mae: 16.6902\n","Epoch 322/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 34.3385 - mae: 15.5956_Epoch 322 Results: R2 Score: 0.98611302 MAE: 3.83982086 MSE: 29.31469917\n","\n","Epoch 322: loss improved from 34.74448 to 34.20465, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 34.2046 - mae: 16.6903\n","Epoch 323/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 33.8054 - mae: 16.2251_Epoch 323 Results: R2 Score: 0.98636006 MAE: 3.80365753 MSE: 28.80739212\n","\n","Epoch 323: loss improved from 34.20465 to 33.67388, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 33.6739 - mae: 16.6904\n","Epoch 324/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 33.2814 - mae: 17.6223_Epoch 324 Results: R2 Score: 0.98660302 MAE: 3.76773286 MSE: 28.30873871\n","\n","Epoch 324: loss improved from 33.67388 to 33.15203, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 33.1520 - mae: 16.6905\n","Epoch 325/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 32.7661 - mae: 17.3438_Epoch 325 Results: R2 Score: 0.98684160 MAE: 3.73209405 MSE: 27.81869316\n","\n","Epoch 325: loss improved from 33.15203 to 32.63890, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 32.6389 - mae: 16.6906\n","Epoch 326/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 32.2595 - mae: 15.9513_Epoch 326 Results: R2 Score: 0.98707557 MAE: 3.69681239 MSE: 27.33699417\n","\n","Epoch 326: loss improved from 32.63890 to 32.13444, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 32.1344 - mae: 16.6907\n","Epoch 327/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 31.7614 - mae: 14.8825_Epoch 327 Results: R2 Score: 0.98730519 MAE: 3.66194439 MSE: 26.86351967\n","\n","Epoch 327: loss improved from 32.13444 to 31.63849, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 31.6385 - mae: 16.6908\n","Epoch 328/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 31.2718 - mae: 15.4860_Epoch 328 Results: R2 Score: 0.98753089 MAE: 3.62734103 MSE: 26.39827919\n","\n","Epoch 328: loss improved from 31.63849 to 31.15094, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 31.1509 - mae: 16.6908\n","Epoch 329/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 30.7904 - mae: 16.0867_Epoch 329 Results: R2 Score: 0.98775257 MAE: 3.59296083 MSE: 25.94107056\n","\n","Epoch 329: loss improved from 31.15094 to 30.67162, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 30.6716 - mae: 16.6909\n","Epoch 330/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 30.3172 - mae: 16.8061_Epoch 330 Results: R2 Score: 0.98797023 MAE: 3.55902219 MSE: 25.49165154\n","\n","Epoch 330: loss improved from 30.67162 to 30.20038, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 30.2004 - mae: 16.6910\n","Epoch 331/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 29.8519 - mae: 18.4178_Epoch 331 Results: R2 Score: 0.98818393 MAE: 3.52551126 MSE: 25.04999161\n","\n","Epoch 331: loss improved from 30.20038 to 29.73710, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 29.7371 - mae: 16.6910\n","Epoch 332/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 29.3946 - mae: 17.2613_Epoch 332 Results: R2 Score: 0.98839359 MAE: 3.49225926 MSE: 24.61591339\n","\n","Epoch 332: loss improved from 29.73710 to 29.28169, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 29.2817 - mae: 16.6911\n","Epoch 333/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 28.9449 - mae: 15.0676_Epoch 333 Results: R2 Score: 0.98859960 MAE: 3.45925331 MSE: 24.18925095\n","\n","Epoch 333: loss improved from 29.28169 to 28.83394, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 28.8339 - mae: 16.6912\n","Epoch 334/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 28.5028 - mae: 17.9870_Epoch 334 Results: R2 Score: 0.98880194 MAE: 3.42647576 MSE: 23.76997375\n","\n","Epoch 334: loss improved from 28.83394 to 28.39371, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 28.3937 - mae: 16.6912\n","Epoch 335/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 28.0682 - mae: 15.6575_Epoch 335 Results: R2 Score: 0.98900065 MAE: 3.39389634 MSE: 23.35797691\n","\n","Epoch 335: loss improved from 28.39371 to 27.96097, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 27.9610 - mae: 16.6913\n","Epoch 336/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 27.6410 - mae: 18.5700_Epoch 336 Results: R2 Score: 0.98919557 MAE: 3.36160898 MSE: 22.95305443\n","\n","Epoch 336: loss improved from 27.96097 to 27.53552, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 27.5355 - mae: 16.6913\n","Epoch 337/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 27.2209 - mae: 17.4991_Epoch 337 Results: R2 Score: 0.98938715 MAE: 3.32957530 MSE: 22.55517960\n","\n","Epoch 337: loss improved from 27.53552 to 27.11726, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 72ms/step - loss: 27.1173 - mae: 16.6914\n","Epoch 338/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 26.8080 - mae: 16.6334_Epoch 338 Results: R2 Score: 0.98957519 MAE: 3.29753375 MSE: 22.16429710\n","\n","Epoch 338: loss improved from 27.11726 to 26.70608, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 26.7061 - mae: 16.6914\n","Epoch 339/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 26.4020 - mae: 16.7592_Epoch 339 Results: R2 Score: 0.98975967 MAE: 3.26594806 MSE: 21.78017807\n","\n","Epoch 339: loss improved from 26.70608 to 26.30180, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 111ms/step - loss: 26.3018 - mae: 16.6915\n","Epoch 340/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 26.0030 - mae: 15.7378_Epoch 340 Results: R2 Score: 0.98994095 MAE: 3.23484945 MSE: 21.40258026\n","\n","Epoch 340: loss improved from 26.30180 to 25.90447, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 95ms/step - loss: 25.9045 - mae: 16.6915\n","Epoch 341/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 25.6107 - mae: 16.5569_Epoch 341 Results: R2 Score: 0.99011919 MAE: 3.20398712 MSE: 21.03154945\n","\n","Epoch 341: loss improved from 25.90447 to 25.51385, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 25.5138 - mae: 16.6916\n","Epoch 342/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 25.2250 - mae: 16.7981_Epoch 342 Results: R2 Score: 0.99029411 MAE: 3.17329860 MSE: 20.66707420\n","\n","Epoch 342: loss improved from 25.51385 to 25.12989, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 73ms/step - loss: 25.1299 - mae: 16.6916\n","Epoch 343/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 24.8460 - mae: 17.4370_Epoch 343 Results: R2 Score: 0.99046588 MAE: 3.14303899 MSE: 20.30884361\n","\n","Epoch 343: loss improved from 25.12989 to 24.75251, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 24.7525 - mae: 16.6916\n","Epoch 344/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 24.4735 - mae: 17.8238_Epoch 344 Results: R2 Score: 0.99063451 MAE: 3.11313581 MSE: 19.95683098\n","\n","Epoch 344: loss improved from 24.75251 to 24.38156, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 24.3816 - mae: 16.6917\n","Epoch 345/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 24.1074 - mae: 16.2659_Epoch 345 Results: R2 Score: 0.99080025 MAE: 3.08346248 MSE: 19.61092377\n","\n","Epoch 345: loss improved from 24.38156 to 24.01700, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 24.0170 - mae: 16.6917\n","Epoch 346/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 23.7474 - mae: 17.8609_Epoch 346 Results: R2 Score: 0.99096308 MAE: 3.05411863 MSE: 19.27106094\n","\n","Epoch 346: loss improved from 24.01700 to 23.65860, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 73ms/step - loss: 23.6586 - mae: 16.6918\n","Epoch 347/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 23.3937 - mae: 16.7730_Epoch 347 Results: R2 Score: 0.99112294 MAE: 3.02502608 MSE: 18.93720436\n","\n","Epoch 347: loss improved from 23.65860 to 23.30637, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 51ms/step - loss: 23.3064 - mae: 16.6918\n","Epoch 348/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 23.0460 - mae: 17.4566_Epoch 348 Results: R2 Score: 0.99127972 MAE: 2.99609613 MSE: 18.60922623\n","\n","Epoch 348: loss improved from 23.30637 to 22.96014, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 104ms/step - loss: 22.9601 - mae: 16.6918\n","Epoch 349/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 22.7042 - mae: 16.7398_Epoch 349 Results: R2 Score: 0.99143365 MAE: 2.96749640 MSE: 18.28687477\n","\n","Epoch 349: loss improved from 22.96014 to 22.61983, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 101ms/step - loss: 22.6198 - mae: 16.6918\n","Epoch 350/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 22.3682 - mae: 17.9304_Epoch 350 Results: R2 Score: 0.99158502 MAE: 2.93920875 MSE: 17.97011375\n","\n","Epoch 350: loss improved from 22.61983 to 22.28532, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 22.2853 - mae: 16.6919\n","Epoch 351/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 22.0380 - mae: 14.4439_Epoch 351 Results: R2 Score: 0.99173350 MAE: 2.91128135 MSE: 17.65889168\n","\n","Epoch 351: loss improved from 22.28532 to 21.95650, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 76ms/step - loss: 21.9565 - mae: 16.6919\n","Epoch 352/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 21.7134 - mae: 16.5290_Epoch 352 Results: R2 Score: 0.99187929 MAE: 2.88371015 MSE: 17.35301781\n","\n","Epoch 352: loss improved from 21.95650 to 21.63333, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 71ms/step - loss: 21.6333 - mae: 16.6919\n","Epoch 353/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 21.3944 - mae: 16.3041_Epoch 353 Results: R2 Score: 0.99202256 MAE: 2.85618424 MSE: 17.05254936\n","\n","Epoch 353: loss improved from 21.63333 to 21.31564, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 21.3156 - mae: 16.6919\n","Epoch 354/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 21.0808 - mae: 18.5684_Epoch 354 Results: R2 Score: 0.99216309 MAE: 2.82861423 MSE: 16.75743675\n","\n","Epoch 354: loss improved from 21.31564 to 21.00337, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 21.0034 - mae: 16.6920\n","Epoch 355/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 20.7725 - mae: 16.3872_Epoch 355 Results: R2 Score: 0.99230109 MAE: 2.80122805 MSE: 16.46746635\n","\n","Epoch 355: loss improved from 21.00337 to 20.69637, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 108ms/step - loss: 20.6964 - mae: 16.6920\n","Epoch 356/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 20.4694 - mae: 17.6403_Epoch 356 Results: R2 Score: 0.99243662 MAE: 2.77433491 MSE: 16.18252373\n","\n","Epoch 356: loss improved from 20.69637 to 20.39461, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 20.3946 - mae: 16.6920\n","Epoch 357/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 20.1715 - mae: 16.8630_Epoch 357 Results: R2 Score: 0.99256959 MAE: 2.74774504 MSE: 15.90255070\n","\n","Epoch 357: loss improved from 20.39461 to 20.09799, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 20.0980 - mae: 16.6920\n","Epoch 358/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 19.8787 - mae: 16.4006_Epoch 358 Results: R2 Score: 0.99270028 MAE: 2.72116494 MSE: 15.62753296\n","\n","Epoch 358: loss improved from 20.09799 to 19.80645, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 19.8064 - mae: 16.6920\n","Epoch 359/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 19.5909 - mae: 16.0849_Epoch 359 Results: R2 Score: 0.99282851 MAE: 2.69500422 MSE: 15.35729027\n","\n","Epoch 359: loss improved from 19.80645 to 19.51985, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 73ms/step - loss: 19.5199 - mae: 16.6920\n","Epoch 360/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 19.3080 - mae: 18.2690_Epoch 360 Results: R2 Score: 0.99295439 MAE: 2.66893482 MSE: 15.09181881\n","\n","Epoch 360: loss improved from 19.51985 to 19.23819, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 19.2382 - mae: 16.6920\n","Epoch 361/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 19.0299 - mae: 17.5828_Epoch 361 Results: R2 Score: 0.99307811 MAE: 2.64307117 MSE: 14.83095551\n","\n","Epoch 361: loss improved from 19.23819 to 18.96130, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 98ms/step - loss: 18.9613 - mae: 16.6920\n","Epoch 362/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 18.7566 - mae: 17.6225_Epoch 362 Results: R2 Score: 0.99319971 MAE: 2.61741924 MSE: 14.57474422\n","\n","Epoch 362: loss improved from 18.96130 to 18.68912, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 49ms/step - loss: 18.6891 - mae: 16.6919\n","Epoch 363/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 18.4879 - mae: 16.4619_Epoch 363 Results: R2 Score: 0.99331898 MAE: 2.59227443 MSE: 14.32286072\n","\n","Epoch 363: loss improved from 18.68912 to 18.42161, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 97ms/step - loss: 18.4216 - mae: 16.6919\n","Epoch 364/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 18.2238 - mae: 18.2309_Epoch 364 Results: R2 Score: 0.99343596 MAE: 2.56743026 MSE: 14.07542896\n","\n","Epoch 364: loss improved from 18.42161 to 18.15867, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 104ms/step - loss: 18.1587 - mae: 16.6919\n","Epoch 365/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 17.9643 - mae: 17.2666_Epoch 365 Results: R2 Score: 0.99355097 MAE: 2.54246926 MSE: 13.83244324\n","\n","Epoch 365: loss improved from 18.15867 to 17.90023, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 17.9002 - mae: 16.6919\n","Epoch 366/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 17.7091 - mae: 15.3382_Epoch 366 Results: R2 Score: 0.99366387 MAE: 2.51765347 MSE: 13.59376240\n","\n","Epoch 366: loss improved from 17.90023 to 17.64618, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 17.6462 - mae: 16.6919\n","Epoch 367/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 17.4584 - mae: 15.5996_Epoch 367 Results: R2 Score: 0.99377486 MAE: 2.49322581 MSE: 13.35920715\n","\n","Epoch 367: loss improved from 17.64618 to 17.39649, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 17.3965 - mae: 16.6919\n","Epoch 368/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 17.2119 - mae: 16.0420_Epoch 368 Results: R2 Score: 0.99388391 MAE: 2.46898723 MSE: 13.12878895\n","\n","Epoch 368: loss improved from 17.39649 to 17.15104, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 17.1510 - mae: 16.6918\n","Epoch 369/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 16.9696 - mae: 15.1725_Epoch 369 Results: R2 Score: 0.99399090 MAE: 2.44490838 MSE: 12.90245724\n","\n","Epoch 369: loss improved from 17.15104 to 16.90978, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 106ms/step - loss: 16.9098 - mae: 16.6918\n","Epoch 370/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 16.7314 - mae: 16.0859_Epoch 370 Results: R2 Score: 0.99409596 MAE: 2.42094636 MSE: 12.68012524\n","\n","Epoch 370: loss improved from 16.90978 to 16.67266, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 113ms/step - loss: 16.6727 - mae: 16.6918\n","Epoch 371/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 16.4973 - mae: 17.6642_Epoch 371 Results: R2 Score: 0.99419909 MAE: 2.39741206 MSE: 12.46158791\n","\n","Epoch 371: loss improved from 16.67266 to 16.43953, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 16.4395 - mae: 16.6917\n","Epoch 372/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 16.2672 - mae: 16.2115_Epoch 372 Results: R2 Score: 0.99430056 MAE: 2.37415838 MSE: 12.24673080\n","\n","Epoch 372: loss improved from 16.43953 to 16.21045, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 16.2105 - mae: 16.6917\n","Epoch 373/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 16.0410 - mae: 18.9339_Epoch 373 Results: R2 Score: 0.99440019 MAE: 2.35108423 MSE: 12.03579140\n","\n","Epoch 373: loss improved from 16.21045 to 15.98521, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 15.9852 - mae: 16.6917\n","Epoch 374/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 15.8187 - mae: 17.6287_Epoch 374 Results: R2 Score: 0.99449794 MAE: 2.32817698 MSE: 11.82852650\n","\n","Epoch 374: loss improved from 15.98521 to 15.76385, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 15.7638 - mae: 16.6917\n","Epoch 375/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 15.6002 - mae: 17.8542_Epoch 375 Results: R2 Score: 0.99459373 MAE: 2.30525041 MSE: 11.62498951\n","\n","Epoch 375: loss improved from 15.76385 to 15.54627, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 15.5463 - mae: 16.6917\n","Epoch 376/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 15.3854 - mae: 17.4427_Epoch 376 Results: R2 Score: 0.99468796 MAE: 2.28253913 MSE: 11.42503166\n","\n","Epoch 376: loss improved from 15.54627 to 15.33235, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 15.3323 - mae: 16.6916\n","Epoch 377/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 15.1742 - mae: 16.0743_Epoch 377 Results: R2 Score: 0.99478057 MAE: 2.26030660 MSE: 11.22840977\n","\n","Epoch 377: loss improved from 15.33235 to 15.12212, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 15.1221 - mae: 16.6916\n","Epoch 378/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 14.9667 - mae: 18.2757_Epoch 378 Results: R2 Score: 0.99487154 MAE: 2.23815513 MSE: 11.03538227\n","\n","Epoch 378: loss improved from 15.12212 to 14.91545, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 14.9155 - mae: 16.6915\n","Epoch 379/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 14.7627 - mae: 17.4821_Epoch 379 Results: R2 Score: 0.99496091 MAE: 2.21609688 MSE: 10.84579468\n","\n","Epoch 379: loss improved from 14.91545 to 14.71233, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 14.7123 - mae: 16.6915\n","Epoch 380/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 14.5622 - mae: 16.2236_Epoch 380 Results: R2 Score: 0.99504844 MAE: 2.19430757 MSE: 10.65948391\n","\n","Epoch 380: loss improved from 14.71233 to 14.51270, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 14.5127 - mae: 16.6915\n","Epoch 381/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 14.3651 - mae: 16.7514_Epoch 381 Results: R2 Score: 0.99513445 MAE: 2.17274022 MSE: 10.47646141\n","\n","Epoch 381: loss improved from 14.51270 to 14.31646, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 104ms/step - loss: 14.3165 - mae: 16.6914\n","Epoch 382/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 14.1714 - mae: 16.6272_Epoch 382 Results: R2 Score: 0.99521903 MAE: 2.15141559 MSE: 10.29663372\n","\n","Epoch 382: loss improved from 14.31646 to 14.12355, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 14.1235 - mae: 16.6914\n","Epoch 383/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 13.9809 - mae: 17.6159_Epoch 383 Results: R2 Score: 0.99530202 MAE: 2.13020039 MSE: 10.11997414\n","\n","Epoch 383: loss improved from 14.12355 to 13.93393, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 13.9339 - mae: 16.6913\n","Epoch 384/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 13.7937 - mae: 15.8072_Epoch 384 Results: R2 Score: 0.99538360 MAE: 2.10942459 MSE: 9.94638443\n","\n","Epoch 384: loss improved from 13.93393 to 13.74754, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 13.7475 - mae: 16.6913\n","Epoch 385/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 13.6098 - mae: 16.8343_Epoch 385 Results: R2 Score: 0.99546358 MAE: 2.08879924 MSE: 9.77583408\n","\n","Epoch 385: loss improved from 13.74754 to 13.56436, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 13.5644 - mae: 16.6913\n","Epoch 386/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 13.4289 - mae: 17.2344_Epoch 386 Results: R2 Score: 0.99554210 MAE: 2.06832361 MSE: 9.60832691\n","\n","Epoch 386: loss improved from 13.56436 to 13.38430, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 72ms/step - loss: 13.3843 - mae: 16.6912\n","Epoch 387/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 13.2512 - mae: 15.9423_Epoch 387 Results: R2 Score: 0.99561927 MAE: 2.04807949 MSE: 9.44384956\n","\n","Epoch 387: loss improved from 13.38430 to 13.20728, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 13.2073 - mae: 16.6911\n","Epoch 388/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 13.0765 - mae: 17.9513_Epoch 388 Results: R2 Score: 0.99569513 MAE: 2.02821040 MSE: 9.28210926\n","\n","Epoch 388: loss improved from 13.20728 to 13.03339, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 51ms/step - loss: 13.0334 - mae: 16.6911\n","Epoch 389/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 12.9047 - mae: 15.1033_Epoch 389 Results: R2 Score: 0.99576956 MAE: 2.00832272 MSE: 9.12335300\n","\n","Epoch 389: loss improved from 13.03339 to 12.86236, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 12.8624 - mae: 16.6910\n","Epoch 390/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 12.7360 - mae: 16.0063_Epoch 390 Results: R2 Score: 0.99584259 MAE: 1.98852980 MSE: 8.96732044\n","\n","Epoch 390: loss improved from 12.86236 to 12.69431, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 121ms/step - loss: 12.6943 - mae: 16.6910\n","Epoch 391/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 12.5700 - mae: 16.0878_Epoch 391 Results: R2 Score: 0.99591425 MAE: 1.96914494 MSE: 8.81407738\n","\n","Epoch 391: loss improved from 12.69431 to 12.52905, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 12.5290 - mae: 16.6909\n","Epoch 392/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 12.4069 - mae: 15.5354_Epoch 392 Results: R2 Score: 0.99598460 MAE: 1.94991887 MSE: 8.66346359\n","\n","Epoch 392: loss improved from 12.52905 to 12.36665, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 12.3666 - mae: 16.6908\n","Epoch 393/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 12.2465 - mae: 17.8640_Epoch 393 Results: R2 Score: 0.99605385 MAE: 1.93069994 MSE: 8.51563072\n","\n","Epoch 393: loss improved from 12.36665 to 12.20695, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 12.2070 - mae: 16.6908\n","Epoch 394/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 12.0889 - mae: 18.2108_Epoch 394 Results: R2 Score: 0.99612183 MAE: 1.91146255 MSE: 8.37041759\n","\n","Epoch 394: loss improved from 12.20695 to 12.05003, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 12.0500 - mae: 16.6907\n","Epoch 395/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 11.9339 - mae: 15.2298_Epoch 395 Results: R2 Score: 0.99618854 MAE: 1.89301014 MSE: 8.22753143\n","\n","Epoch 395: loss improved from 12.05003 to 11.89565, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 107ms/step - loss: 11.8957 - mae: 16.6906\n","Epoch 396/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 11.7816 - mae: 15.9395_Epoch 396 Results: R2 Score: 0.99625417 MAE: 1.87434208 MSE: 8.08727074\n","\n","Epoch 396: loss improved from 11.89565 to 11.74401, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 104ms/step - loss: 11.7440 - mae: 16.6905\n","Epoch 397/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 11.6318 - mae: 16.7400_Epoch 397 Results: R2 Score: 0.99631865 MAE: 1.85580325 MSE: 7.94954157\n","\n","Epoch 397: loss improved from 11.74401 to 11.59481, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 11.5948 - mae: 16.6905\n","Epoch 398/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 11.4845 - mae: 15.4439_Epoch 398 Results: R2 Score: 0.99638187 MAE: 1.83752000 MSE: 7.81417274\n","\n","Epoch 398: loss improved from 11.59481 to 11.44817, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 11.4482 - mae: 16.6904\n","Epoch 399/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 11.3398 - mae: 15.4386_Epoch 399 Results: R2 Score: 0.99644397 MAE: 1.81918371 MSE: 7.68124723\n","\n","Epoch 399: loss improved from 11.44817 to 11.30402, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 11.3040 - mae: 16.6903\n","Epoch 400/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 11.1974 - mae: 16.7548_Epoch 400 Results: R2 Score: 0.99650504 MAE: 1.80123568 MSE: 7.55057478\n","\n","Epoch 400: loss improved from 11.30402 to 11.16227, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 51ms/step - loss: 11.1623 - mae: 16.6902\n","Epoch 401/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 11.0575 - mae: 16.7983_Epoch 401 Results: R2 Score: 0.99656505 MAE: 1.78341067 MSE: 7.42211866\n","\n","Epoch 401: loss improved from 11.16227 to 11.02293, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 88ms/step - loss: 11.0229 - mae: 16.6901\n","Epoch 402/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 10.9199 - mae: 19.1998_Epoch 402 Results: R2 Score: 0.99662402 MAE: 1.76569462 MSE: 7.29590750\n","\n","Epoch 402: loss improved from 11.02293 to 10.88589, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 39ms/step - loss: 10.8859 - mae: 16.6901\n","Epoch 403/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 10.7845 - mae: 15.7564_Epoch 403 Results: R2 Score: 0.99668188 MAE: 1.74843657 MSE: 7.17186022\n","\n","Epoch 403: loss improved from 10.88589 to 10.75114, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 10.7511 - mae: 16.6900\n","Epoch 404/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 10.6515 - mae: 16.3011_Epoch 404 Results: R2 Score: 0.99673874 MAE: 1.73116910 MSE: 7.05000925\n","\n","Epoch 404: loss improved from 10.75114 to 10.61871, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 10.6187 - mae: 16.6899\n","Epoch 405/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 10.5208 - mae: 15.9567_Epoch 405 Results: R2 Score: 0.99679453 MAE: 1.71372783 MSE: 6.93041515\n","\n","Epoch 405: loss improved from 10.61871 to 10.48847, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 121ms/step - loss: 10.4885 - mae: 16.6898\n","Epoch 406/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 10.3922 - mae: 15.5492_Epoch 406 Results: R2 Score: 0.99684945 MAE: 1.69664133 MSE: 6.81280851\n","\n","Epoch 406: loss improved from 10.48847 to 10.36040, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 10.3604 - mae: 16.6897\n","Epoch 407/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 10.2657 - mae: 16.5330_Epoch 407 Results: R2 Score: 0.99690329 MAE: 1.67967367 MSE: 6.69729280\n","\n","Epoch 407: loss improved from 10.36040 to 10.23448, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 10.2345 - mae: 16.6896\n","Epoch 408/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 10.1413 - mae: 16.3803_Epoch 408 Results: R2 Score: 0.99695624 MAE: 1.66300583 MSE: 6.58378553\n","\n","Epoch 408: loss improved from 10.23448 to 10.11066, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 10.1107 - mae: 16.6895\n","Epoch 409/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 10.0191 - mae: 15.3148_Epoch 409 Results: R2 Score: 0.99700826 MAE: 1.64626491 MSE: 6.47229624\n","\n","Epoch 409: loss improved from 10.11066 to 9.98893, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 107ms/step - loss: 9.9889 - mae: 16.6894\n","Epoch 410/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.8989 - mae: 16.6814_Epoch 410 Results: R2 Score: 0.99705931 MAE: 1.62993038 MSE: 6.36269045\n","\n","Epoch 410: loss improved from 9.98893 to 9.86920, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 9.8692 - mae: 16.6894\n","Epoch 411/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.7807 - mae: 16.0709_Epoch 411 Results: R2 Score: 0.99710948 MAE: 1.61379981 MSE: 6.25482178\n","\n","Epoch 411: loss improved from 9.86920 to 9.75152, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 9.7515 - mae: 16.6893\n","Epoch 412/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.6644 - mae: 16.1444_Epoch 412 Results: R2 Score: 0.99715888 MAE: 1.59800148 MSE: 6.14881945\n","\n","Epoch 412: loss improved from 9.75152 to 9.63578, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 9.6358 - mae: 16.6892\n","Epoch 413/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.5502 - mae: 16.8047_Epoch 413 Results: R2 Score: 0.99720728 MAE: 1.58188689 MSE: 6.04493093\n","\n","Epoch 413: loss improved from 9.63578 to 9.52199, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 9.5220 - mae: 16.6891\n","Epoch 414/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.4379 - mae: 17.4943_Epoch 414 Results: R2 Score: 0.99725484 MAE: 1.56600153 MSE: 5.94273281\n","\n","Epoch 414: loss improved from 9.52199 to 9.41010, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 9.4101 - mae: 16.6890\n","Epoch 415/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.3273 - mae: 16.6448_Epoch 415 Results: R2 Score: 0.99730153 MAE: 1.55027032 MSE: 5.84236813\n","\n","Epoch 415: loss improved from 9.41010 to 9.30000, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 123ms/step - loss: 9.3000 - mae: 16.6889\n","Epoch 416/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.2186 - mae: 15.7775_Epoch 416 Results: R2 Score: 0.99734736 MAE: 1.53461170 MSE: 5.74377346\n","\n","Epoch 416: loss improved from 9.30000 to 9.19179, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 9.1918 - mae: 16.6888\n","Epoch 417/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.1117 - mae: 17.3597_Epoch 417 Results: R2 Score: 0.99739244 MAE: 1.51936221 MSE: 5.64677143\n","\n","Epoch 417: loss improved from 9.19179 to 9.08533, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 9.0853 - mae: 16.6887\n","Epoch 418/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 9.0066 - mae: 16.1303_Epoch 418 Results: R2 Score: 0.99743675 MAE: 1.50437486 MSE: 5.55152988\n","\n","Epoch 418: loss improved from 9.08533 to 8.98068, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 114ms/step - loss: 8.9807 - mae: 16.6886\n","Epoch 419/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.9034 - mae: 17.5671_Epoch 419 Results: R2 Score: 0.99748026 MAE: 1.48916221 MSE: 5.45790434\n","\n","Epoch 419: loss improved from 8.98068 to 8.87780, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 8.8778 - mae: 16.6885\n","Epoch 420/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.8017 - mae: 16.7600_Epoch 420 Results: R2 Score: 0.99752307 MAE: 1.47405446 MSE: 5.36588621\n","\n","Epoch 420: loss improved from 8.87780 to 8.77659, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 8.7766 - mae: 16.6884\n","Epoch 421/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.7017 - mae: 17.1552_Epoch 421 Results: R2 Score: 0.99756506 MAE: 1.45929825 MSE: 5.27555418\n","\n","Epoch 421: loss improved from 8.77659 to 8.67700, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 88ms/step - loss: 8.6770 - mae: 16.6883\n","Epoch 422/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.6034 - mae: 17.1706_Epoch 422 Results: R2 Score: 0.99760629 MAE: 1.44457197 MSE: 5.18675280\n","\n","Epoch 422: loss improved from 8.67700 to 8.57915, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 8.5791 - mae: 16.6881\n","Epoch 423/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.5068 - mae: 15.9646_Epoch 423 Results: R2 Score: 0.99764688 MAE: 1.43009245 MSE: 5.09935474\n","\n","Epoch 423: loss improved from 8.57915 to 8.48288, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 50ms/step - loss: 8.4829 - mae: 16.6880\n","Epoch 424/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.4116 - mae: 15.6783_Epoch 424 Results: R2 Score: 0.99768670 MAE: 1.41556013 MSE: 5.01363182\n","\n","Epoch 424: loss improved from 8.48288 to 8.38818, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 8.3882 - mae: 16.6879\n","Epoch 425/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.3182 - mae: 14.8626_Epoch 425 Results: R2 Score: 0.99772588 MAE: 1.40136313 MSE: 4.92930269\n","\n","Epoch 425: loss improved from 8.38818 to 8.29508, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 81ms/step - loss: 8.2951 - mae: 16.6878\n","Epoch 426/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.2262 - mae: 16.6781_Epoch 426 Results: R2 Score: 0.99776427 MAE: 1.38721061 MSE: 4.84653282\n","\n","Epoch 426: loss improved from 8.29508 to 8.20346, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 8.2035 - mae: 16.6877\n","Epoch 427/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.1358 - mae: 15.7677_Epoch 427 Results: R2 Score: 0.99780208 MAE: 1.37334836 MSE: 4.76508379\n","\n","Epoch 427: loss improved from 8.20346 to 8.11344, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 8.1134 - mae: 16.6876\n","Epoch 428/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 8.0468 - mae: 18.9337_Epoch 428 Results: R2 Score: 0.99783915 MAE: 1.35925364 MSE: 4.68515682\n","\n","Epoch 428: loss improved from 8.11344 to 8.02484, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 8.0248 - mae: 16.6875\n","Epoch 429/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.9593 - mae: 16.7862_Epoch 429 Results: R2 Score: 0.99787572 MAE: 1.34569502 MSE: 4.60637522\n","\n","Epoch 429: loss improved from 8.02484 to 7.93770, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 44ms/step - loss: 7.9377 - mae: 16.6874\n","Epoch 430/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.8733 - mae: 16.0469_Epoch 430 Results: R2 Score: 0.99791163 MAE: 1.33222759 MSE: 4.52907085\n","\n","Epoch 430: loss improved from 7.93770 to 7.85204, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 77ms/step - loss: 7.8520 - mae: 16.6873\n","Epoch 431/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.7887 - mae: 16.4808_Epoch 431 Results: R2 Score: 0.99794682 MAE: 1.31859004 MSE: 4.45324087\n","\n","Epoch 431: loss improved from 7.85204 to 7.76774, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 108ms/step - loss: 7.7677 - mae: 16.6872\n","Epoch 432/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.7054 - mae: 14.2391_Epoch 432 Results: R2 Score: 0.99798130 MAE: 1.30512834 MSE: 4.37873602\n","\n","Epoch 432: loss improved from 7.76774 to 7.68490, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 7.6849 - mae: 16.6870\n","Epoch 433/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.6235 - mae: 16.7656_Epoch 433 Results: R2 Score: 0.99801534 MAE: 1.29198372 MSE: 4.30539799\n","\n","Epoch 433: loss improved from 7.68490 to 7.60332, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 101ms/step - loss: 7.6033 - mae: 16.6869\n","Epoch 434/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.5430 - mae: 14.5361_Epoch 434 Results: R2 Score: 0.99804875 MAE: 1.27851045 MSE: 4.23343611\n","\n","Epoch 434: loss improved from 7.60332 to 7.52314, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 7.5231 - mae: 16.6868\n","Epoch 435/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.4638 - mae: 17.0956_Epoch 435 Results: R2 Score: 0.99808159 MAE: 1.26597857 MSE: 4.16242790\n","\n","Epoch 435: loss improved from 7.52314 to 7.44425, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 7.4443 - mae: 16.6867\n","Epoch 436/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.3860 - mae: 17.9736_Epoch 436 Results: R2 Score: 0.99811390 MAE: 1.25294507 MSE: 4.09285307\n","\n","Epoch 436: loss improved from 7.44425 to 7.36668, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 7.3667 - mae: 16.6866\n","Epoch 437/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.3093 - mae: 16.6022_Epoch 437 Results: R2 Score: 0.99814559 MAE: 1.24002659 MSE: 4.02446938\n","\n","Epoch 437: loss improved from 7.36668 to 7.29033, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 7.2903 - mae: 16.6865\n","Epoch 438/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.2338 - mae: 15.8730_Epoch 438 Results: R2 Score: 0.99817664 MAE: 1.22742891 MSE: 3.95738769\n","\n","Epoch 438: loss improved from 7.29033 to 7.21522, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 7.2152 - mae: 16.6863\n","Epoch 439/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.1598 - mae: 15.8340_Epoch 439 Results: R2 Score: 0.99820724 MAE: 1.21459055 MSE: 3.89141726\n","\n","Epoch 439: loss improved from 7.21522 to 7.14142, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 7.1414 - mae: 16.6862\n","Epoch 440/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.0867 - mae: 16.1285_Epoch 440 Results: R2 Score: 0.99823746 MAE: 1.20266891 MSE: 3.82620788\n","\n","Epoch 440: loss improved from 7.14142 to 7.06873, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 77ms/step - loss: 7.0687 - mae: 16.6861\n","Epoch 441/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 7.0150 - mae: 17.1620_Epoch 441 Results: R2 Score: 0.99826702 MAE: 1.19029200 MSE: 3.76235223\n","\n","Epoch 441: loss improved from 7.06873 to 6.99727, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 6.9973 - mae: 16.6860\n","Epoch 442/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.9443 - mae: 17.0137_Epoch 442 Results: R2 Score: 0.99829596 MAE: 1.17786837 MSE: 3.69987154\n","\n","Epoch 442: loss improved from 6.99727 to 6.92691, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 6.9269 - mae: 16.6859\n","Epoch 443/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.8749 - mae: 15.6626_Epoch 443 Results: R2 Score: 0.99832458 MAE: 1.16572845 MSE: 3.63809729\n","\n","Epoch 443: loss improved from 6.92691 to 6.85776, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 6.8578 - mae: 16.6857\n","Epoch 444/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.8065 - mae: 17.0803_Epoch 444 Results: R2 Score: 0.99835275 MAE: 1.15447295 MSE: 3.57727504\n","\n","Epoch 444: loss improved from 6.85776 to 6.78963, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 6.7896 - mae: 16.6856\n","Epoch 445/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.7394 - mae: 18.5305_Epoch 445 Results: R2 Score: 0.99838020 MAE: 1.14232624 MSE: 3.51782155\n","\n","Epoch 445: loss improved from 6.78963 to 6.72271, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 6.7227 - mae: 16.6855\n","Epoch 446/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.6731 - mae: 16.9102_Epoch 446 Results: R2 Score: 0.99840724 MAE: 1.13026893 MSE: 3.45940304\n","\n","Epoch 446: loss improved from 6.72271 to 6.65682, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 6.6568 - mae: 16.6854\n","Epoch 447/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.6080 - mae: 15.9982_Epoch 447 Results: R2 Score: 0.99843400 MAE: 1.11893582 MSE: 3.40163779\n","\n","Epoch 447: loss improved from 6.65682 to 6.59195, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 81ms/step - loss: 6.5920 - mae: 16.6853\n","Epoch 448/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.5439 - mae: 15.8544_Epoch 448 Results: R2 Score: 0.99846020 MAE: 1.10760379 MSE: 3.34500790\n","\n","Epoch 448: loss improved from 6.59195 to 6.52811, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 6.5281 - mae: 16.6852\n","Epoch 449/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.4809 - mae: 18.6929_Epoch 449 Results: R2 Score: 0.99848586 MAE: 1.09599626 MSE: 3.28952217\n","\n","Epoch 449: loss improved from 6.52811 to 6.46532, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 81ms/step - loss: 6.4653 - mae: 16.6850\n","Epoch 450/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.4189 - mae: 18.2108_Epoch 450 Results: R2 Score: 0.99851127 MAE: 1.08507073 MSE: 3.23458886\n","\n","Epoch 450: loss improved from 6.46532 to 6.40356, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 74ms/step - loss: 6.4036 - mae: 16.6849\n","Epoch 451/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.3578 - mae: 18.4072_Epoch 451 Results: R2 Score: 0.99853607 MAE: 1.07381845 MSE: 3.18084455\n","\n","Epoch 451: loss improved from 6.40356 to 6.34276, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 6.3428 - mae: 16.6848\n","Epoch 452/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.2977 - mae: 16.4736_Epoch 452 Results: R2 Score: 0.99856055 MAE: 1.06280398 MSE: 3.12802196\n","\n","Epoch 452: loss improved from 6.34276 to 6.28291, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 6.2829 - mae: 16.6847\n","Epoch 453/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.2387 - mae: 17.4450_Epoch 453 Results: R2 Score: 0.99858466 MAE: 1.05199456 MSE: 3.07584333\n","\n","Epoch 453: loss improved from 6.28291 to 6.22409, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 6.2241 - mae: 16.6845\n","Epoch 454/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.1804 - mae: 16.9339_Epoch 454 Results: R2 Score: 0.99860815 MAE: 1.04104805 MSE: 3.02495003\n","\n","Epoch 454: loss improved from 6.22409 to 6.16607, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 104ms/step - loss: 6.1661 - mae: 16.6844\n","Epoch 455/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.1232 - mae: 17.0765_Epoch 455 Results: R2 Score: 0.99863141 MAE: 1.03037250 MSE: 2.97475243\n","\n","Epoch 455: loss improved from 6.16607 to 6.10910, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 6.1091 - mae: 16.6843\n","Epoch 456/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.0669 - mae: 16.6391_Epoch 456 Results: R2 Score: 0.99865421 MAE: 1.01969802 MSE: 2.92539048\n","\n","Epoch 456: loss improved from 6.10910 to 6.05299, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 6.0530 - mae: 16.6841\n","Epoch 457/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 6.0114 - mae: 16.5737_Epoch 457 Results: R2 Score: 0.99867663 MAE: 1.00942600 MSE: 2.87672782\n","\n","Epoch 457: loss improved from 6.05299 to 5.99770, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 5.9977 - mae: 16.6840\n","Epoch 458/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.9568 - mae: 16.6225_Epoch 458 Results: R2 Score: 0.99869870 MAE: 0.99898732 MSE: 2.82896948\n","\n","Epoch 458: loss improved from 5.99770 to 5.94336, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 76ms/step - loss: 5.9434 - mae: 16.6839\n","Epoch 459/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.9031 - mae: 17.2093_Epoch 459 Results: R2 Score: 0.99872034 MAE: 0.98841310 MSE: 2.78218222\n","\n","Epoch 459: loss improved from 5.94336 to 5.88986, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 5.8899 - mae: 16.6837\n","Epoch 460/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.8502 - mae: 17.5221_Epoch 460 Results: R2 Score: 0.99874174 MAE: 0.97891295 MSE: 2.73582315\n","\n","Epoch 460: loss improved from 5.88986 to 5.83723, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 77ms/step - loss: 5.8372 - mae: 16.6836\n","Epoch 461/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.7983 - mae: 15.8100_Epoch 461 Results: R2 Score: 0.99876258 MAE: 0.96862561 MSE: 2.69053030\n","\n","Epoch 461: loss improved from 5.83723 to 5.78548, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 77ms/step - loss: 5.7855 - mae: 16.6834\n","Epoch 462/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.7471 - mae: 16.7163_Epoch 462 Results: R2 Score: 0.99878319 MAE: 0.95857805 MSE: 2.64601350\n","\n","Epoch 462: loss improved from 5.78548 to 5.73448, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 5.7345 - mae: 16.6833\n","Epoch 463/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.6967 - mae: 17.6567_Epoch 463 Results: R2 Score: 0.99880340 MAE: 0.94866294 MSE: 2.60224390\n","\n","Epoch 463: loss improved from 5.73448 to 5.68429, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 5.6843 - mae: 16.6832\n","Epoch 464/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.6471 - mae: 16.4760_Epoch 464 Results: R2 Score: 0.99882337 MAE: 0.93895990 MSE: 2.55899692\n","\n","Epoch 464: loss improved from 5.68429 to 5.63487, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 5.6349 - mae: 16.6830\n","Epoch 465/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.5983 - mae: 17.7707_Epoch 465 Results: R2 Score: 0.99884284 MAE: 0.92902672 MSE: 2.51676059\n","\n","Epoch 465: loss improved from 5.63487 to 5.58620, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 5.5862 - mae: 16.6829\n","Epoch 466/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.5502 - mae: 17.6502_Epoch 466 Results: R2 Score: 0.99886211 MAE: 0.91939008 MSE: 2.47503543\n","\n","Epoch 466: loss improved from 5.58620 to 5.53832, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 86ms/step - loss: 5.5383 - mae: 16.6828\n","Epoch 467/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.5028 - mae: 16.3629_Epoch 467 Results: R2 Score: 0.99888109 MAE: 0.91012460 MSE: 2.43402267\n","\n","Epoch 467: loss improved from 5.53832 to 5.49116, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 5.4912 - mae: 16.6826\n","Epoch 468/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.4563 - mae: 16.7229_Epoch 468 Results: R2 Score: 0.99889962 MAE: 0.90058362 MSE: 2.39376092\n","\n","Epoch 468: loss improved from 5.49116 to 5.44479, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 105ms/step - loss: 5.4448 - mae: 16.6825\n","Epoch 469/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.4105 - mae: 16.2382_Epoch 469 Results: R2 Score: 0.99891785 MAE: 0.89092225 MSE: 2.35425115\n","\n","Epoch 469: loss improved from 5.44479 to 5.39913, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 109ms/step - loss: 5.3991 - mae: 16.6823\n","Epoch 470/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.3653 - mae: 17.8667_Epoch 470 Results: R2 Score: 0.99893574 MAE: 0.88149518 MSE: 2.31546736\n","\n","Epoch 470: loss improved from 5.39913 to 5.35412, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 105ms/step - loss: 5.3541 - mae: 16.6822\n","Epoch 471/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.3209 - mae: 15.5260_Epoch 471 Results: R2 Score: 0.99895337 MAE: 0.87243539 MSE: 2.27713847\n","\n","Epoch 471: loss improved from 5.35412 to 5.30986, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 5.3099 - mae: 16.6821\n","Epoch 472/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.2771 - mae: 16.6377_Epoch 472 Results: R2 Score: 0.99897074 MAE: 0.86323828 MSE: 2.23953414\n","\n","Epoch 472: loss improved from 5.30986 to 5.26636, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 5.2664 - mae: 16.6819\n","Epoch 473/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.2341 - mae: 16.7341_Epoch 473 Results: R2 Score: 0.99898791 MAE: 0.85459268 MSE: 2.20232320\n","\n","Epoch 473: loss improved from 5.26636 to 5.22346, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 5.2235 - mae: 16.6818\n","Epoch 474/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.1917 - mae: 15.4865_Epoch 474 Results: R2 Score: 0.99900465 MAE: 0.84563082 MSE: 2.16603565\n","\n","Epoch 474: loss improved from 5.22346 to 5.18118, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 5.1812 - mae: 16.6816\n","Epoch 475/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.1500 - mae: 16.2430_Epoch 475 Results: R2 Score: 0.99902120 MAE: 0.83710045 MSE: 2.13017726\n","\n","Epoch 475: loss improved from 5.18118 to 5.13974, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 5.1397 - mae: 16.6815\n","Epoch 476/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.1090 - mae: 16.8361_Epoch 476 Results: R2 Score: 0.99903736 MAE: 0.82791388 MSE: 2.09503651\n","\n","Epoch 476: loss improved from 5.13974 to 5.09885, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 5.0988 - mae: 16.6813\n","Epoch 477/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.0684 - mae: 16.5069_Epoch 477 Results: R2 Score: 0.99905331 MAE: 0.81934255 MSE: 2.06039262\n","\n","Epoch 477: loss improved from 5.09885 to 5.05843, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 95ms/step - loss: 5.0584 - mae: 16.6812\n","Epoch 478/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 5.0287 - mae: 17.7272_Epoch 478 Results: R2 Score: 0.99906903 MAE: 0.81072527 MSE: 2.02636313\n","\n","Epoch 478: loss improved from 5.05843 to 5.01885, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 102ms/step - loss: 5.0189 - mae: 16.6811\n","Epoch 479/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.9895 - mae: 16.4287_Epoch 479 Results: R2 Score: 0.99908439 MAE: 0.80210710 MSE: 1.99302006\n","\n","Epoch 479: loss improved from 5.01885 to 4.97973, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 43ms/step - loss: 4.9797 - mae: 16.6809\n","Epoch 480/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.9509 - mae: 16.6165_Epoch 480 Results: R2 Score: 0.99909952 MAE: 0.79327416 MSE: 1.96019673\n","\n","Epoch 480: loss improved from 4.97973 to 4.94124, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 4.9412 - mae: 16.6808\n","Epoch 481/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.9127 - mae: 17.3551_Epoch 481 Results: R2 Score: 0.99911444 MAE: 0.78507328 MSE: 1.92790508\n","\n","Epoch 481: loss improved from 4.94124 to 4.90335, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 4.9034 - mae: 16.6806\n","Epoch 482/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.8754 - mae: 15.6882_Epoch 482 Results: R2 Score: 0.99912912 MAE: 0.77689439 MSE: 1.89593434\n","\n","Epoch 482: loss improved from 4.90335 to 4.86614, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 104ms/step - loss: 4.8661 - mae: 16.6805\n","Epoch 483/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.8385 - mae: 17.1921_Epoch 483 Results: R2 Score: 0.99914350 MAE: 0.76842642 MSE: 1.86476886\n","\n","Epoch 483: loss improved from 4.86614 to 4.82942, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 4.8294 - mae: 16.6804\n","Epoch 484/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.8022 - mae: 16.1463_Epoch 484 Results: R2 Score: 0.99915761 MAE: 0.76025856 MSE: 1.83417475\n","\n","Epoch 484: loss improved from 4.82942 to 4.79326, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 50ms/step - loss: 4.7933 - mae: 16.6802\n","Epoch 485/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.7665 - mae: 18.4012_Epoch 485 Results: R2 Score: 0.99917152 MAE: 0.75214833 MSE: 1.80392027\n","\n","Epoch 485: loss improved from 4.79326 to 4.75762, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 4.7576 - mae: 16.6800\n","Epoch 486/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.7312 - mae: 17.0917_Epoch 486 Results: R2 Score: 0.99918522 MAE: 0.74416006 MSE: 1.77416599\n","\n","Epoch 486: loss improved from 4.75762 to 4.72259, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 4.7226 - mae: 16.6799\n","Epoch 487/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.6965 - mae: 16.4658_Epoch 487 Results: R2 Score: 0.99919879 MAE: 0.73634958 MSE: 1.74477041\n","\n","Epoch 487: loss improved from 4.72259 to 4.68801, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 4.6880 - mae: 16.6798\n","Epoch 488/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.6624 - mae: 17.0683_Epoch 488 Results: R2 Score: 0.99921198 MAE: 0.72841078 MSE: 1.71610284\n","\n","Epoch 488: loss improved from 4.68801 to 4.65395, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 4.6540 - mae: 16.6796\n","Epoch 489/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.6288 - mae: 16.0774_Epoch 489 Results: R2 Score: 0.99922498 MAE: 0.72054577 MSE: 1.68786740\n","\n","Epoch 489: loss improved from 4.65395 to 4.62046, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 97ms/step - loss: 4.6205 - mae: 16.6795\n","Epoch 490/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.5957 - mae: 15.0602_Epoch 490 Results: R2 Score: 0.99923781 MAE: 0.71290410 MSE: 1.66001034\n","\n","Epoch 490: loss improved from 4.62046 to 4.58753, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 98ms/step - loss: 4.5875 - mae: 16.6793\n","Epoch 491/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.5630 - mae: 17.4275_Epoch 491 Results: R2 Score: 0.99925038 MAE: 0.70549756 MSE: 1.63271630\n","\n","Epoch 491: loss improved from 4.58753 to 4.55500, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 4.5550 - mae: 16.6792\n","Epoch 492/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.5310 - mae: 17.0193_Epoch 492 Results: R2 Score: 0.99926276 MAE: 0.69777113 MSE: 1.60585666\n","\n","Epoch 492: loss improved from 4.55500 to 4.52311, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 4.5231 - mae: 16.6790\n","Epoch 493/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.4993 - mae: 16.6550_Epoch 493 Results: R2 Score: 0.99927486 MAE: 0.69018644 MSE: 1.57947421\n","\n","Epoch 493: loss improved from 4.52311 to 4.49153, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 4.4915 - mae: 16.6789\n","Epoch 494/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.4682 - mae: 16.8997_Epoch 494 Results: R2 Score: 0.99928677 MAE: 0.68260324 MSE: 1.55370021\n","\n","Epoch 494: loss improved from 4.49153 to 4.46064, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 112ms/step - loss: 4.4606 - mae: 16.6787\n","Epoch 495/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.4377 - mae: 14.8141_Epoch 495 Results: R2 Score: 0.99929855 MAE: 0.67543489 MSE: 1.52805519\n","\n","Epoch 495: loss improved from 4.46064 to 4.43004, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 4.4300 - mae: 16.6786\n","Epoch 496/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.4075 - mae: 18.2352_Epoch 496 Results: R2 Score: 0.99931018 MAE: 0.66791946 MSE: 1.50280654\n","\n","Epoch 496: loss improved from 4.43004 to 4.40001, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 4.4000 - mae: 16.6784\n","Epoch 497/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.3776 - mae: 17.4397_Epoch 497 Results: R2 Score: 0.99932157 MAE: 0.66091561 MSE: 1.47803235\n","\n","Epoch 497: loss improved from 4.40001 to 4.37021, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 4.3702 - mae: 16.6783\n","Epoch 498/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.3482 - mae: 15.6671_Epoch 498 Results: R2 Score: 0.99933280 MAE: 0.65422338 MSE: 1.45366597\n","\n","Epoch 498: loss improved from 4.37021 to 4.34102, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 4.3410 - mae: 16.6781\n","Epoch 499/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.3195 - mae: 16.3563_Epoch 499 Results: R2 Score: 0.99934381 MAE: 0.64676183 MSE: 1.42974854\n","\n","Epoch 499: loss improved from 4.34102 to 4.31228, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 124ms/step - loss: 4.3123 - mae: 16.6779\n","Epoch 500/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.2910 - mae: 17.0295_Epoch 500 Results: R2 Score: 0.99935454 MAE: 0.63921505 MSE: 1.40640414\n","\n","Epoch 500: loss improved from 4.31228 to 4.28398, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 4.2840 - mae: 16.6778\n","Epoch 501/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.2630 - mae: 17.5815_Epoch 501 Results: R2 Score: 0.99936518 MAE: 0.63234705 MSE: 1.38334680\n","\n","Epoch 501: loss improved from 4.28398 to 4.25604, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 4.2560 - mae: 16.6777\n","Epoch 502/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.2354 - mae: 17.0987_Epoch 502 Results: R2 Score: 0.99937561 MAE: 0.62573093 MSE: 1.36060607\n","\n","Epoch 502: loss improved from 4.25604 to 4.22857, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 4.2286 - mae: 16.6775\n","Epoch 503/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.2083 - mae: 17.3637_Epoch 503 Results: R2 Score: 0.99938597 MAE: 0.61908573 MSE: 1.33809876\n","\n","Epoch 503: loss improved from 4.22857 to 4.20149, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 106ms/step - loss: 4.2015 - mae: 16.6773\n","Epoch 504/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.1815 - mae: 14.9508_Epoch 504 Results: R2 Score: 0.99939616 MAE: 0.61207312 MSE: 1.31594944\n","\n","Epoch 504: loss improved from 4.20149 to 4.17478, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 4.1748 - mae: 16.6772\n","Epoch 505/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.1549 - mae: 16.6331_Epoch 505 Results: R2 Score: 0.99940608 MAE: 0.60539639 MSE: 1.29442620\n","\n","Epoch 505: loss improved from 4.17478 to 4.14847, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 4.1485 - mae: 16.6771\n","Epoch 506/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.1290 - mae: 14.3989_Epoch 506 Results: R2 Score: 0.99941581 MAE: 0.59874827 MSE: 1.27320206\n","\n","Epoch 506: loss improved from 4.14847 to 4.12256, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 4.1226 - mae: 16.6769\n","Epoch 507/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.1035 - mae: 13.9396_Epoch 507 Results: R2 Score: 0.99942546 MAE: 0.59219253 MSE: 1.25225651\n","\n","Epoch 507: loss improved from 4.12256 to 4.09713, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 4.0971 - mae: 16.6767\n","Epoch 508/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0782 - mae: 16.2590_Epoch 508 Results: R2 Score: 0.99943490 MAE: 0.58535790 MSE: 1.23174000\n","\n","Epoch 508: loss improved from 4.09713 to 4.07192, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 4.0719 - mae: 16.6766\n","Epoch 509/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0533 - mae: 15.6656_Epoch 509 Results: R2 Score: 0.99944409 MAE: 0.57815206 MSE: 1.21172655\n","\n","Epoch 509: loss improved from 4.07192 to 4.04711, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 4.0471 - mae: 16.6764\n","Epoch 510/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0287 - mae: 18.1595_Epoch 510 Results: R2 Score: 0.99945328 MAE: 0.57215476 MSE: 1.19167447\n","\n","Epoch 510: loss improved from 4.04711 to 4.02267, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 73ms/step - loss: 4.0227 - mae: 16.6763\n","Epoch 511/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 4.0046 - mae: 15.5032_Epoch 511 Results: R2 Score: 0.99946234 MAE: 0.56589514 MSE: 1.17201424\n","\n","Epoch 511: loss improved from 4.02267 to 3.99866, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 33ms/step - loss: 3.9987 - mae: 16.6761\n","Epoch 512/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9807 - mae: 17.1591_Epoch 512 Results: R2 Score: 0.99947111 MAE: 0.55938143 MSE: 1.15295053\n","\n","Epoch 512: loss improved from 3.99866 to 3.97497, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 19ms/step - loss: 3.9750 - mae: 16.6760\n","Epoch 513/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9575 - mae: 15.7125_Epoch 513 Results: R2 Score: 0.99947991 MAE: 0.55335939 MSE: 1.13381541\n","\n","Epoch 513: loss improved from 3.97497 to 3.95164, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 44ms/step - loss: 3.9516 - mae: 16.6758\n","Epoch 514/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9343 - mae: 16.4229_Epoch 514 Results: R2 Score: 0.99948842 MAE: 0.54705769 MSE: 1.11532605\n","\n","Epoch 514: loss improved from 3.95164 to 3.92868, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 124ms/step - loss: 3.9287 - mae: 16.6757\n","Epoch 515/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.9116 - mae: 15.0851_Epoch 515 Results: R2 Score: 0.99949681 MAE: 0.54096103 MSE: 1.09706950\n","\n","Epoch 515: loss improved from 3.92868 to 3.90602, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 113ms/step - loss: 3.9060 - mae: 16.6755\n","Epoch 516/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8892 - mae: 16.3076_Epoch 516 Results: R2 Score: 0.99950516 MAE: 0.53512841 MSE: 1.07891035\n","\n","Epoch 516: loss improved from 3.90602 to 3.88368, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 105ms/step - loss: 3.8837 - mae: 16.6754\n","Epoch 517/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8672 - mae: 17.1499_Epoch 517 Results: R2 Score: 0.99951332 MAE: 0.52890724 MSE: 1.06118309\n","\n","Epoch 517: loss improved from 3.88368 to 3.86166, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 3.8617 - mae: 16.6752\n","Epoch 518/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8454 - mae: 15.7663_Epoch 518 Results: R2 Score: 0.99952130 MAE: 0.52336782 MSE: 1.04376721\n","\n","Epoch 518: loss improved from 3.86166 to 3.84003, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 3.8400 - mae: 16.6750\n","Epoch 519/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8241 - mae: 19.3629_Epoch 519 Results: R2 Score: 0.99952917 MAE: 0.51725298 MSE: 1.02667379\n","\n","Epoch 519: loss improved from 3.84003 to 3.81876, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 3.8188 - mae: 16.6749\n","Epoch 520/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.8029 - mae: 16.9747_Epoch 520 Results: R2 Score: 0.99953681 MAE: 0.51122981 MSE: 1.01006341\n","\n","Epoch 520: loss improved from 3.81876 to 3.79767, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 3.7977 - mae: 16.6747\n","Epoch 521/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7823 - mae: 16.7104_Epoch 521 Results: R2 Score: 0.99954450 MAE: 0.50562030 MSE: 0.99330747\n","\n","Epoch 521: loss improved from 3.79767 to 3.77703, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 3.7770 - mae: 16.6746\n","Epoch 522/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7617 - mae: 18.6750_Epoch 522 Results: R2 Score: 0.99955200 MAE: 0.49990106 MSE: 0.97698581\n","\n","Epoch 522: loss improved from 3.77703 to 3.75663, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 71ms/step - loss: 3.7566 - mae: 16.6744\n","Epoch 523/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7415 - mae: 16.1228_Epoch 523 Results: R2 Score: 0.99955942 MAE: 0.49439883 MSE: 0.96081829\n","\n","Epoch 523: loss improved from 3.75663 to 3.73654, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 3.7365 - mae: 16.6743\n","Epoch 524/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7217 - mae: 16.0941_Epoch 524 Results: R2 Score: 0.99956671 MAE: 0.48915946 MSE: 0.94494694\n","\n","Epoch 524: loss improved from 3.73654 to 3.71680, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 73ms/step - loss: 3.7168 - mae: 16.6741\n","Epoch 525/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.7021 - mae: 17.8694_Epoch 525 Results: R2 Score: 0.99957382 MAE: 0.48375055 MSE: 0.92946398\n","\n","Epoch 525: loss improved from 3.71680 to 3.69718, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 3.6972 - mae: 16.6740\n","Epoch 526/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6827 - mae: 16.1289_Epoch 526 Results: R2 Score: 0.99958088 MAE: 0.47824508 MSE: 0.91414714\n","\n","Epoch 526: loss improved from 3.69718 to 3.67785, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 49ms/step - loss: 3.6778 - mae: 16.6738\n","Epoch 527/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6636 - mae: 17.4189_Epoch 527 Results: R2 Score: 0.99958772 MAE: 0.47230163 MSE: 0.89923286\n","\n","Epoch 527: loss improved from 3.67785 to 3.65887, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 3.6589 - mae: 16.6737\n","Epoch 528/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6448 - mae: 16.3403_Epoch 528 Results: R2 Score: 0.99959445 MAE: 0.46681169 MSE: 0.88458151\n","\n","Epoch 528: loss improved from 3.65887 to 3.64018, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 3.6402 - mae: 16.6735\n","Epoch 529/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6265 - mae: 17.9928_Epoch 529 Results: R2 Score: 0.99960126 MAE: 0.46173954 MSE: 0.86976075\n","\n","Epoch 529: loss improved from 3.64018 to 3.62191, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 39ms/step - loss: 3.6219 - mae: 16.6734\n","Epoch 530/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.6081 - mae: 17.9597_Epoch 530 Results: R2 Score: 0.99960771 MAE: 0.45622283 MSE: 0.85568702\n","\n","Epoch 530: loss improved from 3.62191 to 3.60360, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 45ms/step - loss: 3.6036 - mae: 16.6732\n","Epoch 531/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5900 - mae: 16.8480_Epoch 531 Results: R2 Score: 0.99961403 MAE: 0.45077917 MSE: 0.84193003\n","\n","Epoch 531: loss improved from 3.60360 to 3.58567, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 128ms/step - loss: 3.5857 - mae: 16.6730\n","Epoch 532/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5725 - mae: 16.2045_Epoch 532 Results: R2 Score: 0.99962055 MAE: 0.44614252 MSE: 0.82776034\n","\n","Epoch 532: loss improved from 3.58567 to 3.56819, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 49ms/step - loss: 3.5682 - mae: 16.6729\n","Epoch 533/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5550 - mae: 15.7142_Epoch 533 Results: R2 Score: 0.99962683 MAE: 0.44114190 MSE: 0.81410301\n","\n","Epoch 533: loss improved from 3.56819 to 3.55073, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 110ms/step - loss: 3.5507 - mae: 16.6727\n","Epoch 534/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5377 - mae: 15.7913_Epoch 534 Results: R2 Score: 0.99963285 MAE: 0.43576783 MSE: 0.80099553\n","\n","Epoch 534: loss improved from 3.55073 to 3.53355, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 81ms/step - loss: 3.5335 - mae: 16.6726\n","Epoch 535/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5209 - mae: 17.2387_Epoch 535 Results: R2 Score: 0.99963892 MAE: 0.43117213 MSE: 0.78776497\n","\n","Epoch 535: loss improved from 3.53355 to 3.51675, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 3.5167 - mae: 16.6724\n","Epoch 536/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.5043 - mae: 16.4246_Epoch 536 Results: R2 Score: 0.99964498 MAE: 0.42613435 MSE: 0.77459526\n","\n","Epoch 536: loss improved from 3.51675 to 3.50012, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 96ms/step - loss: 3.5001 - mae: 16.6723\n","Epoch 537/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4877 - mae: 17.5670_Epoch 537 Results: R2 Score: 0.99965078 MAE: 0.42123652 MSE: 0.76195347\n","\n","Epoch 537: loss improved from 3.50012 to 3.48364, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 3.4836 - mae: 16.6721\n","Epoch 538/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4714 - mae: 16.7423_Epoch 538 Results: R2 Score: 0.99965649 MAE: 0.41638759 MSE: 0.74951017\n","\n","Epoch 538: loss improved from 3.48364 to 3.46742, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 3.4674 - mae: 16.6719\n","Epoch 539/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4555 - mae: 15.9735_Epoch 539 Results: R2 Score: 0.99966210 MAE: 0.41164637 MSE: 0.73729151\n","\n","Epoch 539: loss improved from 3.46742 to 3.45154, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 3.4515 - mae: 16.6718\n","Epoch 540/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4398 - mae: 16.8904_Epoch 540 Results: R2 Score: 0.99966768 MAE: 0.40675294 MSE: 0.72511452\n","\n","Epoch 540: loss improved from 3.45154 to 3.43589, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 3.4359 - mae: 16.6716\n","Epoch 541/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4241 - mae: 17.5473_Epoch 541 Results: R2 Score: 0.99967323 MAE: 0.40241513 MSE: 0.71302581\n","\n","Epoch 541: loss improved from 3.43589 to 3.42036, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 70ms/step - loss: 3.4204 - mae: 16.6715\n","Epoch 542/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.4089 - mae: 17.9681_Epoch 542 Results: R2 Score: 0.99967847 MAE: 0.39713299 MSE: 0.70160717\n","\n","Epoch 542: loss improved from 3.42036 to 3.40506, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 3.4051 - mae: 16.6713\n","Epoch 543/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3937 - mae: 17.8014_Epoch 543 Results: R2 Score: 0.99968378 MAE: 0.39266798 MSE: 0.69003910\n","\n","Epoch 543: loss improved from 3.40506 to 3.39007, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 3.3901 - mae: 16.6712\n","Epoch 544/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3788 - mae: 15.5905_Epoch 544 Results: R2 Score: 0.99968901 MAE: 0.38797280 MSE: 0.67866558\n","\n","Epoch 544: loss improved from 3.39007 to 3.37519, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 3.3752 - mae: 16.6710\n","Epoch 545/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3641 - mae: 17.9760_Epoch 545 Results: R2 Score: 0.99969422 MAE: 0.38394472 MSE: 0.66733700\n","\n","Epoch 545: loss improved from 3.37519 to 3.36054, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 48ms/step - loss: 3.3605 - mae: 16.6709\n","Epoch 546/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3496 - mae: 16.9414_Epoch 546 Results: R2 Score: 0.99969925 MAE: 0.37941143 MSE: 0.65637177\n","\n","Epoch 546: loss improved from 3.36054 to 3.34600, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 3.3460 - mae: 16.6707\n","Epoch 547/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3354 - mae: 16.4620_Epoch 547 Results: R2 Score: 0.99970419 MAE: 0.37461954 MSE: 0.64558834\n","\n","Epoch 547: loss improved from 3.34600 to 3.33190, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 3.3319 - mae: 16.6706\n","Epoch 548/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3211 - mae: 15.4500_Epoch 548 Results: R2 Score: 0.99970902 MAE: 0.37028611 MSE: 0.63504040\n","\n","Epoch 548: loss improved from 3.33190 to 3.31777, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 3.3178 - mae: 16.6704\n","Epoch 549/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.3073 - mae: 16.0343_Epoch 549 Results: R2 Score: 0.99971384 MAE: 0.36602288 MSE: 0.62457812\n","\n","Epoch 549: loss improved from 3.31777 to 3.30386, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 3.3039 - mae: 16.6702\n","Epoch 550/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2935 - mae: 17.0266_Epoch 550 Results: R2 Score: 0.99971858 MAE: 0.36266398 MSE: 0.61424249\n","\n","Epoch 550: loss improved from 3.30386 to 3.29022, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 3.2902 - mae: 16.6701\n","Epoch 551/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2804 - mae: 17.0847_Epoch 551 Results: R2 Score: 0.99972323 MAE: 0.35772499 MSE: 0.60411298\n","\n","Epoch 551: loss improved from 3.29022 to 3.27713, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 111ms/step - loss: 3.2771 - mae: 16.6699\n","Epoch 552/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2669 - mae: 16.7552_Epoch 552 Results: R2 Score: 0.99972784 MAE: 0.35431799 MSE: 0.59406066\n","\n","Epoch 552: loss improved from 3.27713 to 3.26367, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 3.2637 - mae: 16.6698\n","Epoch 553/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2540 - mae: 15.2463_Epoch 553 Results: R2 Score: 0.99973231 MAE: 0.35008681 MSE: 0.58428985\n","\n","Epoch 553: loss improved from 3.26367 to 3.25085, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 3.2509 - mae: 16.6696\n","Epoch 554/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2411 - mae: 16.7475_Epoch 554 Results: R2 Score: 0.99973669 MAE: 0.34598601 MSE: 0.57478344\n","\n","Epoch 554: loss improved from 3.25085 to 3.23779, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 3.2378 - mae: 16.6695\n","Epoch 555/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2285 - mae: 17.2195_Epoch 555 Results: R2 Score: 0.99974104 MAE: 0.34222585 MSE: 0.56529212\n","\n","Epoch 555: loss improved from 3.23779 to 3.22535, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 81ms/step - loss: 3.2253 - mae: 16.6693\n","Epoch 556/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2159 - mae: 17.5270_Epoch 556 Results: R2 Score: 0.99974523 MAE: 0.33737609 MSE: 0.55617738\n","\n","Epoch 556: loss improved from 3.22535 to 3.21257, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 3.2126 - mae: 16.6691\n","Epoch 557/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.2033 - mae: 16.5900_Epoch 557 Results: R2 Score: 0.99974947 MAE: 0.33429766 MSE: 0.54688835\n","\n","Epoch 557: loss improved from 3.21257 to 3.20027, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 3.2003 - mae: 16.6690\n","Epoch 558/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1913 - mae: 15.1943_Epoch 558 Results: R2 Score: 0.99975367 MAE: 0.33033076 MSE: 0.53775930\n","\n","Epoch 558: loss improved from 3.20027 to 3.18824, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 3.1882 - mae: 16.6688\n","Epoch 559/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1792 - mae: 16.8132_Epoch 559 Results: R2 Score: 0.99975780 MAE: 0.32615712 MSE: 0.52876282\n","\n","Epoch 559: loss improved from 3.18824 to 3.17616, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 3.1762 - mae: 16.6687\n","Epoch 560/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1671 - mae: 16.2115_Epoch 560 Results: R2 Score: 0.99976171 MAE: 0.32264730 MSE: 0.52022874\n","\n","Epoch 560: loss improved from 3.17616 to 3.16439, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 3.1644 - mae: 16.6685\n","Epoch 561/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1558 - mae: 17.2137_Epoch 561 Results: R2 Score: 0.99976558 MAE: 0.31896260 MSE: 0.51181901\n","\n","Epoch 561: loss improved from 3.16439 to 3.15297, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 3.1530 - mae: 16.6684\n","Epoch 562/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1444 - mae: 17.2200_Epoch 562 Results: R2 Score: 0.99976941 MAE: 0.31540272 MSE: 0.50343478\n","\n","Epoch 562: loss improved from 3.15297 to 3.14125, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 3.1412 - mae: 16.6682\n","Epoch 563/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1330 - mae: 17.1573_Epoch 563 Results: R2 Score: 0.99977333 MAE: 0.31143433 MSE: 0.49488637\n","\n","Epoch 563: loss improved from 3.14125 to 3.13016, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 3.1302 - mae: 16.6680\n","Epoch 564/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1213 - mae: 16.2970_Epoch 564 Results: R2 Score: 0.99977688 MAE: 0.30756435 MSE: 0.48715517\n","\n","Epoch 564: loss improved from 3.13016 to 3.11884, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 3.1188 - mae: 16.6679\n","Epoch 565/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.1107 - mae: 15.6109_Epoch 565 Results: R2 Score: 0.99978070 MAE: 0.30398846 MSE: 0.47883603\n","\n","Epoch 565: loss improved from 3.11884 to 3.10768, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 98ms/step - loss: 3.1077 - mae: 16.6677\n","Epoch 566/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0994 - mae: 16.6686_Epoch 566 Results: R2 Score: 0.99978435 MAE: 0.30096844 MSE: 0.47084349\n","\n","Epoch 566: loss improved from 3.10768 to 3.09674, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 3.0967 - mae: 16.6676\n","Epoch 567/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0888 - mae: 17.2239_Epoch 567 Results: R2 Score: 0.99978785 MAE: 0.29758719 MSE: 0.46322635\n","\n","Epoch 567: loss improved from 3.09674 to 3.08592, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 49ms/step - loss: 3.0859 - mae: 16.6674\n","Epoch 568/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0784 - mae: 16.1519_Epoch 568 Results: R2 Score: 0.99979127 MAE: 0.29368502 MSE: 0.45577803\n","\n","Epoch 568: loss improved from 3.08592 to 3.07559, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 3.0756 - mae: 16.6672\n","Epoch 569/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0680 - mae: 16.1765_Epoch 569 Results: R2 Score: 0.99979485 MAE: 0.28919557 MSE: 0.44795674\n","\n","Epoch 569: loss improved from 3.07559 to 3.06511, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 3.0651 - mae: 16.6671\n","Epoch 570/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0568 - mae: 17.6478_Epoch 570 Results: R2 Score: 0.99979819 MAE: 0.28671008 MSE: 0.44072911\n","\n","Epoch 570: loss improved from 3.06511 to 3.05442, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 112ms/step - loss: 3.0544 - mae: 16.6669\n","Epoch 571/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0471 - mae: 16.9781_Epoch 571 Results: R2 Score: 0.99980155 MAE: 0.28250834 MSE: 0.43334273\n","\n","Epoch 571: loss improved from 3.05442 to 3.04456, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 112ms/step - loss: 3.0446 - mae: 16.6668\n","Epoch 572/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0366 - mae: 16.6311_Epoch 572 Results: R2 Score: 0.99980486 MAE: 0.28006673 MSE: 0.42612016\n","\n","Epoch 572: loss improved from 3.04456 to 3.03433, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 99ms/step - loss: 3.0343 - mae: 16.6666\n","Epoch 573/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0272 - mae: 16.1673_Epoch 573 Results: R2 Score: 0.99980806 MAE: 0.27610806 MSE: 0.41914916\n","\n","Epoch 573: loss improved from 3.03433 to 3.02477, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 132ms/step - loss: 3.0248 - mae: 16.6665\n","Epoch 574/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0171 - mae: 15.3969_Epoch 574 Results: R2 Score: 0.99981124 MAE: 0.27321699 MSE: 0.41222477\n","\n","Epoch 574: loss improved from 3.02477 to 3.01464, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 50ms/step - loss: 3.0146 - mae: 16.6663\n","Epoch 575/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 3.0076 - mae: 17.0961_Epoch 575 Results: R2 Score: 0.99981443 MAE: 0.26994231 MSE: 0.40526339\n","\n","Epoch 575: loss improved from 3.01464 to 3.00491, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 3.0049 - mae: 16.6662\n","Epoch 576/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9979 - mae: 16.6061_Epoch 576 Results: R2 Score: 0.99981747 MAE: 0.26609862 MSE: 0.39864263\n","\n","Epoch 576: loss improved from 3.00491 to 2.99541, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 69ms/step - loss: 2.9954 - mae: 16.6660\n","Epoch 577/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9883 - mae: 16.7894_Epoch 577 Results: R2 Score: 0.99982040 MAE: 0.26260290 MSE: 0.39224458\n","\n","Epoch 577: loss improved from 2.99541 to 2.98605, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 2.9860 - mae: 16.6658\n","Epoch 578/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9789 - mae: 17.4582_Epoch 578 Results: R2 Score: 0.99982347 MAE: 0.26035181 MSE: 0.38555622\n","\n","Epoch 578: loss improved from 2.98605 to 2.97680, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 2.9768 - mae: 16.6657\n","Epoch 579/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9700 - mae: 19.0484_Epoch 579 Results: R2 Score: 0.99982629 MAE: 0.25730956 MSE: 0.37940603\n","\n","Epoch 579: loss improved from 2.97680 to 2.96768, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 2.9677 - mae: 16.6655\n","Epoch 580/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9613 - mae: 16.2542_Epoch 580 Results: R2 Score: 0.99982919 MAE: 0.25374952 MSE: 0.37306449\n","\n","Epoch 580: loss improved from 2.96768 to 2.95907, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 132ms/step - loss: 2.9591 - mae: 16.6654\n","Epoch 581/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9521 - mae: 14.7072_Epoch 581 Results: R2 Score: 0.99983203 MAE: 0.25146949 MSE: 0.36683270\n","\n","Epoch 581: loss improved from 2.95907 to 2.94976, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 2.9498 - mae: 16.6652\n","Epoch 582/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9436 - mae: 15.8425_Epoch 582 Results: R2 Score: 0.99983482 MAE: 0.24788573 MSE: 0.36077914\n","\n","Epoch 582: loss improved from 2.94976 to 2.94151, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 2.9415 - mae: 16.6651\n","Epoch 583/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9347 - mae: 14.4116_Epoch 583 Results: R2 Score: 0.99983754 MAE: 0.24509858 MSE: 0.35483646\n","\n","Epoch 583: loss improved from 2.94151 to 2.93246, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 2.9325 - mae: 16.6649\n","Epoch 584/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9261 - mae: 17.4907_Epoch 584 Results: R2 Score: 0.99984025 MAE: 0.24167867 MSE: 0.34894863\n","\n","Epoch 584: loss improved from 2.93246 to 2.92466, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 2.9247 - mae: 16.6648\n","Epoch 585/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9175 - mae: 17.4484_Epoch 585 Results: R2 Score: 0.99984287 MAE: 0.23944144 MSE: 0.34322140\n","\n","Epoch 585: loss improved from 2.92466 to 2.91549, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 46ms/step - loss: 2.9155 - mae: 16.6646\n","Epoch 586/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9094 - mae: 17.6188_Epoch 586 Results: R2 Score: 0.99984547 MAE: 0.23625448 MSE: 0.33752447\n","\n","Epoch 586: loss improved from 2.91549 to 2.90747, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 73ms/step - loss: 2.9075 - mae: 16.6644\n","Epoch 587/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.9012 - mae: 16.3879_Epoch 587 Results: R2 Score: 0.99984807 MAE: 0.23324634 MSE: 0.33186501\n","\n","Epoch 587: loss improved from 2.90747 to 2.89905, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 103ms/step - loss: 2.8991 - mae: 16.6643\n","Epoch 588/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8928 - mae: 18.2578_Epoch 588 Results: R2 Score: 0.99985052 MAE: 0.23061405 MSE: 0.32653522\n","\n","Epoch 588: loss improved from 2.89905 to 2.89114, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 2.8911 - mae: 16.6641\n","Epoch 589/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8849 - mae: 17.3608_Epoch 589 Results: R2 Score: 0.99985277 MAE: 0.22810140 MSE: 0.32161334\n","\n","Epoch 589: loss improved from 2.89114 to 2.88268, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 2.8827 - mae: 16.6639\n","Epoch 590/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8776 - mae: 17.3136_Epoch 590 Results: R2 Score: 0.99985548 MAE: 0.22556868 MSE: 0.31572077\n","\n","Epoch 590: loss improved from 2.88268 to 2.87564, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 2.8756 - mae: 16.6638\n","Epoch 591/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8694 - mae: 15.5939_Epoch 591 Results: R2 Score: 0.99985788 MAE: 0.22306861 MSE: 0.31044912\n","\n","Epoch 591: loss improved from 2.87564 to 2.86729, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 2.8673 - mae: 16.6636\n","Epoch 592/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8619 - mae: 16.0594_Epoch 592 Results: R2 Score: 0.99986016 MAE: 0.22061425 MSE: 0.30549395\n","\n","Epoch 592: loss improved from 2.86729 to 2.86044, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 104ms/step - loss: 2.8604 - mae: 16.6635\n","Epoch 593/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8546 - mae: 17.0466_Epoch 593 Results: R2 Score: 0.99986247 MAE: 0.21736471 MSE: 0.30043977\n","\n","Epoch 593: loss improved from 2.86044 to 2.85269, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 2.8527 - mae: 16.6633\n","Epoch 594/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8467 - mae: 16.8692_Epoch 594 Results: R2 Score: 0.99986474 MAE: 0.21541144 MSE: 0.29548126\n","\n","Epoch 594: loss improved from 2.85269 to 2.84456, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 76ms/step - loss: 2.8446 - mae: 16.6632\n","Epoch 595/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8396 - mae: 17.3205_Epoch 595 Results: R2 Score: 0.99986710 MAE: 0.21145126 MSE: 0.29033610\n","\n","Epoch 595: loss improved from 2.84456 to 2.83761, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 52ms/step - loss: 2.8376 - mae: 16.6630\n","Epoch 596/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8315 - mae: 16.4435_Epoch 596 Results: R2 Score: 0.99986908 MAE: 0.20856273 MSE: 0.28601298\n","\n","Epoch 596: loss improved from 2.83761 to 2.82977, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 86ms/step - loss: 2.8298 - mae: 16.6629\n","Epoch 597/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8243 - mae: 17.7793_Epoch 597 Results: R2 Score: 0.99987136 MAE: 0.20573917 MSE: 0.28101483\n","\n","Epoch 597: loss improved from 2.82977 to 2.82270, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 127ms/step - loss: 2.8227 - mae: 16.6627\n","Epoch 598/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8169 - mae: 16.4121_Epoch 598 Results: R2 Score: 0.99987353 MAE: 0.20501822 MSE: 0.27629045\n","\n","Epoch 598: loss improved from 2.82270 to 2.81546, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 2.8155 - mae: 16.6625\n","Epoch 599/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8107 - mae: 17.7574_Epoch 599 Results: R2 Score: 0.99987552 MAE: 0.20264003 MSE: 0.27193913\n","\n","Epoch 599: loss improved from 2.81546 to 2.80865, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 47ms/step - loss: 2.8087 - mae: 16.6624\n","Epoch 600/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.8039 - mae: 17.3336_Epoch 600 Results: R2 Score: 0.99987750 MAE: 0.19994214 MSE: 0.26766944\n","\n","Epoch 600: loss improved from 2.80865 to 2.80201, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 72ms/step - loss: 2.8020 - mae: 16.6622\n","Epoch 601/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7972 - mae: 16.0915_Epoch 601 Results: R2 Score: 0.99987959 MAE: 0.19906920 MSE: 0.26307368\n","\n","Epoch 601: loss improved from 2.80201 to 2.79580, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 2.7958 - mae: 16.6620\n","Epoch 602/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7910 - mae: 16.8510_Epoch 602 Results: R2 Score: 0.99988161 MAE: 0.19438112 MSE: 0.25865811\n","\n","Epoch 602: loss improved from 2.79580 to 2.78889, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 2.7889 - mae: 16.6619\n","Epoch 603/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7832 - mae: 15.4283_Epoch 603 Results: R2 Score: 0.99988352 MAE: 0.19337033 MSE: 0.25450575\n","\n","Epoch 603: loss improved from 2.78889 to 2.78150, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 2.7815 - mae: 16.6617\n","Epoch 604/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7775 - mae: 15.2100_Epoch 604 Results: R2 Score: 0.99988539 MAE: 0.19132096 MSE: 0.25040793\n","\n","Epoch 604: loss improved from 2.78150 to 2.77580, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 2.7758 - mae: 16.6616\n","Epoch 605/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7711 - mae: 16.2216_Epoch 605 Results: R2 Score: 0.99988740 MAE: 0.18678324 MSE: 0.24604049\n","\n","Epoch 605: loss improved from 2.77580 to 2.76912, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 2.7691 - mae: 16.6614\n","Epoch 606/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7633 - mae: 17.7497_Epoch 606 Results: R2 Score: 0.99988914 MAE: 0.18621442 MSE: 0.24221885\n","\n","Epoch 606: loss improved from 2.76912 to 2.76224, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 81ms/step - loss: 2.7622 - mae: 16.6612\n","Epoch 607/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7580 - mae: 16.6251_Epoch 607 Results: R2 Score: 0.99989102 MAE: 0.18253623 MSE: 0.23813835\n","\n","Epoch 607: loss improved from 2.76224 to 2.75616, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 122ms/step - loss: 2.7562 - mae: 16.6611\n","Epoch 608/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7509 - mae: 16.7147_Epoch 608 Results: R2 Score: 0.99989271 MAE: 0.18171856 MSE: 0.23443873\n","\n","Epoch 608: loss improved from 2.75616 to 2.74984, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 100ms/step - loss: 2.7498 - mae: 16.6609\n","Epoch 609/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7455 - mae: 16.3537_Epoch 609 Results: R2 Score: 0.99989449 MAE: 0.17835851 MSE: 0.23053497\n","\n","Epoch 609: loss improved from 2.74984 to 2.74394, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 116ms/step - loss: 2.7439 - mae: 16.6607\n","Epoch 610/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7390 - mae: 18.1742_Epoch 610 Results: R2 Score: 0.99989642 MAE: 0.17630377 MSE: 0.22633533\n","\n","Epoch 610: loss improved from 2.74394 to 2.73764, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 80ms/step - loss: 2.7376 - mae: 16.6606\n","Epoch 611/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7327 - mae: 16.7663_Epoch 611 Results: R2 Score: 0.99989801 MAE: 0.17380351 MSE: 0.22286537\n","\n","Epoch 611: loss improved from 2.73764 to 2.73164, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 50ms/step - loss: 2.7316 - mae: 16.6604\n","Epoch 612/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7268 - mae: 17.9668_Epoch 612 Results: R2 Score: 0.99989984 MAE: 0.17210408 MSE: 0.21886866\n","\n","Epoch 612: loss improved from 2.73164 to 2.72570, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 2.7257 - mae: 16.6603\n","Epoch 613/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7209 - mae: 15.8638_Epoch 613 Results: R2 Score: 0.99990123 MAE: 0.16966064 MSE: 0.21581767\n","\n","Epoch 613: loss improved from 2.72570 to 2.71979, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 2.7198 - mae: 16.6601\n","Epoch 614/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7153 - mae: 16.0347_Epoch 614 Results: R2 Score: 0.99990298 MAE: 0.16775823 MSE: 0.21201898\n","\n","Epoch 614: loss improved from 2.71979 to 2.71366, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 41ms/step - loss: 2.7137 - mae: 16.6600\n","Epoch 615/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7094 - mae: 16.0390_Epoch 615 Results: R2 Score: 0.99990436 MAE: 0.16751395 MSE: 0.20900767\n","\n","Epoch 615: loss improved from 2.71366 to 2.70819, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 2.7082 - mae: 16.6598\n","Epoch 616/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.7051 - mae: 17.6558_Epoch 616 Results: R2 Score: 0.99990607 MAE: 0.16414239 MSE: 0.20526387\n","\n","Epoch 616: loss improved from 2.70819 to 2.70337, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 2.7034 - mae: 16.6596\n","Epoch 617/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6984 - mae: 16.0317_Epoch 617 Results: R2 Score: 0.99990759 MAE: 0.16221479 MSE: 0.20193557\n","\n","Epoch 617: loss improved from 2.70337 to 2.69716, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 91ms/step - loss: 2.6972 - mae: 16.6594\n","Epoch 618/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6929 - mae: 16.6668_Epoch 618 Results: R2 Score: 0.99990899 MAE: 0.16243024 MSE: 0.19889002\n","\n","Epoch 618: loss improved from 2.69716 to 2.69229, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 82ms/step - loss: 2.6923 - mae: 16.6592\n","Epoch 619/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6888 - mae: 18.6673_Epoch 619 Results: R2 Score: 0.99991054 MAE: 0.16043827 MSE: 0.19549651\n","\n","Epoch 619: loss improved from 2.69229 to 2.68674, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 2.6867 - mae: 16.6591\n","Epoch 620/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6832 - mae: 15.3773_Epoch 620 Results: R2 Score: 0.99991202 MAE: 0.15821096 MSE: 0.19227332\n","\n","Epoch 620: loss improved from 2.68674 to 2.68174, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 2.6817 - mae: 16.6589\n","Epoch 621/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6777 - mae: 17.0268_Epoch 621 Results: R2 Score: 0.99991338 MAE: 0.15685083 MSE: 0.18930656\n","\n","Epoch 621: loss improved from 2.68174 to 2.67653, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 2.6765 - mae: 16.6588\n","Epoch 622/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6729 - mae: 15.9668_Epoch 622 Results: R2 Score: 0.99991500 MAE: 0.15266933 MSE: 0.18575262\n","\n","Epoch 622: loss improved from 2.67653 to 2.67137, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 76ms/step - loss: 2.6714 - mae: 16.6586\n","Epoch 623/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6662 - mae: 15.7593_Epoch 623 Results: R2 Score: 0.99991600 MAE: 0.15555082 MSE: 0.18356651\n","\n","Epoch 623: loss improved from 2.67137 to 2.66502, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 88ms/step - loss: 2.6650 - mae: 16.6584\n","Epoch 624/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6643 - mae: 15.8154_Epoch 624 Results: R2 Score: 0.99991794 MAE: 0.15045063 MSE: 0.17933698\n","\n","Epoch 624: loss improved from 2.66502 to 2.66266, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 2.6627 - mae: 16.6583\n","Epoch 625/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6564 - mae: 15.6310_Epoch 625 Results: R2 Score: 0.99991896 MAE: 0.14983211 MSE: 0.17710271\n","\n","Epoch 625: loss improved from 2.66266 to 2.65539, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 86ms/step - loss: 2.6554 - mae: 16.6581\n","Epoch 626/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6525 - mae: 16.2071_Epoch 626 Results: R2 Score: 0.99992033 MAE: 0.14683431 MSE: 0.17413390\n","\n","Epoch 626: loss improved from 2.65539 to 2.65108, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 83ms/step - loss: 2.6511 - mae: 16.6579\n","Epoch 627/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6469 - mae: 15.6319_Epoch 627 Results: R2 Score: 0.99992189 MAE: 0.14373434 MSE: 0.17071562\n","\n","Epoch 627: loss improved from 2.65108 to 2.64598, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 2.6460 - mae: 16.6578\n","Epoch 628/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6409 - mae: 17.7931_Epoch 628 Results: R2 Score: 0.99992314 MAE: 0.14250956 MSE: 0.16798292\n","\n","Epoch 628: loss improved from 2.64598 to 2.63987, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 2.6399 - mae: 16.6576\n","Epoch 629/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6363 - mae: 18.0244_Epoch 629 Results: R2 Score: 0.99992420 MAE: 0.14149022 MSE: 0.16567014\n","\n","Epoch 629: loss improved from 2.63987 to 2.63525, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 2.6352 - mae: 16.6575\n","Epoch 630/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6324 - mae: 15.7803_Epoch 630 Results: R2 Score: 0.99992549 MAE: 0.13995662 MSE: 0.16285577\n","\n","Epoch 630: loss improved from 2.63525 to 2.63149, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 127ms/step - loss: 2.6315 - mae: 16.6573\n","Epoch 631/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6276 - mae: 17.1266_Epoch 631 Results: R2 Score: 0.99992646 MAE: 0.13929375 MSE: 0.16073839\n","\n","Epoch 631: loss improved from 2.63149 to 2.62674, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 63ms/step - loss: 2.6267 - mae: 16.6571\n","Epoch 632/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6240 - mae: 16.5210_Epoch 632 Results: R2 Score: 0.99992791 MAE: 0.13581793 MSE: 0.15756212\n","\n","Epoch 632: loss improved from 2.62674 to 2.62226, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 108ms/step - loss: 2.6223 - mae: 16.6570\n","Epoch 633/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6177 - mae: 15.8745_Epoch 633 Results: R2 Score: 0.99992899 MAE: 0.13655594 MSE: 0.15520655\n","\n","Epoch 633: loss improved from 2.62226 to 2.61653, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 110ms/step - loss: 2.6165 - mae: 16.6568\n","Epoch 634/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6146 - mae: 16.8600_Epoch 634 Results: R2 Score: 0.99993017 MAE: 0.13542141 MSE: 0.15265021\n","\n","Epoch 634: loss improved from 2.61653 to 2.61310, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 38ms/step - loss: 2.6131 - mae: 16.6566\n","Epoch 635/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6104 - mae: 16.3206_Epoch 635 Results: R2 Score: 0.99993119 MAE: 0.13345493 MSE: 0.15039563\n","\n","Epoch 635: loss improved from 2.61310 to 2.60921, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 2.6092 - mae: 16.6565\n","Epoch 636/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6058 - mae: 15.5896_Epoch 636 Results: R2 Score: 0.99993251 MAE: 0.12984650 MSE: 0.14751299\n","\n","Epoch 636: loss improved from 2.60921 to 2.60407, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 2.6041 - mae: 16.6563\n","Epoch 637/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.6001 - mae: 16.6237_Epoch 637 Results: R2 Score: 0.99993346 MAE: 0.13002545 MSE: 0.14542858\n","\n","Epoch 637: loss improved from 2.60407 to 2.59999, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 57ms/step - loss: 2.6000 - mae: 16.6561\n","Epoch 638/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5968 - mae: 16.2549_Epoch 638 Results: R2 Score: 0.99993470 MAE: 0.12510987 MSE: 0.14273672\n","\n","Epoch 638: loss improved from 2.59999 to 2.59502, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 72ms/step - loss: 2.5950 - mae: 16.6559\n","Epoch 639/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5905 - mae: 19.6042_Epoch 639 Results: R2 Score: 0.99993565 MAE: 0.12542903 MSE: 0.14065281\n","\n","Epoch 639: loss improved from 2.59502 to 2.58983, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 144ms/step - loss: 2.5898 - mae: 16.6558\n","Epoch 640/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5874 - mae: 14.6324_Epoch 640 Results: R2 Score: 0.99993657 MAE: 0.12510765 MSE: 0.13865222\n","\n","Epoch 640: loss improved from 2.58983 to 2.58654, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 89ms/step - loss: 2.5865 - mae: 16.6556\n","Epoch 641/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5841 - mae: 15.0677_Epoch 641 Results: R2 Score: 0.99993759 MAE: 0.12415735 MSE: 0.13642590\n","\n","Epoch 641: loss improved from 2.58654 to 2.58276, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 2.5828 - mae: 16.6555\n","Epoch 642/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5801 - mae: 16.2870_Epoch 642 Results: R2 Score: 0.99993822 MAE: 0.12841672 MSE: 0.13506302\n","\n","Epoch 642: loss improved from 2.58276 to 2.57928, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 2.5793 - mae: 16.6553\n","Epoch 643/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5796 - mae: 17.4498_Epoch 643 Results: R2 Score: 0.99993969 MAE: 0.12072720 MSE: 0.13182352\n","\n","Epoch 643: loss improved from 2.57928 to 2.57677, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 2.5768 - mae: 16.6551\n","Epoch 644/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5713 - mae: 17.0081_Epoch 644 Results: R2 Score: 0.99994046 MAE: 0.12203533 MSE: 0.13014728\n","\n","Epoch 644: loss improved from 2.57677 to 2.56987, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 2.5699 - mae: 16.6549\n","Epoch 645/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5692 - mae: 15.1089_Epoch 645 Results: R2 Score: 0.99994137 MAE: 0.12122516 MSE: 0.12815624\n","\n","Epoch 645: loss improved from 2.56987 to 2.56902, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 73ms/step - loss: 2.5690 - mae: 16.6548\n","Epoch 646/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5657 - mae: 17.7531_Epoch 646 Results: R2 Score: 0.99994276 MAE: 0.11620887 MSE: 0.12511611\n","\n","Epoch 646: loss improved from 2.56902 to 2.56384, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 60ms/step - loss: 2.5638 - mae: 16.6546\n","Epoch 647/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5590 - mae: 17.2142_Epoch 647 Results: R2 Score: 0.99994296 MAE: 0.12103263 MSE: 0.12469015\n","\n","Epoch 647: loss improved from 2.56384 to 2.55931, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 78ms/step - loss: 2.5593 - mae: 16.6545\n","Epoch 648/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5595 - mae: 16.4884_Epoch 648 Results: R2 Score: 0.99994454 MAE: 0.11465834 MSE: 0.12125284\n","\n","Epoch 648: loss improved from 2.55931 to 2.55742, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 115ms/step - loss: 2.5574 - mae: 16.6542\n","Epoch 649/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5518 - mae: 16.8203_Epoch 649 Results: R2 Score: 0.99994530 MAE: 0.11455657 MSE: 0.11957549\n","\n","Epoch 649: loss improved from 2.55742 to 2.55093, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 2.5509 - mae: 16.6541\n","Epoch 650/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5491 - mae: 16.8935_Epoch 650 Results: R2 Score: 0.99994596 MAE: 0.11247925 MSE: 0.11813141\n","\n","Epoch 650: loss improved from 2.55093 to 2.54889, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 2.5489 - mae: 16.6540\n","Epoch 651/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5455 - mae: 16.9563_Epoch 651 Results: R2 Score: 0.99994728 MAE: 0.11004794 MSE: 0.11523658\n","\n","Epoch 651: loss improved from 2.54889 to 2.54431, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 94ms/step - loss: 2.5443 - mae: 16.6538\n","Epoch 652/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5400 - mae: 16.1974_Epoch 652 Results: R2 Score: 0.99994821 MAE: 0.10658410 MSE: 0.11322629\n","\n","Epoch 652: loss improved from 2.54431 to 2.53897, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 64ms/step - loss: 2.5390 - mae: 16.6537\n","Epoch 653/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5351 - mae: 16.6832_Epoch 653 Results: R2 Score: 0.99994886 MAE: 0.10538576 MSE: 0.11180012\n","\n","Epoch 653: loss improved from 2.53897 to 2.53476, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 2.5348 - mae: 16.6535\n","Epoch 654/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5320 - mae: 15.6555_Epoch 654 Results: R2 Score: 0.99994961 MAE: 0.10772755 MSE: 0.11016653\n","\n","Epoch 654: loss improved from 2.53476 to 2.53179, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 108ms/step - loss: 2.5318 - mae: 16.6533\n","Epoch 655/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5304 - mae: 16.3020_Epoch 655 Results: R2 Score: 0.99995003 MAE: 0.10943766 MSE: 0.10924795\n","\n","Epoch 655: loss improved from 2.53179 to 2.53055, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 2.5306 - mae: 16.6532\n","Epoch 656/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5291 - mae: 16.8572_Epoch 656 Results: R2 Score: 0.99995135 MAE: 0.10488357 MSE: 0.10635931\n","\n","Epoch 656: loss improved from 2.53055 to 2.52782, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 2.5278 - mae: 16.6530\n","Epoch 657/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5227 - mae: 16.7915_Epoch 657 Results: R2 Score: 0.99995206 MAE: 0.10345075 MSE: 0.10480981\n","\n","Epoch 657: loss improved from 2.52782 to 2.52164, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 144ms/step - loss: 2.5216 - mae: 16.6528\n","Epoch 658/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5191 - mae: 16.5567_Epoch 658 Results: R2 Score: 0.99995282 MAE: 0.10227185 MSE: 0.10315367\n","\n","Epoch 658: loss improved from 2.52164 to 2.51821, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 72ms/step - loss: 2.5182 - mae: 16.6526\n","Epoch 659/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5157 - mae: 17.2757_Epoch 659 Results: R2 Score: 0.99995368 MAE: 0.10079779 MSE: 0.10127462\n","\n","Epoch 659: loss improved from 2.51821 to 2.51459, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 2.5146 - mae: 16.6525\n","Epoch 660/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5116 - mae: 15.9175_Epoch 660 Results: R2 Score: 0.99995430 MAE: 0.10048159 MSE: 0.09991182\n","\n","Epoch 660: loss improved from 2.51459 to 2.51068, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 2.5107 - mae: 16.6523\n","Epoch 661/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5090 - mae: 17.3172_Epoch 661 Results: R2 Score: 0.99995474 MAE: 0.10373095 MSE: 0.09895616\n","\n","Epoch 661: loss improved from 2.51068 to 2.50860, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 113ms/step - loss: 2.5086 - mae: 16.6521\n","Epoch 662/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5087 - mae: 17.7499_Epoch 662 Results: R2 Score: 0.99995552 MAE: 0.10146993 MSE: 0.09724370\n","\n","Epoch 662: loss improved from 2.50860 to 2.50765, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 108ms/step - loss: 2.5076 - mae: 16.6520\n","Epoch 663/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.5047 - mae: 17.5867_Epoch 663 Results: R2 Score: 0.99995653 MAE: 0.09750669 MSE: 0.09503295\n","\n","Epoch 663: loss improved from 2.50765 to 2.50303, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 2.5030 - mae: 16.6518\n","Epoch 664/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4992 - mae: 18.7884_Epoch 664 Results: R2 Score: 0.99995704 MAE: 0.09755669 MSE: 0.09393501\n","\n","Epoch 664: loss improved from 2.50303 to 2.49852, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 114ms/step - loss: 2.4985 - mae: 16.6516\n","Epoch 665/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4969 - mae: 15.7629_Epoch 665 Results: R2 Score: 0.99995757 MAE: 0.09841244 MSE: 0.09276068\n","\n","Epoch 665: loss improved from 2.49852 to 2.49633, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 109ms/step - loss: 2.4963 - mae: 16.6515\n","Epoch 666/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4950 - mae: 16.2787_Epoch 666 Results: R2 Score: 0.99995833 MAE: 0.09762584 MSE: 0.09111232\n","\n","Epoch 666: loss improved from 2.49633 to 2.49614, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 132ms/step - loss: 2.4961 - mae: 16.6513\n","Epoch 667/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4916 - mae: 17.1571_Epoch 667 Results: R2 Score: 0.99995914 MAE: 0.09402963 MSE: 0.08934126\n","\n","Epoch 667: loss improved from 2.49614 to 2.48997, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 59ms/step - loss: 2.4900 - mae: 16.6511\n","Epoch 668/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4871 - mae: 15.1645_Epoch 668 Results: R2 Score: 0.99995925 MAE: 0.09892104 MSE: 0.08910476\n","\n","Epoch 668: loss improved from 2.48997 to 2.48642, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 117ms/step - loss: 2.4864 - mae: 16.6510\n","Epoch 669/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4879 - mae: 17.7905_Epoch 669 Results: R2 Score: 0.99996033 MAE: 0.09381115 MSE: 0.08674241\n","\n","Epoch 669: loss did not improve from 2.48642\n","2/2 [==============================] - 0s 39ms/step - loss: 2.4872 - mae: 16.6508\n","Epoch 670/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4818 - mae: 16.9394_Epoch 670 Results: R2 Score: 0.99996104 MAE: 0.09142733 MSE: 0.08517048\n","\n","Epoch 670: loss improved from 2.48642 to 2.48074, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 2.4807 - mae: 16.6506\n","Epoch 671/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4780 - mae: 14.9611_Epoch 671 Results: R2 Score: 0.99996149 MAE: 0.09303120 MSE: 0.08419845\n","\n","Epoch 671: loss improved from 2.48074 to 2.47782, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 74ms/step - loss: 2.4778 - mae: 16.6505\n","Epoch 672/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4764 - mae: 16.7051_Epoch 672 Results: R2 Score: 0.99996178 MAE: 0.09573712 MSE: 0.08357190\n","\n","Epoch 672: loss improved from 2.47782 to 2.47696, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 87ms/step - loss: 2.4770 - mae: 16.6502\n","Epoch 673/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4761 - mae: 16.9709_Epoch 673 Results: R2 Score: 0.99996312 MAE: 0.08843809 MSE: 0.08065104\n","\n","Epoch 673: loss improved from 2.47696 to 2.47451, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 76ms/step - loss: 2.4745 - mae: 16.6501\n","Epoch 674/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4684 - mae: 16.6346_Epoch 674 Results: R2 Score: 0.99996274 MAE: 0.09677692 MSE: 0.08148331\n","\n","Epoch 674: loss improved from 2.47451 to 2.46822, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 2.4682 - mae: 16.6500\n","Epoch 675/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4720 - mae: 16.7801_Epoch 675 Results: R2 Score: 0.99996363 MAE: 0.09356530 MSE: 0.07953965\n","\n","Epoch 675: loss did not improve from 2.46822\n","2/2 [==============================] - 0s 106ms/step - loss: 2.4710 - mae: 16.6497\n","Epoch 676/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4672 - mae: 16.9876_Epoch 676 Results: R2 Score: 0.99996435 MAE: 0.09131698 MSE: 0.07793663\n","\n","Epoch 676: loss improved from 2.46822 to 2.46509, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 115ms/step - loss: 2.4651 - mae: 16.6496\n","Epoch 677/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4633 - mae: 16.5577_Epoch 677 Results: R2 Score: 0.99996477 MAE: 0.09042354 MSE: 0.07703526\n","\n","Epoch 677: loss improved from 2.46509 to 2.46319, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 2.4632 - mae: 16.6494\n","Epoch 678/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4608 - mae: 16.6847_Epoch 678 Results: R2 Score: 0.99996573 MAE: 0.08650439 MSE: 0.07493865\n","\n","Epoch 678: loss improved from 2.46319 to 2.46007, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 84ms/step - loss: 2.4601 - mae: 16.6492\n","Epoch 679/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4554 - mae: 17.2147_Epoch 679 Results: R2 Score: 0.99996627 MAE: 0.08408134 MSE: 0.07375798\n","\n","Epoch 679: loss improved from 2.46007 to 2.45460, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 2.4546 - mae: 16.6491\n","Epoch 680/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4520 - mae: 15.9495_Epoch 680 Results: R2 Score: 0.99996573 MAE: 0.09486554 MSE: 0.07494708\n","\n","Epoch 680: loss improved from 2.45460 to 2.45368, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 89ms/step - loss: 2.4537 - mae: 16.6489\n","Epoch 681/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4573 - mae: 17.1915_Epoch 681 Results: R2 Score: 0.99996730 MAE: 0.08500756 MSE: 0.07149918\n","\n","Epoch 681: loss did not improve from 2.45368\n","2/2 [==============================] - 0s 73ms/step - loss: 2.4538 - mae: 16.6487\n","Epoch 682/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4480 - mae: 18.1472_Epoch 682 Results: R2 Score: 0.99996760 MAE: 0.08600689 MSE: 0.07083581\n","\n","Epoch 682: loss improved from 2.45368 to 2.44734, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 2.4473 - mae: 16.6486\n","Epoch 683/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4465 - mae: 16.3415_Epoch 683 Results: R2 Score: 0.99996844 MAE: 0.08118296 MSE: 0.06900423\n","\n","Epoch 683: loss improved from 2.44734 to 2.44492, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 2.4449 - mae: 16.6484\n","Epoch 684/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4411 - mae: 15.8439_Epoch 684 Results: R2 Score: 0.99996906 MAE: 0.07929775 MSE: 0.06766830\n","\n","Epoch 684: loss improved from 2.44492 to 2.44205, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 146ms/step - loss: 2.4420 - mae: 16.6482\n","Epoch 685/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4377 - mae: 16.1266_Epoch 685 Results: R2 Score: 0.99996947 MAE: 0.07832742 MSE: 0.06676511\n","\n","Epoch 685: loss improved from 2.44205 to 2.43728, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 79ms/step - loss: 2.4373 - mae: 16.6481\n","Epoch 686/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4350 - mae: 14.8483_Epoch 686 Results: R2 Score: 0.99996993 MAE: 0.07923212 MSE: 0.06576989\n","\n","Epoch 686: loss improved from 2.43728 to 2.43484, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 90ms/step - loss: 2.4348 - mae: 16.6479\n","Epoch 687/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4334 - mae: 17.3968_Epoch 687 Results: R2 Score: 0.99997010 MAE: 0.08082934 MSE: 0.06539180\n","\n","Epoch 687: loss improved from 2.43484 to 2.43305, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 2.4331 - mae: 16.6477\n","Epoch 688/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4325 - mae: 15.8828_Epoch 688 Results: R2 Score: 0.99997030 MAE: 0.08485807 MSE: 0.06493864\n","\n","Epoch 688: loss did not improve from 2.43305\n","2/2 [==============================] - 0s 41ms/step - loss: 2.4337 - mae: 16.6476\n","Epoch 689/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4327 - mae: 17.4858_Epoch 689 Results: R2 Score: 0.99997100 MAE: 0.07936604 MSE: 0.06342981\n","\n","Epoch 689: loss improved from 2.43305 to 2.43130, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 88ms/step - loss: 2.4313 - mae: 16.6474\n","Epoch 690/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4273 - mae: 15.4782_Epoch 690 Results: R2 Score: 0.99997149 MAE: 0.07835780 MSE: 0.06234728\n","\n","Epoch 690: loss improved from 2.43130 to 2.42569, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 66ms/step - loss: 2.4257 - mae: 16.6472\n","Epoch 691/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4248 - mae: 16.4275_Epoch 691 Results: R2 Score: 0.99997173 MAE: 0.08120652 MSE: 0.06183683\n","\n","Epoch 691: loss improved from 2.42569 to 2.42456, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 77ms/step - loss: 2.4246 - mae: 16.6471\n","Epoch 692/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4243 - mae: 15.4981_Epoch 692 Results: R2 Score: 0.99997218 MAE: 0.08028162 MSE: 0.06084004\n","\n","Epoch 692: loss improved from 2.42456 to 2.42406, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 2.4241 - mae: 16.6469\n","Epoch 693/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4215 - mae: 17.4920_Epoch 693 Results: R2 Score: 0.99997270 MAE: 0.07726395 MSE: 0.05969571\n","\n","Epoch 693: loss improved from 2.42406 to 2.42013, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 2.4201 - mae: 16.6467\n","Epoch 694/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4177 - mae: 16.0966_Epoch 694 Results: R2 Score: 0.99997299 MAE: 0.08010976 MSE: 0.05906629\n","\n","Epoch 694: loss improved from 2.42013 to 2.41682, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 2.4168 - mae: 16.6465\n","Epoch 695/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4174 - mae: 15.3112_Epoch 695 Results: R2 Score: 0.99997319 MAE: 0.08067328 MSE: 0.05861757\n","\n","Epoch 695: loss did not improve from 2.41682\n","2/2 [==============================] - 0s 76ms/step - loss: 2.4185 - mae: 16.6464\n","Epoch 696/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4157 - mae: 18.1925_Epoch 696 Results: R2 Score: 0.99997423 MAE: 0.07405455 MSE: 0.05635401\n","\n","Epoch 696: loss improved from 2.41682 to 2.41308, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 2.4131 - mae: 16.6462\n","Epoch 697/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4091 - mae: 16.0947_Epoch 697 Results: R2 Score: 0.99997424 MAE: 0.07696776 MSE: 0.05632884\n","\n","Epoch 697: loss improved from 2.41308 to 2.40936, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 74ms/step - loss: 2.4094 - mae: 16.6460\n","Epoch 698/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4095 - mae: 17.7273_Epoch 698 Results: R2 Score: 0.99997458 MAE: 0.07645126 MSE: 0.05560451\n","\n","Epoch 698: loss did not improve from 2.40936\n","2/2 [==============================] - 0s 74ms/step - loss: 2.4097 - mae: 16.6459\n","Epoch 699/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4071 - mae: 15.5000_Epoch 699 Results: R2 Score: 0.99997497 MAE: 0.07565336 MSE: 0.05474775\n","\n","Epoch 699: loss improved from 2.40936 to 2.40776, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 56ms/step - loss: 2.4078 - mae: 16.6457\n","Epoch 700/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4045 - mae: 17.4825_Epoch 700 Results: R2 Score: 0.99997576 MAE: 0.07109234 MSE: 0.05300752\n","\n","Epoch 700: loss improved from 2.40776 to 2.40259, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 62ms/step - loss: 2.4026 - mae: 16.6455\n","Epoch 701/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3995 - mae: 18.7556_Epoch 701 Results: R2 Score: 0.99997519 MAE: 0.08115484 MSE: 0.05426110\n","\n","Epoch 701: loss improved from 2.40259 to 2.40007, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 86ms/step - loss: 2.4001 - mae: 16.6454\n","Epoch 702/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.4045 - mae: 17.5663_Epoch 702 Results: R2 Score: 0.99997598 MAE: 0.07570045 MSE: 0.05253649\n","\n","Epoch 702: loss did not improve from 2.40007\n","2/2 [==============================] - 0s 40ms/step - loss: 2.4055 - mae: 16.6452\n","Epoch 703/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3987 - mae: 16.8925_Epoch 703 Results: R2 Score: 0.99997660 MAE: 0.07225732 MSE: 0.05117851\n","\n","Epoch 703: loss improved from 2.40007 to 2.39673, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 61ms/step - loss: 2.3967 - mae: 16.6450\n","Epoch 704/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3944 - mae: 16.2349_Epoch 704 Results: R2 Score: 0.99997634 MAE: 0.07742434 MSE: 0.05175647\n","\n","Epoch 704: loss improved from 2.39673 to 2.39391, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 68ms/step - loss: 2.3939 - mae: 16.6448\n","Epoch 705/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3961 - mae: 16.1742_Epoch 705 Results: R2 Score: 0.99997711 MAE: 0.07384764 MSE: 0.05007192\n","\n","Epoch 705: loss did not improve from 2.39391\n","2/2 [==============================] - 0s 60ms/step - loss: 2.3960 - mae: 16.6447\n","Epoch 706/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3917 - mae: 15.4224_Epoch 706 Results: R2 Score: 0.99997741 MAE: 0.07317284 MSE: 0.04941891\n","\n","Epoch 706: loss improved from 2.39391 to 2.39012, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 51ms/step - loss: 2.3901 - mae: 16.6445\n","Epoch 707/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3895 - mae: 15.8418_Epoch 707 Results: R2 Score: 0.99997763 MAE: 0.07501932 MSE: 0.04891698\n","\n","Epoch 707: loss improved from 2.39012 to 2.38785, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 2.3878 - mae: 16.6443\n","Epoch 708/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3886 - mae: 15.9763_Epoch 708 Results: R2 Score: 0.99997750 MAE: 0.08037931 MSE: 0.04920307\n","\n","Epoch 708: loss did not improve from 2.38785\n","2/2 [==============================] - 0s 74ms/step - loss: 2.3883 - mae: 16.6441\n","Epoch 709/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3905 - mae: 15.7231_Epoch 709 Results: R2 Score: 0.99997850 MAE: 0.07277347 MSE: 0.04703748\n","\n","Epoch 709: loss did not improve from 2.38785\n","2/2 [==============================] - 0s 35ms/step - loss: 2.3886 - mae: 16.6440\n","Epoch 710/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3833 - mae: 15.7666_Epoch 710 Results: R2 Score: 0.99997904 MAE: 0.06889873 MSE: 0.04585311\n","\n","Epoch 710: loss improved from 2.38785 to 2.38104, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 75ms/step - loss: 2.3810 - mae: 16.6438\n","Epoch 711/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3787 - mae: 16.2913_Epoch 711 Results: R2 Score: 0.99997859 MAE: 0.07641190 MSE: 0.04683327\n","\n","Epoch 711: loss improved from 2.38104 to 2.37959, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 115ms/step - loss: 2.3796 - mae: 16.6436\n","Epoch 712/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3823 - mae: 16.1766_Epoch 712 Results: R2 Score: 0.99997945 MAE: 0.06880099 MSE: 0.04494655\n","\n","Epoch 712: loss did not improve from 2.37959\n","2/2 [==============================] - 0s 41ms/step - loss: 2.3817 - mae: 16.6435\n","Epoch 713/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3755 - mae: 16.9298_Epoch 713 Results: R2 Score: 0.99998022 MAE: 0.06458218 MSE: 0.04326282\n","\n","Epoch 713: loss improved from 2.37959 to 2.37329, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 53ms/step - loss: 2.3733 - mae: 16.6433\n","Epoch 714/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3706 - mae: 15.2787_Epoch 714 Results: R2 Score: 0.99997983 MAE: 0.07088353 MSE: 0.04412397\n","\n","Epoch 714: loss improved from 2.37329 to 2.37081, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 2.3708 - mae: 16.6431\n","Epoch 715/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3734 - mae: 16.5769_Epoch 715 Results: R2 Score: 0.99998020 MAE: 0.07190587 MSE: 0.04330212\n","\n","Epoch 715: loss did not improve from 2.37081\n","2/2 [==============================] - 0s 69ms/step - loss: 2.3736 - mae: 16.6430\n","Epoch 716/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3716 - mae: 17.9339_Epoch 716 Results: R2 Score: 0.99998048 MAE: 0.07098003 MSE: 0.04268544\n","\n","Epoch 716: loss improved from 2.37081 to 2.37011, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 115ms/step - loss: 2.3701 - mae: 16.6428\n","Epoch 717/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3695 - mae: 16.8807_Epoch 717 Results: R2 Score: 0.99998081 MAE: 0.06860490 MSE: 0.04197548\n","\n","Epoch 717: loss improved from 2.37011 to 2.37008, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 2.3701 - mae: 16.6426\n","Epoch 718/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3663 - mae: 16.0920_Epoch 718 Results: R2 Score: 0.99998113 MAE: 0.06814160 MSE: 0.04127357\n","\n","Epoch 718: loss improved from 2.37008 to 2.36683, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 85ms/step - loss: 2.3668 - mae: 16.6424\n","Epoch 719/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3641 - mae: 18.0348_Epoch 719 Results: R2 Score: 0.99998146 MAE: 0.06742815 MSE: 0.04054627\n","\n","Epoch 719: loss improved from 2.36683 to 2.36366, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 55ms/step - loss: 2.3637 - mae: 16.6423\n","Epoch 720/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3618 - mae: 16.1890_Epoch 720 Results: R2 Score: 0.99998199 MAE: 0.06376496 MSE: 0.03940098\n","\n","Epoch 720: loss improved from 2.36366 to 2.36055, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 93ms/step - loss: 2.3606 - mae: 16.6421\n","Epoch 721/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3576 - mae: 15.7935_Epoch 721 Results: R2 Score: 0.99998178 MAE: 0.06788261 MSE: 0.03984862\n","\n","Epoch 721: loss improved from 2.36055 to 2.35772, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 123ms/step - loss: 2.3577 - mae: 16.6419\n","Epoch 722/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3590 - mae: 17.6436_Epoch 722 Results: R2 Score: 0.99998222 MAE: 0.06670531 MSE: 0.03888459\n","\n","Epoch 722: loss did not improve from 2.35772\n","2/2 [==============================] - 0s 62ms/step - loss: 2.3598 - mae: 16.6417\n","Epoch 723/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3561 - mae: 16.8402_Epoch 723 Results: R2 Score: 0.99998265 MAE: 0.06402213 MSE: 0.03793837\n","\n","Epoch 723: loss improved from 2.35772 to 2.35498, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 92ms/step - loss: 2.3550 - mae: 16.6416\n","Epoch 724/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3528 - mae: 17.0178_Epoch 724 Results: R2 Score: 0.99998198 MAE: 0.07369925 MSE: 0.03941417\n","\n","Epoch 724: loss improved from 2.35498 to 2.35380, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 72ms/step - loss: 2.3538 - mae: 16.6414\n","Epoch 725/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3579 - mae: 18.1901_Epoch 725 Results: R2 Score: 0.99998334 MAE: 0.06258353 MSE: 0.03642885\n","\n","Epoch 725: loss did not improve from 2.35380\n","2/2 [==============================] - 0s 34ms/step - loss: 2.3557 - mae: 16.6413\n","Epoch 726/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3481 - mae: 16.0792_Epoch 726 Results: R2 Score: 0.99998278 MAE: 0.06899539 MSE: 0.03765577\n","\n","Epoch 726: loss improved from 2.35380 to 2.34854, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 49ms/step - loss: 2.3485 - mae: 16.6411\n","Epoch 727/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3512 - mae: 17.2518_Epoch 727 Results: R2 Score: 0.99998323 MAE: 0.06844270 MSE: 0.03668814\n","\n","Epoch 727: loss did not improve from 2.34854\n","2/2 [==============================] - 0s 43ms/step - loss: 2.3523 - mae: 16.6409\n","Epoch 728/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3485 - mae: 15.3530_Epoch 728 Results: R2 Score: 0.99998365 MAE: 0.06419093 MSE: 0.03575708\n","\n","Epoch 728: loss improved from 2.34854 to 2.34541, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 77ms/step - loss: 2.3454 - mae: 16.6407\n","Epoch 729/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3444 - mae: 15.3031_Epoch 729 Results: R2 Score: 0.99998354 MAE: 0.06863835 MSE: 0.03600322\n","\n","Epoch 729: loss did not improve from 2.34541\n","2/2 [==============================] - 0s 52ms/step - loss: 2.3460 - mae: 16.6406\n","Epoch 730/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3456 - mae: 17.3213_Epoch 730 Results: R2 Score: 0.99998448 MAE: 0.06097240 MSE: 0.03395364\n","\n","Epoch 730: loss improved from 2.34541 to 2.34284, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 54ms/step - loss: 2.3428 - mae: 16.6404\n","Epoch 731/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3383 - mae: 16.1930_Epoch 731 Results: R2 Score: 0.99998405 MAE: 0.06642696 MSE: 0.03489645\n","\n","Epoch 731: loss improved from 2.34284 to 2.33873, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 51ms/step - loss: 2.3387 - mae: 16.6402\n","Epoch 732/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3409 - mae: 16.7498_Epoch 732 Results: R2 Score: 0.99998389 MAE: 0.06940425 MSE: 0.03523823\n","\n","Epoch 732: loss did not improve from 2.33873\n","2/2 [==============================] - 0s 44ms/step - loss: 2.3402 - mae: 16.6401\n","Epoch 733/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3419 - mae: 18.0243_Epoch 733 Results: R2 Score: 0.99998452 MAE: 0.06462201 MSE: 0.03387271\n","\n","Epoch 733: loss did not improve from 2.33873\n","2/2 [==============================] - 0s 43ms/step - loss: 2.3425 - mae: 16.6399\n","Epoch 734/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3366 - mae: 16.9953_Epoch 734 Results: R2 Score: 0.99998485 MAE: 0.06417582 MSE: 0.03314063\n","\n","Epoch 734: loss improved from 2.33873 to 2.33446, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 2.3345 - mae: 16.6397\n","Epoch 735/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3343 - mae: 17.5377_Epoch 735 Results: R2 Score: 0.99998500 MAE: 0.06427906 MSE: 0.03280305\n","\n","Epoch 735: loss improved from 2.33446 to 2.33330, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 67ms/step - loss: 2.3333 - mae: 16.6396\n","Epoch 736/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3332 - mae: 16.9534_Epoch 736 Results: R2 Score: 0.99998528 MAE: 0.06462508 MSE: 0.03218823\n","\n","Epoch 736: loss improved from 2.33330 to 2.33320, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 58ms/step - loss: 2.3332 - mae: 16.6394\n","Epoch 737/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3312 - mae: 17.3431_Epoch 737 Results: R2 Score: 0.99998522 MAE: 0.06625468 MSE: 0.03232973\n","\n","Epoch 737: loss improved from 2.33320 to 2.33111, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 112ms/step - loss: 2.3311 - mae: 16.6392\n","Epoch 738/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3311 - mae: 18.2970_Epoch 738 Results: R2 Score: 0.99998590 MAE: 0.06101720 MSE: 0.03085496\n","\n","Epoch 738: loss did not improve from 2.33111\n","2/2 [==============================] - 0s 69ms/step - loss: 2.3311 - mae: 16.6390\n","Epoch 739/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3256 - mae: 14.3841_Epoch 739 Results: R2 Score: 0.99998612 MAE: 0.06061137 MSE: 0.03037589\n","\n","Epoch 739: loss improved from 2.33111 to 2.32414, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 65ms/step - loss: 2.3241 - mae: 16.6389\n","Epoch 740/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3237 - mae: 15.9340_Epoch 740 Results: R2 Score: 0.99998548 MAE: 0.06775843 MSE: 0.03177414\n","\n","Epoch 740: loss improved from 2.32414 to 2.32382, saving model to /home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\n","2/2 [==============================] - 0s 127ms/step - loss: 2.3238 - mae: 16.6387\n","Epoch 741/2000\n","1/2 [==============>...............] - ETA: 0s - loss: 2.3275 - mae: 15.6610"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(X, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m Y \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(Y, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, Y, epochs\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,  callbacks\u001b[39m=\u001b[39;49m[print_callback, checkpoint])\n","File \u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/keras/engine/training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1620\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1621\u001b[0m     }\n\u001b[1;32m   1622\u001b[0m     epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1624\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_epoch_end(epoch, epoch_logs)\n\u001b[1;32m   1625\u001b[0m training_logs \u001b[39m=\u001b[39m epoch_logs\n\u001b[1;32m   1626\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n","File \u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/keras/callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    446\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    447\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 448\u001b[0m     callback\u001b[39m.\u001b[39;49mon_epoch_end(epoch, logs)\n","\u001b[1;32m/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb Cell 17\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# get mae from fx and u_xx\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X21sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m mae \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanAbsoluteError()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X21sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m mae \u001b[39m=\u001b[39m mae(u_xx, fx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X21sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m# get mse from fx and u_xx\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X21sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m mse \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError()\n","File \u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/keras/losses.py:158\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m reduction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_reduction()\n\u001b[1;32m    155\u001b[0m sample_weight \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mapply_valid_mask(\n\u001b[1;32m    156\u001b[0m     losses, sample_weight, mask, reduction\n\u001b[1;32m    157\u001b[0m )\n\u001b[0;32m--> 158\u001b[0m \u001b[39mreturn\u001b[39;00m losses_utils\u001b[39m.\u001b[39;49mcompute_weighted_loss(\n\u001b[1;32m    159\u001b[0m     losses, sample_weight, reduction\u001b[39m=\u001b[39;49mreduction\n\u001b[1;32m    160\u001b[0m )\n","File \u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/keras/utils/losses_utils.py:358\u001b[0m, in \u001b[0;36mcompute_weighted_loss\u001b[0;34m(losses, sample_weight, reduction, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m input_casted:\n\u001b[1;32m    356\u001b[0m     \u001b[39m# Convert the result back to the input type.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(loss, input_dtype)\n\u001b[0;32m--> 358\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7003\u001b[0m, in \u001b[0;36mname_scope_v2.__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m   7002\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, type_arg, value_arg, traceback_arg):\n\u001b[0;32m-> 7003\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exit_fns\u001b[39m.\u001b[39;49mpop()(type_arg, value_arg, traceback_arg)\n\u001b[1;32m   7004\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","checkpoint = ModelCheckpoint(\"/home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_ScaleTanh0.8_2000Epochs.h5\", \n","                             monitor=\"loss\", \n","                             save_best_only=True, \n","                             save_weights_only=True, \n","                             mode=\"min\", verbose=1)\n","\n","# print_callback = LambdaCallback(on_epoch_end=print_values)\n","X = tf.convert_to_tensor(X, dtype=tf.float32)\n","Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n","\n","history = model.fit(X, Y, epochs=2000, batch_size=1000, verbose=1,  callbacks=[print_callback, checkpoint])\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# save best model\n","# model.save(\"/home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_Tanh_1000Epochs.h5\")\n","\n","# load best model\n","model.load_weights(\"/home/reaganwu/Projects/Match/Reagan_Method/Models/Dense_level2_Tanh_1_2000Epochs.h5\")"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n","WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n","Custom Loss on Evaluation: 10481.00390625\n","MAE on Evaluation: 76.57369232177734\n","MSE on Evaluation: 10441.3408203125\n"]}],"source":["# model evaluate on training dataset\n","# model.evaluate(X, Y, verbose=1)\n","X = tf.convert_to_tensor(X, dtype=tf.float32)\n","Evaluation = X\n","\n","# 对u_xx进行计算\n","with tf.GradientTape(persistent=True) as tape:\n","    tape.watch(Evaluation)\n","    u = model(Evaluation)\n","    u_x = tape.gradient(u, Evaluation)\n","    u_xx = tape.gradient(u_x, Evaluation)\n","   \n","u_xx_sum = -tf.reduce_sum(u_xx, axis=1)  # (n,)\n","\n","# 计算 fx（目标值）\n","fx = calculate_fx(Evaluation)\n","# u_xx = tf.reduce_sum(u_xx, axis=1)  # 调整维度\n","\n","# 计算 MAE 和 MSE\n","mae = tf.keras.losses.MeanAbsoluteError()\n","mse = tf.keras.losses.MeanSquaredError()\n","\n","mae_result = mae(u_xx_sum, fx)\n","mse_result = mse(u_xx_sum, fx)\n","\n","# 计算 custom_loss\n","custom_loss_result = custom_loss(fx, u_xx_sum)\n","\n","print(f\"Custom Loss on Evaluation: {custom_loss_result.numpy()}\")\n","print(f\"MAE on Evaluation: {mae_result.numpy()}\")\n","print(f\"MSE on Evaluation: {mse_result.numpy()}\")\n","\n"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1000,)\n"]},{"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 1000 values, but the requested shape has 5000 [Op:Reshape]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[1;32m/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fx \u001b[39m=\u001b[39m calculate_fx(X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(fx\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fx \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mreshape(fx, (\u001b[39m5000\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m Y \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(Y, (\u001b[39m5000\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/reaganwu/Projects/Match/Reagan_Method/Poisson_10Level_AdvV2.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(Y\u001b[39m.\u001b[39mshape)\n","File \u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/miniconda3/envs/match/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 1000 values, but the requested shape has 5000 [Op:Reshape]"]}],"source":["fx = calculate_fx(X)\n","print(fx.shape)\n","fx = tf.reshape(fx, (5000, 1))\n","\n","Y = tf.reshape(Y, (5000, 1))\n","print(Y.shape)\n","\n","# calculate u and Y difference\n","var = np.abs(fx - Y)\n","\n","print(var)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1048576, 10)\n","(1048576,)\n"]}],"source":["print(X_test.shape)\n","print(X_label.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Test for training dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model evaluate on training dataset\n","# model.evaluate(X, Y, verbose=1)\n","X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n","Evaluation_Test = X_test\n","\n","batch_size = 32\n","\n","for i in range(0, len(X_test), batch_size):\n","    batch_x = X_test[i:i + batch_size]\n","\n","    # 对u_xx进行计算\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch(batch_x)\n","        u = model(batch_x)\n","        u_x = tape.gradient(u, batch_x)\n","        u_xx = tape.gradient(u_x, batch_x)\n","\n","    u_xx_sum = -tf.reduce_sum(u_xx, axis=1)  # (n,)\n","\n","    # 计算 fx（目标值）\n","    fx = calculate_fx(batch_x)\n","    # u_xx = tf.reduce_sum(u_xx, axis=1)  # 调整维度\n","\n","    # 计算 MAE 和 MSE\n","    mae = tf.keras.losses.MeanAbsoluteError()\n","    mse = tf.keras.losses.MeanSquaredError()\n","\n","    mae_result = mae(u_xx_sum, fx)\n","    mse_result = mse(u_xx_sum, fx)\n","\n","    custom_result = mae(u, fx)\n","    # 计算 custom_loss\n","    # custom_loss_result = custom_loss(fx, u_xx_sum)\n","\n","    print(f\"Custom Loss on Evaluation: {custom_result.numpy()}\")\n","    print(f\"MAE on Evaluation: {mae_result.numpy()}\")\n","    print(f\"MSE on Evaluation: {mse_result.numpy()}\")\n","\n","\n"]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample 1:\n","\n","  Input Features: [ 0.38066748 -0.11779924  0.49182895 -0.28236443  0.6984869   0.27163818\n"," -0.16516867 -0.99390054  0.03281171 -0.37720427]\n","  u_xx (Second Derivative): 0.25995445251464844\n","  fx (Target Value): 0.27659469842910767\n","  true label: 0.27659469842910767\n","Sample 2:\n","\n","  Input Features: [-0.7819005   0.60252035 -0.07623412 -0.41566762  0.5154711   0.2847628\n","  0.5363898  -0.94055295  0.16329856 -0.58253396]\n","  u_xx (Second Derivative): 7.866493225097656\n","  fx (Target Value): 7.901674270629883\n","  true label: 7.901674270629883\n","Sample 3:\n","\n","  Input Features: [ 0.3912849  -0.887194    0.34508973  0.51839685 -0.9987569  -0.1926932\n","  0.672494   -0.6173878  -0.5921433   0.14394332]\n","  u_xx (Second Derivative): 2.4057388305664062\n","  fx (Target Value): 2.4587996006011963\n","  true label: 2.4587996006011963\n","Sample 4:\n","\n","  Input Features: [ 0.9163202  -0.27283478 -0.7805259  -0.79065853 -0.39624092 -0.08022989\n"," -0.6982708   0.71994174  0.07583103  0.7517782 ]\n","  u_xx (Second Derivative): -0.19415855407714844\n","  fx (Target Value): -0.2355443686246872\n","  true label: -0.2355443686246872\n","Sample 5:\n","\n","  Input Features: [ 0.61049145  0.41157383 -0.22056699 -0.30773267 -0.71905434 -0.8254603\n"," -0.7479095  -0.30258977  0.18089248 -0.6890236 ]\n","  u_xx (Second Derivative): 0.6310806274414062\n","  fx (Target Value): 0.8774973750114441\n","  true label: 0.8774973750114441\n","Sample 6:\n","\n","  Input Features: [ 0.91986173 -0.7826049   0.13097575  0.37468544 -0.9735684  -0.33711344\n","  0.6398549  -0.6416207  -0.78033215  0.6006738 ]\n","  u_xx (Second Derivative): 52.28007507324219\n","  fx (Target Value): 52.401851654052734\n","  true label: 52.401851654052734\n","Sample 7:\n","\n","  Input Features: [-0.6577639  -0.20698534 -0.8773979  -0.8583666  -0.9257719  -0.7983944\n","  0.9981874  -0.06208178 -0.20971851 -0.5055096 ]\n","  u_xx (Second Derivative): -0.14073562622070312\n","  fx (Target Value): -0.1795736402273178\n","  true label: -0.1795736402273178\n","Sample 8:\n","\n","  Input Features: [ 0.9389831   0.28249028 -0.9338973   0.76895565  0.45425653  0.569263\n"," -0.34139064 -0.4663546  -0.9033295   0.93516314]\n","  u_xx (Second Derivative): 8.063742637634277\n","  fx (Target Value): 8.040839195251465\n","  true label: 8.040839195251465\n","Sample 9:\n","\n","  Input Features: [-0.12481789  0.8019618   0.602031    0.29908007  0.5268174   0.8762694\n","  0.06040727 -0.27766296 -0.8091599   0.40473753]\n","  u_xx (Second Derivative): 26.0488338470459\n","  fx (Target Value): 25.98316192626953\n","  true label: 25.98316192626953\n","Sample 10:\n","\n","  Input Features: [-0.46110213  0.8453991  -0.9781682   0.00317403 -0.27398485 -0.2423396\n"," -0.83897    -0.9380443  -0.70274955 -0.76756394]\n","  u_xx (Second Derivative): 0.16273856163024902\n","  fx (Target Value): 0.016470255330204964\n","  true label: 0.016470255330204964\n"]}],"source":["def calculate_fx(X):\n","    # 判断是否有1和-1的边界情况\n","    has_boundary = tf.reduce_any(tf.math.logical_or(X == -1, X == 1))\n","\n","    if has_boundary:\n","        # 如果有边界情况，将fx置零\n","        fx = tf.constant(0.0, dtype=tf.float32)\n","    else:\n","        # 否则计算正常的fx\n","        fx = -160 * tf.constant(np.pi, dtype=tf.float32)**2 * tf.reduce_prod(tf.math.sin(4 * tf.constant(np.pi, dtype=tf.float32) * X), axis=-1)\n","\n","    return fx\n","\n","begin = 40  # 假设您想查看前10个样本\n","end = 50\n","# 从测试数据中挑选前n个样本\n","X = tf.convert_to_tensor(X, dtype=tf.float32)\n","Y = tf.convert_to_tensor(Y, dtype=tf.float32)\n","# selected = X[begin:end]\n","# selected_label = Y[begin:end]\n","selected = X\n","selected_label = Y\n","\n","# # 对u_xx进行计算\n","with tf.GradientTape(persistent=True) as tape:\n","    tape.watch(X)\n","    u = model(X)\n","    u_x = tape.gradient(u, X)\n","    u_xx = tape.gradient(u_x, X)\n","    fx = calculate_fx(X)\n","    fx = tf.convert_to_tensor(fx, dtype=tf.float32)  # 将fx转换为张量\n","u_xx_s = - tf.reduce_sum(u_xx, axis=1)  # 这将将u_xx的维度从 (5000, 10) 调整为 (5000,)\n","\n","for i in range(10):\n","    # print(u_xx_sum.shape)\n","    print(f\"Sample {i + 1}:\\n\")\n","    print(f\"  Input Features: {selected[i]}\")\n","    print(f\"  u_xx (Second Derivative): {u_xx_s[i].numpy()}\")\n","    print(f\"  fx (Target Value): {fx[i].numpy()}\")\n","    print(f\"  true label: {selected_label[i].numpy()}\")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["32768/32768 [==============================] - 140s 4ms/step - loss: 0.4003\n","测试集损失: 0.4003188908100128\n"]}],"source":["# # 评估模型\n","# test_loss = model.evaluate(X_test, X_label, verbose=1)\n","# print(\"测试集损失:\", test_loss)"]},{"cell_type":"markdown","metadata":{},"source":["## Plot for training"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7fb4900bb0a0>]"]},"execution_count":174,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAk8AAAGhCAYAAAB4YVABAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+00lEQVR4nO3de3iU5YH+8TuTECCRmQTFFASMg2VADoZKQDYSTgWNuqgImi2tCUWNGrCcdpWoKAZtCAaERDkEvIRUpYisKKVRlGo2iFZQl3VtpRJA27QxJXEmBHKamd8f/jLrOBzycHiD4fu5Lq44zzzvM897O5fcvvMyhPn9fr8AAADQIrbW3gAAAMAPCeUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAQERrb+Bc4vf75fOdW98ZarOFnXN7asvI2zpkbS3ytg5ZW8tmC1NYWJilr0l5+g6fz6+qqtrW3kZARIRNsbHR8niOqKnJ19rbafPI2zpkbS3ytg5ZW6s5b6vxsR0AAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAByhMAAIAB4/K0b98+TZkyRQkJCUpKSlJubq4aGhqM1nj++eflcrmUkZERNF5VVaUFCxZo0qRJ6t+/vwYNGnTM4x988EG5XK6QXyUlJaanAwAAYCTCZLLb7VZaWpri4+OVn5+viooK5eTkqK6uTvPmzWvRGpWVlXrmmWd04YUXhjxXUVGhrVu3auDAgerfv78+//zz467To0cPPfXUU0FjvXr1MjkdAAAAY0blaf369aqtrVVBQYFiYmIkSV6vV/Pnz1dGRobi4uJOusaiRYs0evRolZeXhzzncrn03nvvSZLy8/NPWJ46dOighIQEk+0DAACcNqOP7UpKSjRs2LBAcZKklJQU+Xw+7dix46TH79q1S2+99ZZmz5597M3YuAULAACc24yuPJWVlenWW28NGrPb7erSpYvKyspOeKzX61V2drbuueceXXzxxeY7/Z6DBw/qqquuUn19vXr37q377rtPP/3pT0973YiIc6fAhYfbgn7i7CJv65C1tcjbOmRtrdbK2ag8eTwe2e32kHGHwyG3233CY1988UUdPXpU6enpRhs8lr59+2rAgAG6/PLLVVNTo5deekmZmZlaunSprrvuulNe12YLU2xs9Gnv70yz2zu29hbOK+RtHbK2Fnlbh6zbNqPydKoOHTqkZcuWaeHChYqMjDzt9dLS0oIejx49WqmpqVq2bNlplSefzy+P58jpbu+MCQ+3yW7vKI/nqLxeX2tvp80jb+uQtbXI2zpkba3mvK1mVJ7sdrtqampCxt1utxwOx3GPW7p0qVwulwYPHiyPxyNJampqUlNTkzwej6KiohQRceo9zmazady4cVq0aJHq6urUoUOHU16rqence7N7vb5zcl9tFXlbh6ytRd7WIeu2zaixOJ3OkHubampqVFlZKafTedzj9u/frw8//FCJiYkhzyUmJqqwsFDJyckmWwEAAGgVRuUpOTlZK1asCLr3qbi4WDabTUlJScc9LisrK3DFqdmTTz6pDh06aNasWXK5XKew9f/j8/lUXFysH//4x6d11QkAAOBkjMpTamqqioqKlJmZqYyMDFVUVCg3N1epqalB3/GUlpam8vJybdu2TdK3N3h/n91uV1RUlIYOHRo0XlxcLEn64osv5PV6A48HDBigSy65RH/729/04IMP6oYbbtCll14qt9utl156SZ9++qny8/PNzh4AAMCQUXlyOBxau3atsrOzlZmZqejoaE2cOFEzZ84Mmufz+eT1ek9pQ7/61a+O+fjXv/61JkyYoOjoaF1wwQVavny5Dh06pHbt2ql///4qLCzU8OHDT+k1AQAAWirM7/f7W3sT5wqv16eqqtrW3kZARIRNsbHRqq6u5cZDC5C3dcjaWuRtHbK2VnPeVuNbvAAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAxQngAAAAwYl6d9+/ZpypQpSkhIUFJSknJzc9XQ0GC0xvPPPy+Xy6WMjIyg8aqqKi1YsECTJk1S//79NWjQoOOusX37do0fP14DBgzQtddeq1deecX0VAAAAIwZlSe32620tDQ1NjYqPz9fM2fO1IYNG5STk9PiNSorK/XMM8/owgsvDHmuoqJCW7du1YUXXqj+/fsfd41du3Zp2rRpSkhIUGFhoVJSUvTQQw+puLjY5HQAAACMRZhMXr9+vWpra1VQUKCYmBhJktfr1fz585WRkaG4uLiTrrFo0SKNHj1a5eXlIc+5XC699957kqT8/Hx9/vnnx1xj+fLlGjhwoB5//HFJ0tVXX62vvvpKy5Yt03XXXWdySgAAAEaMrjyVlJRo2LBhgeIkSSkpKfL5fNqxY8dJj9+1a5feeustzZ49+9ibsZ18Ow0NDfrggw9CStL111+vffv26a9//etJ1wAAADhVRleeysrKdOuttwaN2e12denSRWVlZSc81uv1Kjs7W/fcc48uvvhi853+f19++aUaGxvldDqDxnv16hXYY/fu3U95/YiIc+ce+vBwW9BPnF3kbR2ythZ5W4esrdVaORuVJ4/HI7vdHjLucDjkdrtPeOyLL76oo0ePKj093WiD39f8Ot/fR/Pjk+3jRGy2MMXGRp/65s4Su71ja2/hvELe1iFra5G3dci6bTMqT6fq0KFDWrZsmRYuXKjIyEgrXvKU+Hx+eTxHWnsbAeHhNtntHeXxHJXX62vt7bR55G0dsrYWeVuHrK3VnLfVjMqT3W5XTU1NyLjb7ZbD4TjucUuXLpXL5dLgwYPl8XgkSU1NTWpqapLH41FUVJQiIlq2lebX+f4+mtc90T5aoqnp3Huze72+c3JfbRV5W4esrUXe1iHrts2oPDmdzpB7m2pqalRZWRlyD9J37d+/Xx9++KESExNDnktMTFRhYaGSk5NbtIeePXuqXbt2Kisr0/DhwwPjzfs60T4AAABOl1F5Sk5O1ooVK4LufSouLpbNZlNSUtJxj8vKygpcGWr25JNPqkOHDpo1a5ZcLleL9xAZGamhQ4fqjTfeUFpaWmB869at6tWr12ndLA4AAHAyRuUpNTVVRUVFyszMVEZGhioqKpSbm6vU1NSg73hKS0tTeXm5tm3bJknq27dvyFp2u11RUVEaOnRo0HjzF11+8cUX8nq9gccDBgzQJZdcIkm69957dccdd+ixxx5TSkqKPvjgA23ZskVLliwxOR0AAABjRuXJ4XBo7dq1ys7OVmZmpqKjozVx4kTNnDkzaJ7P55PX6z2lDf3qV7865uNf//rXmjBhgiRp8ODBys/P19NPP62NGzeqW7duWrBggVJSUk7pNQEAAFoqzO/3+1t7E+cKr9enqqra1t5GQESETbGx0aquruXGQwuQt3XI2lrkbR2ytlZz3lbjW7wAAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMUJ4AAAAMGJenffv2acqUKUpISFBSUpJyc3PV0NBgtMbzzz8vl8uljIyMkOcqKio0ffp0DRo0SEOGDNFDDz2kw4cPB8158MEH5XK5Qn6VlJSYng4AAICRCJPJbrdbaWlpio+PV35+vioqKpSTk6O6ujrNmzevRWtUVlbqmWee0YUXXhjyXGNjo+68805JUl5enurq6rRw4ULNnj1bK1euDJrbo0cPPfXUU0FjvXr1MjkdAAAAY0blaf369aqtrVVBQYFiYmIkSV6vV/Pnz1dGRobi4uJOusaiRYs0evRolZeXhzz3xhtv6C9/+Yu2bt0qp9MpSbLb7Zo6dar27NmjgQMHBuZ26NBBCQkJJtsHAAA4bUYf25WUlGjYsGGB4iRJKSkp8vl82rFjx0mP37Vrl9566y3Nnj37uOu7XK5AcZKkpKQkxcTE6N133zXZKgAAwFlhVJ7KysqCio307ZWhLl26qKys7ITHer1eZWdn65577tHFF1/c4vXDwsJ02WWXhax/8OBBXXXVVerfv78mTJigt956y+RUAAAATonRx3Yej0d2uz1k3OFwyO12n/DYF198UUePHlV6evoJ1+/UqdNJ1+/bt68GDBigyy+/XDU1NXrppZeUmZmppUuX6rrrrmv5CR1DRMS58wcQw8NtQT9xdpG3dcjaWuRtHbK2VmvlbFSeTtWhQ4e0bNkyLVy4UJGRkae9XlpaWtDj0aNHKzU1VcuWLTut8mSzhSk2Nvp0t3fG2e0dW3sL5xXytg5ZW4u8rUPWbZtRebLb7aqpqQkZd7vdcjgcxz1u6dKlcrlcGjx4sDwejySpqalJTU1N8ng8ioqKUkREhOx2e8jXEjSv37Vr1+Oub7PZNG7cOC1atEh1dXXq0KGDyWkF+Hx+eTxHTunYsyE83Ca7vaM8nqPyen2tvZ02j7ytQ9bWIm/rkLW1mvO2mlF5cjqdIfce1dTUqLKyMuRepe/av3+/PvzwQyUmJoY8l5iYqMLCQiUnJ8vpdGrv3r1Bz/v9fu3fv19JSUkmWz1lTU3n3pvd6/Wdk/tqq8jbOmRtLfK2Dlm3bUblKTk5WStWrAi696m4uFg2m+2E5SYrKytwxanZk08+qQ4dOmjWrFlyuVyB9V977TUdOHBA8fHxkqSdO3fqm2++0YgRI467vs/nU3FxsX784x+f8lUnAACAljAqT6mpqSoqKlJmZqYyMjJUUVGh3NxcpaamBn3HU1pamsrLy7Vt2zZJ397g/X12u11RUVEaOnRoYOzaa6/VypUrNX36dM2aNUtHjx5Vbm6uRo4cGfiOp7/97W968MEHdcMNN+jSSy+V2+3WSy+9pE8//VT5+fmnFAIAAEBLGZUnh8OhtWvXKjs7W5mZmYqOjtbEiRM1c+bMoHk+n09er9d4M+3atdPq1au1YMECzZo1SxERERo7dqyysrICc6Kjo3XBBRdo+fLlOnTokNq1a6f+/fursLBQw4cPN35NAAAAE2F+v9/f2ps4V3i9PlVV1bb2NgIiImyKjY1WdXUtn51bgLytQ9bWIm/rkLW1mvO2Gl9EAQAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYMC4PO3bt09TpkxRQkKCkpKSlJubq4aGBqM1nn/+eblcLmVkZIQ8V1FRoenTp2vQoEEaMmSIHnroIR0+fDhk3vbt2zV+/HgNGDBA1157rV555RXTUwEAADBmVJ7cbrfS0tLU2Nio/Px8zZw5Uxs2bFBOTk6L16isrNQzzzyjCy+8MOS5xsZG3XnnnTpw4IDy8vL02GOPqbS0VLNnzw6at2vXLk2bNk0JCQkqLCxUSkqKHnroIRUXF5ucDgAAgLEIk8nr169XbW2tCgoKFBMTI0nyer2aP3++MjIyFBcXd9I1Fi1apNGjR6u8vDzkuTfeeEN/+ctftHXrVjmdTkmS3W7X1KlTtWfPHg0cOFCStHz5cg0cOFCPP/64JOnqq6/WV199pWXLlum6664zOSUAAAAjRleeSkpKNGzYsEBxkqSUlBT5fD7t2LHjpMfv2rVLb731VsiVpO+u73K5AsVJkpKSkhQTE6N3331XktTQ0KAPPvggpCRdf/312rdvn/7617+anBIAAIARoytPZWVluvXWW4PG7Ha7unTporKyshMe6/V6lZ2drXvuuUcXX3zxcdf/bnGSpLCwMF122WWB9b/88ks1NjaGzOvVq1dgje7du5ucVpCIiHPnHvrwcFvQT5xd5G0dsrYWeVuHrK3VWjkblSePxyO73R4y7nA45Ha7T3jsiy++qKNHjyo9Pf2E63fq1OmE6zf//P4+mh+fbB8nYrOFKTY2+pSPP1vs9o6tvYXzCnlbh6ytRd7WIeu2zag8napDhw5p2bJlWrhwoSIjI614yVPi8/nl8Rxp7W0EhIfbZLd3lMdzVF6vr7W30+aRt3XI2lrkbR2ytlZz3lYzKk92u101NTUh4263Ww6H47jHLV26VC6XS4MHD5bH45EkNTU1qampSR6PR1FRUYqIiJDdbj/m1xK43W517dpVkgKv8/19NK97on20RFPTufdm93p95+S+2irytg5ZW4u8rUPWbZtReXI6nSH3NtXU1KiysjLkHqTv2r9/vz788EMlJiaGPJeYmKjCwkIlJyfL6XRq7969Qc/7/X7t379fSUlJkqSePXuqXbt2Kisr0/DhwwPzmvd1on0AAACcLqPylJycrBUrVgTd+1RcXCybzRYoN8eSlZUVuDLU7Mknn1SHDh00a9YsuVyuwPqvvfaaDhw4oPj4eEnSzp079c0332jEiBGSpMjISA0dOlRvvPGG0tLSAutt3bpVvXr1Oq2bxQEAAE7GqDylpqaqqKhImZmZysjIUEVFhXJzc5Wamhr0HU9paWkqLy/Xtm3bJEl9+/YNWctutysqKkpDhw4NjF177bVauXKlpk+frlmzZuno0aPKzc3VyJEjA9/xJEn33nuv7rjjDj322GNKSUnRBx98oC1btmjJkiXGAQAAAJgwKk8Oh0Nr165Vdna2MjMzFR0drYkTJ2rmzJlB83w+n7xer/Fm2rVrp9WrV2vBggWaNWuWIiIiNHbsWGVlZQXNGzx4sPLz8/X0009r48aN6tatmxYsWKCUlBTj1wQAADAR5vf7/a29iXOF1+tTVVVta28jICLCptjYaFVX13LjoQXI2zpkbS3ytg5ZW6s5b6vxLV4AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGKE8AAAAGIlp7AwBwNvl9Ph3d+7ma3G5FOBzq2NulMBv/3wjg1FGeALRZNbt3qXL9C2qqrg6MRcTGqkvqZHW6anAr7gzADxn/+wWgTarZvUt/X14QVJwkqam6Wn9fXqCa3btaaWcAfugoTwDaHL/Pp8r1L5xwTuX6F+X3+SzaEYC2hPIEoM05uvfzkCtO39dUXaWjez+3aEcA2hLKE4A2p8ntPqPzAOC7KE8A2pwIh+OMzgOA76I8AWhzOvZ2KSI29oRzImI7q2Nvl0U7AtCWUJ4AtDlhNpu6pE4+4ZwuqT/j+54AnBL+ywGgTep01WB1vXdayBWoiNjO6nrvNL7nCcApM/6SzH379mnBggX6+OOPFR0drZtuukkzZsxQZGTkCY+bM2eO9uzZo6+//lrt2rVT7969de+99+qaa64JWT8nJ0cffvih2rVrp5EjR2ru3Lnq3LlzYM6mTZs0d+7ckNe46667NGfOHNNTAtBGdbpqsC4Y9BO+YRzAGWVUntxut9LS0hQfH6/8/HxVVFQoJydHdXV1mjdv3gmPbWxsVHp6uuLj41VfX6+NGzfq7rvv1rp16zR48Lf/B3j48GGlpaUpLi5OTz31lOrq6rR48WJlZGTot7/9rWzf+w/e6tWr1alTp8DjuLg4k9MBcB4Is9kU1adva28DQBtiVJ7Wr1+v2tpaFRQUKCYmRpLk9Xo1f/58ZWRknLC8LF26NOhxcnKyxowZo82bNwfK04svvqiamhq9+uqruuiiiyRJl156qSZOnKi3335bY8eODVqjX79+QVekAAAAzjaja9clJSUaNmxYoDhJUkpKinw+n3bs2GH0wuHh4erUqZMaGxsDY5999pn69OkTKE6SNGDAAMXExGj79u1G6wMAAJwNRleeysrKdOuttwaN2e12denSRWVlZSc93u/3y+v1qqamRps2bdLBgwf1+OOPB56vr68/5r1TkZGRx1z/xhtvVHV1tbp166bbbrtNd955p8LDw01OKURExLlzL0R4uC3oJ84u8rYOWVuLvK1D1tZqrZyNypPH45Hdbg8Zdzgccrfgm3o3btyohx9+WJIUFRWlJUuWaNCgQYHn4+PjtWnTJtXV1alDhw6SpPLyclVWVioqKiowr0uXLpo+fbquvPJKhYWFafv27Xr66adVUVFx0nuvTsRmC1NsbPQpH3+22O0dW3sL5xXytg5ZW4u8rUPWbZvxn7Y7HWPGjFGfPn1UXV2t4uJizZgxQwUFBRoxYoQkadKkSVq3bp3mzZun2bNnq66uTo888ohsNpvCwsIC6wwfPlzDhw8PPL7mmmvUvn17rV27Vvfcc48uvvjiU9qfz+eXx3Pk9E7yDAoPt8lu7yiP56i8Xv4C07ONvK1D1tYib+uQtbWa87aaUXmy2+2qqakJGXe73XK04K856Ny5c+AG7+TkZLndbi1atChQnpxOp5544gk98cQT2rx5syRp3LhxSk5OVm1t7QnXTklJ0XPPPac//elPp1yeJKmp6dx7s3u9vnNyX20VeVuHrK1F3tYh67bNqDw5nc6Qe49qampUWVkpp9Np/OL9+vVTSUlJ0NjNN9+s66+/XgcOHJDD4VBcXJxuuOEGjR492nh9AACAM83oTqvk5GS999578ng8gbHi4mLZbDYlJSUZv/ju3bvVo0ePkPHIyEj17t1bcXFx2rlzpw4cOKBbbrnlhGtt3bpV4eHhuuKKK4z3AQAA0FJGV55SU1NVVFSkzMxMZWRkqKKiQrm5uUpNTQ36jqe0tDSVl5dr27ZtkqR33nlHr776qkaOHKmuXbvK7XZry5YtKi0t1eLFiwPHHTlyRPn5+UpMTFT79u31ySefaNWqVZo2bVrQla2pU6dq6NChcrm+/Us93377bW3YsEF33HGHunTpclqBAAAAnIhReXI4HFq7dq2ys7OVmZmp6OhoTZw4UTNnzgya5/P55PV6A4979OihhoYG5eXlqbq6WrGxsXK5XCoqKtKQIUMC82w2m/bu3atNmzbpyJEjcjqdevTRRzVhwoSg9S+77DK98sor+sc//iGfz6f4+HhlZWXpF7/4xalkAAAA0GJhfr/f39qbOFd4vT5VVZ34xnQrRUTYFBsbrerqWm48tAB5W4esrUXe1iFrazXnbTW+xQsAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMAA5QkAAMCAcXnat2+fpkyZooSEBCUlJSk3N1cNDQ0nPW7OnDkaN26cEhISlJiYqMmTJ6u0tPSY6991112Bef/+7/+uqqqqM7YPAACA0xFhMtntdistLU3x8fHKz89XRUWFcnJyVFdXp3nz5p3w2MbGRqWnpys+Pl719fXauHGj7r77bq1bt06DBw+WJB0+fFhpaWmKi4vTU089pbq6Oi1evFgZGRn67W9/K5vNdtr7AAAAOB1G5Wn9+vWqra1VQUGBYmJiJEler1fz589XRkaG4uLijnvs0qVLgx4nJydrzJgx2rx5c6A8vfjii6qpqdGrr76qiy66SJJ06aWXauLEiXr77bc1duzY094HAADA6TD62K6kpETDhg0LFBZJSklJkc/n044dO4xeODw8XJ06dVJjY2Ng7LPPPlOfPn0CxUmSBgwYoJiYGG3fvv2s7AMAAMCE0ZWnsrIy3XrrrUFjdrtdXbp0UVlZ2UmP9/v98nq9qqmp0aZNm3Tw4EE9/vjjgefr6+sVGRkZclxkZGTQ+qe7jxOJiDh37qEPD7cF/cTZRd7WIWtrkbd1yNparZWzUXnyeDyy2+0h4w6HQ263+6THb9y4UQ8//LAkKSoqSkuWLNGgQYMCz8fHx2vTpk2qq6tThw4dJEnl5eWqrKxUVFTUGdvH8dhsYYqNjT7l488Wu71ja2/hvELe1iFra5G3dci6bTMqT6drzJgx6tOnj6qrq1VcXKwZM2aooKBAI0aMkCRNmjRJ69at07x58zR79mzV1dXpkUcekc1mU1hY2Fnfn8/nl8dz5Ky/TkuFh9tkt3eUx3NUXq+vtbfT5pG3dcjaWuRtHbK2VnPeVjMqT3a7XTU1NSHjbrdbDofjpMd37txZnTt3lvTtDeNut1uLFi0KlCen06knnnhCTzzxhDZv3ixJGjdunJKTk1VbW3vG9nEiTU3n3pvd6/Wdk/tqq8jbOmRtLfK2Dlm3bUblyel0htxTVFNTo8rKSjmdTuMX79evn0pKSoLGbr75Zl1//fU6cOCAHA6H4uLidMMNN2j06NFnbR8AAAAtZXSnVXJyst577z15PJ7AWHFxsWw2m5KSkoxffPfu3erRo0fIeGRkpHr37q24uDjt3LlTBw4c0C233HLW9gEAANBSRleeUlNTVVRUpMzMTGVkZKiiokK5ublKTU0N+m6ltLQ0lZeXa9u2bZKkd955R6+++qpGjhyprl27yu12a8uWLSotLdXixYsDxx05ckT5+flKTExU+/bt9cknn2jVqlWaNm1a0BWllu4DAADgTDMqTw6HQ2vXrlV2drYyMzMVHR2tiRMnaubMmUHzfD6fvF5v4HGPHj3U0NCgvLw8VVdXKzY2Vi6XS0VFRRoyZEhgns1m0969e7Vp0yYdOXJETqdTjz76qCZMmHBK+wAAADjTwvx+v7+1N3Gu8Hp9qqqqPflEi0RE2BQbG63q6lpuPLQAeVuHrK1F3tYha2s15201vsULAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAAOUJAADAgHF52rdvn6ZMmaKEhAQlJSUpNzdXDQ0NJz1uzpw5GjdunBISEpSYmKjJkyertLQ0ZN7evXuVkZGhq6++WoMHD9bkyZP1/vvvB83Jz8+Xy+UK+fXSSy+Zng4AAICRCJPJbrdbaWlpio+PV35+vioqKpSTk6O6ujrNmzfvhMc2NjYqPT1d8fHxqq+v18aNG3X33Xdr3bp1Gjx4sCSpqqpK6enp6tGjh5544gm1a9dORUVFuuuuu7Rx40a5XK7Aeh06dNDatWuDXqNHjx4mpwMAAGDMqDytX79etbW1KigoUExMjCTJ6/Vq/vz5ysjIUFxc3HGPXbp0adDj5ORkjRkzRps3bw6Up507d+rQoUPasGGDunfvLkkaMmSIhgwZorfeeiuoPNlsNiUkJJhsHwAA4LQZfWxXUlKiYcOGBYqTJKWkpMjn82nHjh1GLxweHq5OnTqpsbExMNb8z506dQqMtW/fXu3atZPf7zdaHwAA4GwwuvJUVlamW2+9NWjMbrerS5cuKisrO+nxfr9fXq9XNTU12rRpkw4ePKjHH3888PyoUaN00UUXKScnRzNnzlRERISee+45hYWF6aabbgpaq66uTldffbU8Ho/i4+OVnp6u2267zeR0jiki4ty5hz483Bb0E2cXeVuHrK1F3tYha2u1Vs5G5cnj8chut4eMOxwOud3ukx6/ceNGPfzww5KkqKgoLVmyRIMGDQpa54UXXlBGRoaGDx8uSYqJiVFhYWHQ/Uw9e/bUnDlzdMUVV6i+vl6vv/66HnnkEdXU1Gjq1KkmpxTEZgtTbGz0KR9/ttjtHVt7C+cV8rYOWVuLvK1D1m2bUXk6XWPGjFGfPn1UXV2t4uJizZgxQwUFBRoxYoQk6dChQ5o2bZp69uyprKwshYeHa8OGDbr33nv1wgsvqFevXpIUchVq5MiRamxs1PLly3XHHXeoXbt2p7Q/n88vj+fI6Z3kGRQebpPd3lEez1F5vb7W3k6bR97WIWtrkbd1yNpazXlbzag82e121dTUhIy73W45HI6THt+5c2d17txZ0rc3jLvdbi1atChQnlavXi23261NmzYpMjJSkjRs2DDdcMMNevbZZ5WXl3fctVNSUvTGG2/oyy+/DJSsU9HUdO692b1e3zm5r7aKvK1D1tYib+uQddtm9GGh0+kMubeppqZGlZWVcjqdxi/er18/HTx4MPD4iy++kNPpDBQn6dsby10ul7788kvj9QEAAM40o/KUnJys9957Tx6PJzBWXFwsm82mpKQk4xffvXt30L1M3bp10759+1RfXx8Y83q9+vOf/6xLLrnkhGtt3bpVdrtdPXv2NN4HAABASxl9bJeamqqioiJlZmYqIyNDFRUVys3NVWpqatB3PKWlpam8vFzbtm2TJL3zzjt69dVXNXLkSHXt2lVut1tbtmxRaWmpFi9eHDhu0qRJ2rhxo+677z5NnjxZ4eHh+u1vf6uDBw9qwYIFgXkTJkzQzTffLKfTqbq6Or3++ut68803lZWVdcr3OwEAALSEUXlyOBxau3atsrOzlZmZqejoaE2cOFEzZ84Mmufz+eT1egOPe/TooYaGBuXl5am6ulqxsbFyuVwqKirSkCFDAvP69++v1atX69lnn9XcuXPl8/l0+eWXa9WqVUpMTAzM69mzp55//nn985//VFhYmHr37q1FixZp/Pjxp5oDAABAi4T5+fbJAK/Xp6qq2tbeRkBEhE2xsdGqrq7lxkMLkLd1yNpa5G0dsrZWc95W41u8AAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADFCeAAAADBiXp3379mnKlClKSEhQUlKScnNz1dDQcNLj5syZo3HjxikhIUGJiYmaPHmySktLQ+bt3btXGRkZuvrqqzV48GBNnjxZ77//fsi8jz76SLfffrsGDhyoUaNGadWqVfL7/aanAwAAYMSoPLndbqWlpamxsVH5+fmaOXOmNmzYoJycnJMe29jYqPT0dD377LPKzc1VTEyM7r77bu3atSswp6qqSunp6frmm2/0xBNPaPHixYqKitJdd92lzz//PDDv4MGDmjp1qrp06aKVK1cqLS1Ny5Yt03PPPWdyOgAAAMYiTCavX79etbW1KigoUExMjCTJ6/Vq/vz5ysjIUFxc3HGPXbp0adDj5ORkjRkzRps3b9bgwYMlSTt37tShQ4e0YcMGde/eXZI0ZMgQDRkyRG+99ZZcLpckac2aNYqNjdXixYsVGRmpYcOGqaqqSitWrNAvfvELRUZGmpwWAABAixldeSopKdGwYcMCxUmSUlJS5PP5tGPHDqMXDg8PV6dOndTY2BgYa/7nTp06Bcbat2+vdu3aBX0kV1JSojFjxgSVpOuvv14ej0cff/yx0T4AAABMGJWnsrIyOZ3OoDG73a4uXbqorKzspMf7/X41NTWpurpaa9as0cGDB3X77bcHnh81apQuuugi5eTk6Ouvv1ZVVZXy8vIUFhamm266SZJ05MgR/f3vfw/Zh9PpVFhYWIv2AQAAcKqMPrbzeDyy2+0h4w6HQ263+6THb9y4UQ8//LAkKSoqSkuWLNGgQYOC1nnhhReUkZGh4cOHS5JiYmJUWFioHj16SJJqamokKWQfkZGR6tixY4v2cSIREefOH0AMD7cF/cTZRd7WIWtrkbd1yNparZWzUXk6XWPGjFGfPn1UXV2t4uJizZgxQwUFBRoxYoQk6dChQ5o2bZp69uyprKwshYeHa8OGDbr33nv1wgsvqFevXmd1fzZbmGJjo8/qa5wKu71ja2/hvELe1iFra5G3dci6bTMqT3a7PXDl57vcbrccDsdJj+/cubM6d+4s6dsbxt1utxYtWhQoT6tXr5bb7damTZsC9zMNGzZMN9xwg5599lnl5eUF7of6/j4aGhp09OjRFu3jeHw+vzyeI6d8/JkWHm6T3d5RHs9Reb2+1t5Om0fe1iFra5G3dcjaWs15W82oPDmdzpB7impqalRZWRlyD1JL9OvXTyUlJYHHX3zxhZxOZ9CN4OHh4XK5XPryyy8lfftxX9euXUP2sX//fvn9/lPax3c1NZ17b3av13dO7qutIm/rkLW1yNs6ZN22GX1YmJycrPfee08ejycwVlxcLJvNpqSkJOMX3717d+BeJknq1q2b9u3bp/r6+sCY1+vVn//8Z11yySVB+3j77beD/qTe1q1bZbfbg+6hAgAAONOMylNqaqqio6OVmZmp0tJSvfLKK8rNzVVqamrQdzylpaVp7NixgcfvvPOOZsyYoVdffVUffPCB3nzzTd1///0qLS1VZmZmYN6kSZNUXV2t++67T9u3b9e7776r6dOn6+DBg5o8eXJg3tSpU1VVVaXZs2dr586dWrt2rdasWaN77rmH73gCAABnldHHdg6HQ2vXrlV2drYyMzMVHR2tiRMnaubMmUHzfD6fvF5v4HGPHj3U0NCgvLw8VVdXKzY2Vi6XS0VFRRoyZEhgXv/+/bV69Wo9++yzmjt3rnw+ny6//HKtWrVKiYmJgXmXXnqp1qxZo5ycHN19993q3Lmz7r//fv3yl7881RwAAABaJMzPXwgX4PX6VFVV29rbCIiIsCk2NlrV1bV8dm4B8rYOWVuLvK1D1tZqzttqfBEFAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAcoTAACAAePytG/fPk2ZMkUJCQlKSkpSbm6uGhoaTnrcnDlzNG7cOCUkJCgxMVGTJ09WaWlp0Jz8/Hy5XK5j/po3b95J57300kumpwMAAGAkwmSy2+1WWlqa4uPjlZ+fr4qKCuXk5Kiuri6o3BxLY2Oj0tPTFR8fr/r6em3cuFF333231q1bp8GDB0uSJk2apOHDhwcd9+GHH+qpp55ScnJy0HiHDh20du3aoLEePXqYnA4AAIAxo/K0fv161dbWqqCgQDExMZIkr9er+fPnKyMjQ3Fxccc9dunSpUGPk5OTNWbMGG3evDlQnn70ox/pRz/6UchrOhyOkPJks9mUkJBgsn0AAIDTZvSxXUlJiYYNGxYoTpKUkpIin8+nHTt2GL1weHi4OnXqpMbGxuPOqa+v17Zt23TttdcqMjLSaH0AAICzwejKU1lZmW699dagMbvdri5duqisrOykx/v9fnm9XtXU1GjTpk06ePCgHn/88ePO/8Mf/qDDhw/rxhtvDHmurq5OV199tTwej+Lj45Wenq7bbrvN5HSOKSLi3LmHPjzcFvQTZxd5W4esrUXe1iFra7VWzkblyePxyG63h4w7HA653e6THr9x40Y9/PDDkqSoqCgtWbJEgwYNOu78LVu2KC4uTomJiUHjPXv21Jw5c3TFFVeovr5er7/+uh555BHV1NRo6tSpJqcUxGYLU2xs9Ckff7bY7R1bewvnFfK2Dllbi7ytQ9Ztm1F5Ol1jxoxRnz59VF1dreLiYs2YMUMFBQUaMWJEyFyPx6N3331XP//5z2WzBTfLm266KejxyJEj1djYqOXLl+uOO+5Qu3btTml/Pp9fHs+RUzr2bAgPt8lu7yiP56i8Xl9rb6fNI2/rkLW1yNs6ZG2t5rytZlSe7Ha7ampqQsbdbrccDsdJj+/cubM6d+4s6dsbxt1utxYtWnTM8vTGG2+ooaFB//qv/9qivaWkpOiNN97Ql19+qV69erXomGNpajr33uxer++c3FdbRd7WIWtrkbd1yLptM/qw0Ol0htzbVFNTo8rKSjmdTuMX79evnw4ePHjM57Zs2SKn06krrrjCeF0AAICzxejKU3JyslasWBF071NxcbFsNpuSkpKMX3z37t3H/G6mr7/+Wn/84x81bdq0Fq+1detW2e129ezZ03gfzWy2MHXuzD1P5zvytg5ZW4u8rUPWbZtReUpNTVVRUZEyMzOVkZGhiooK5ebmKjU1Neg7ntLS0lReXq5t27ZJkt555x29+uqrGjlypLp27Sq3260tW7aotLRUixcvDnmdrVu3yufzHfcjuwkTJujmm2+W0+lUXV2dXn/9db355pvKyso65fudJCksLEzh4WGnfPzZwp/asBZ5W4esrUXe1iHrts2oPDkcDq1du1bZ2dnKzMxUdHS0Jk6cqJkzZwbN8/l88nq9gcc9evRQQ0OD8vLyVF1drdjYWLlcLhUVFWnIkCEhr/P6669r4MCBx72K1LNnTz3//PP65z//qbCwMPXu3VuLFi3S+PHjTU4HAADAWJjf7/e39iYAAAB+KLiuCAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyBAAAYIDyZLE//OEPuuWWW9S/f3+NGDFCy5YtC/pLlL/v008/Vd++fTVo0KCQ5xoaGrRw4UIlJSUpISFBU6ZMUVlZ2dnc/g9KS7Our6/X0qVLNXr0aPXv318jR47UwoULg+b4/X6tWrVKI0eO1MCBA3X77bfrk08+sehMfhhakrfX61VhYaGuu+46XXnllRozZowWLlyo2traoHm8t//PwYMHNW/ePN1000264oordOONNx5z3ssvv6xrr71WAwYM0Pjx4/WHP/whZE5NTY2ysrI0ZMgQDRo0SPfff7++/vrrkHkfffSRbr/9dg0cOFCjRo3SqlWrdL78NahnKu89e/Zo7ty5Gjt2rK688kqNGzdOeXl5OnLkSMha52veZ/K9/V333XefXC6X1qxZE/Lcmcqa8mShTz75RPfdd5969eql5cuXKz09XWvWrNFTTz11zPl+v1/Z2dnq3LnzMZ9fsGCBXn75Zc2cOVP5+flqaGhQenq6ampqzuZp/CC0NGufz6f77rtPv/vd7zRt2jQ999xzmjFjhiIjI4PmFRYWatmyZUpPT9fKlSvVpUsX/fKXv9RXX31l5Wmds1qa9/Lly/X0009rwoQJWrlypdLT07V+/XrNmzcvaB7v7f/zl7/8Re+++64uvfRS9erV65hzfve73+mRRx5RSkqKCgsLlZCQoGnTpoUU/BkzZmjHjh167LHH9NRTT2n//v2666671NTUFJhz8OBBTZ06VV26dNHKlSuVlpamZcuW6bnnnjubp3nOOFN5//73v9fBgwd15513atWqVUpLS9OGDRt0zz33BK11Pud9Jt/bzd59913993//9zGfO6NZ+2GZX/7yl/5bbrklaGzNmjX+fv36+SsrK0Pmv/zyy/6xY8f68/Ly/AkJCUHP/f3vf/f37dvXv379+sBYdXW1PyEhwb9q1aqzcwI/IC3NesOGDf6rrrrKX1FRcdy16urq/D/5yU/8eXl5gbH6+nr/qFGj/I8++ugZ3/sPUUvzvvbaa/0PPPBA0LylS5f6+/fv729sbPT7/by3v8/r9Qb++YEHHvDfcMMNIXPGjRvnnzVrVtDY7bff7r/zzjsDjz/66CN/7969/f/1X/8VGNu3b5/f5XL5f/e73wXGHnnkEf+oUaP89fX1gbG8vDz/4MGDg8baqjOV96FDh0KOe+211/y9e/f2/8///E9g7HzO+0xl3ay+vt4/duxY/8aNG/29e/f2r169Ouj5M5k1V54s9Kc//UlJSUlBY9dcc40aGxtVWloaNO7xeJSXl6e5c+eqXbt2IWuVlpbK5/PpuuuuC4zFxMQoKSlJJSUlZ+cEfkBamvXLL7+s6667ThdffPFx1/roo490+PBhpaSkBMYiIyM1duxYsv7/Wpp3U1OTLrjggqB5nTp1Crpszns7mM124v9Mf/XVVzpw4EDQ+1OSrr/+eu3cuVMNDQ2SpJKSEtnt9qB/T06nU3379g3KtaSkRGPGjAm6+nr99dfL4/Ho448/PhOndE47U3kf6xODK664QpKCPio9n/M+U1k3W7Nmjex2uyZMmHDM9c5k1pQnC9XX14d8HNT8eN++fUHjTz/9tPr166dRo0Ydc62ysjJdeOGFcjgcQeO9evU6b+8N+a6WZN3Y2KjPPvtM3bp103/8x38oISFBgwYN0q9+9StVVlYGjmvO0+l0Bq3Xq1cvlZeXq66u7myeyg9CS9/bkyZN0muvvaadO3eqtrZWe/bsUVFRkVJTUxURESGJ97ap5kwuu+yyoPFevXqpsbEx8NFyWVmZLrvsMoWFhQXNczqdgTWOHDmiv//97yHvdafTqbCwMPJXy/M+lt27d0v6v/+WkPeJmWRdXl6uVatW6eGHHw55j0tnPusIo9k4LZdeeqn27NkTNNb8ua3b7Q6M/elPf9LGjRv1n//5n8ddy+PxqFOnTiHjdrs9aK3zVUuy/uabb9TY2KjCwkIlJiaqoKBAVVVVWrRokaZPn67169dL+jbryMhItW/fPmg9u90uv98vt9utDh06nP2TOoe19L2dkZGhhoYGTZkyJXC1afz48crKygrM4b1tpjkTu90eNN78uPn54+XqcDj06aefSlLgnrLvrxUZGamOHTuSv1qe9/dVVVUpPz9fY8aMUXx8vCTyPhmTrH/9619r7NixSkhIOOZaZzprrjxZ6Gc/+5lKSkq0du1affPNN9q1a5eefvpphYeHB+b4/X7Nnz9fP/vZz457Ax1OriVZ+3w+SVJ0dLQKCgp0zTXXaPz48Vq4cKE+/vhj7dy5s7W2/4PTkrwl6Te/+Y3WrVunuXPn6je/+Y0effRRlZSUKDs7u5V2Dpx9jY2NmjVrliTpsccea93NtEGlpaUqLS3V7NmzLXtNypOFJkyYoLS0NOXm5mro0KFKT09XamqqHA5H4J6brVu3qqysTL/4xS/k8Xjk8XhUX18vSUH/bLfbdfjw4ZDX8Hg8IR93nI9akrXdbldYWJh+8pOfBH3kNGTIEIWHh+uLL74IzGtoaAhk38zj8SgsLIy81bK8q6urtXDhQt1///1KS0tTYmKifvazn+mhhx7Siy++qP3790vivW2qOZPv/0lEj8cT9PzxcnW73YE5zVemvr9WQ0ODjh49Sv5qed7N/H6/srKytGfPHhUWFgbdX0neJ9bSrBcsWKA77rhDHTt2DPy+KX17O0HzP5/prClPFrLZbMrKytL777+vzZs367333tNtt92mqqoqXXnllZK+/YzX7XZr9OjRSkxMVGJiogoLC3XkyBElJiYqPz9f0ref0/7zn/8MudRYVlYW8pnu+aglWXfs2FGXXHLJcddoLkvNeTb/5t6srKxM3bp1O+8/spNalvdXX32lhoYG9e3bN+jY5ptov/zyS0m8t001Z/L9ezbKysrUrl079ejRIzBv//79Id9ps3///sAaUVFR6tq1a8hazceRf8vzbrZw4UL9/ve/1zPPPKM+ffoEPUfeJ9bSrPfv368VK1YEfs9MTEyUJC1dulSJiYmqr68/41lTnlpBp06d1KdPH9ntdhUVFal79+76l3/5F0nSLbfconXr1gX9uuWWW9S+fXutW7dOt99+u6Rv/ySTzWbTm2++GVjX7XartLRUycnJrXJe56ITZS1Jo0aN0kcffRR0Ven999+X1+tVv379JEk/+clPdMEFF+j3v/99YE5jY6PefPNNsv6eE+XdrVs3SdL//u//Bh3TfL9N9+7dJfHeNtWjRw/Fx8eruLg4aHzr1q0aNmxY4KpqcnKy3G530MfR+/fv12effRaUa3Jyst5++201NjYGrWW324/5Zb3nm5bmLUmrVq3S888/r5ycHA0bNuyY65H38bU06+//nrlu3TpJUmpqqtatWxf4E+tnMmtuGLfQnj179Mc//lF9+/ZVXV2dtm/frs2bN6uwsDBwb0j37t0Dv4k0++Mf/6jw8HANHTo0MPajH/1IEydOVG5urmw2m+Li4rRy5Up16tRJqamplp7XuaglWUvS1KlTtXnzZt1333264447VFVVpby8PF111VW6+uqrJUnt27dXRkaG8vPz1blzZ/Xu3VsvvfSSvvnmG02dOrW1TvGc0pK8L7roIv30pz/V0qVL5fV6dcUVV+iLL75Qfn6+/uVf/iVwjx/v7WBHjx7Vu+++K0n629/+psOHDwd+MxkyZIg6d+6s6dOna86cOerZs6eGDh2qrVu3as+ePfrNb34TWGfQoEG65pprlJWVpQceeEDt27fXkiVL5HK5NG7cuMC8qVOn6vXXX9fs2bP1b//2b9q7d6/WrFmjmTNnhvyJyrboTOX9+uuvKy8vT+PHj1f37t2DvtSxZ8+ega8yOJ/zPlNZf/f3xu9qPqbZGc3a6FuhcFo+++wz/6RJk/wJCQn+hIQEf1pamv+jjz466XHLli0L+ZJMv//bLwTLycnxDxs2zD9w4EB/enq6/4svvjgbW//BMcn6s88+8//85z/3DxgwwD9kyBD/3Llz/W63O2iOz+fzr1ixwp+cnOzv37+/f9KkSS36d3e+aGneNTU1/pycHP9Pf/pT/4ABA/yjR4/2Z2dn+7/55pugeby3/89XX33l79279zF/vf/++4F5GzZs8I8dO9bfr18//4033ujfvn17yFoej8c/d+5c/+DBg/0JCQn+adOm+f/xj3+EzNu9e7d/0qRJ/v79+/uTk5P9K1eu9Pt8vrN6nueKM5X3Aw88cNx1XnnllaC552veZ/K9/X3H+pJMv//MZR3m958Hf4EOAADAGcI9TwAAAAYoTwAAAAYoTwAAAAYoTwAAAAYoTwAAAAYoTwAAAAYoTwAAAAYoTwAAAAYoTwAAAAYoTwAAAAYoTwAAAAb+Hwq9HdLF8Yq6AAAAAElFTkSuQmCC","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# plot tensorflow training preocess of MSE loss\n","# import matplotlib.pyplot as plt\n","# plt.plot(history.history['loss'])\n","# plt.title('model loss')\n","# plt.ylabel('loss')\n","# plt.xlabel('epoch')\n","# plt.show()\n","# plot by using seaborn\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()\n","plt.plot(history.history['loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.show()\n","\n","#plot the minimun point value in the fig\n","min_point = np.min(history.history['loss'])\n","min_point_index = np.argmin(history.history['loss'])\n","# print(min_point)\n","# print(min_point_index)\n","plt.plot(min_point_index, min_point, 'ro')\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"match","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
