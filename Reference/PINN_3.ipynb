{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm, trange\n",
    "from math import exp, sqrt, log\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import i0, i1, iv\n",
    "from numpy import random\n",
    "from torch.nn.functional import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BASICnet(nn.Module):\n",
    "    def __init__(self, dim, width):\n",
    "        super(BASICnet, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.width = width\n",
    "\n",
    "        self.fc1 = nn.Linear(self.dim, self.width)\n",
    "        self.fc2 = nn.Linear(self.width, self.width)\n",
    "        self.fc3 = nn.Linear(self.width, self.width)\n",
    "        self.fc4 = nn.Linear(self.width, self.width)\n",
    "\n",
    "        self.output = nn.Linear(self.width, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # s = nn.ConstantPad2d(x, (0, self.dim - self.dim))\n",
    "        y = self.fc1(x)\n",
    "        y = torch.tanh(y)\n",
    "        y = self.fc2(y)\n",
    "        y = torch.tanh(y)\n",
    "        y = self.fc3(y)\n",
    "        y = torch.tanh(y)\n",
    "        y = self.fc4(y)\n",
    "        y = torch.tanh(y)\n",
    "        \n",
    "        output = self.output(y)\n",
    "        return output\n",
    "\n",
    "    def assign_value(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                nn.init.constant_(m.bias.data, 0.1)\n",
    "\n",
    "class TESTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TESTNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauculate equation (Righthand side of the equation, RHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model from the dataset and using montecarlo method to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def calculate_fx(X):\n",
    "    # Check if there are boundary cases with 1 and -1 in each row\n",
    "    has_boundary = torch.any((X == 1) | (X == -1), dim=-1)\n",
    "\n",
    "    # Create an initial fx tensor filled with the regular values\n",
    "    regular_fx = -160 * (torch.tensor(4 * np.pi, dtype=torch.float32).pow(2)) * torch.prod(torch.sin(4 * np.pi * X), dim=-1)\n",
    "    \n",
    "    # Where there are boundary cases, set fx to zero\n",
    "    fx = torch.where(has_boundary, torch.tensor(0.0, dtype=torch.float32, device=X.device), regular_fx)\n",
    "\n",
    "    return fx\n",
    "\n",
    "\n",
    "\n",
    "def data_generator_monte_carlo(Numberofgenpoints, dim, prob_special = 0.1):\n",
    "    source = torch.randn(size = (Numberofgenpoints, dim), requires_grad=True) # 生成一个大矩阵\n",
    "    source = normalize(source, p=2)\n",
    "    radius = torch.rand(size = (Numberofgenpoints, 1))\n",
    "    radius = torch.pow(torch.rand(size = (Numberofgenpoints, 1)), 1/dim)\n",
    "    source = source * radius\n",
    "\n",
    "    # # 随即确认替换的行\n",
    "    num_replace_incol = torch.randint(1, Numberofgenpoints, size=(1,)).item()\n",
    "\n",
    "    for _ in range(num_replace_incol):\n",
    "        if random.random() < prob_special:\n",
    "            special_value = random.choice([1, -1])\n",
    "            row_index = torch.randint(0, Numberofgenpoints, size=(1,)).item()\n",
    "            source[row_index] = torch.full((dim, ), special_value)\n",
    "        else:\n",
    "            row_index = torch.randint(0, Numberofgenpoints, size=(1,)).item()\n",
    "            col_index = torch.randint(0, dim, size=(1,)).item()\n",
    "            replace_value = torch.randint(0, 2, size=(1,)).item() * 2 - 1\n",
    "            source[row_index, col_index] = replace_value\n",
    "\n",
    "    max_value = torch.max(source)\n",
    "    min_value = torch.min(source)\n",
    "\n",
    "    target = calculate_fx(source)\n",
    "    # set target as the requres_graade true\n",
    "\n",
    "    if max_value > 1 or min_value < -1:\n",
    "        raise ValueError\n",
    "    \n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_588706/4016173177.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_source = torch.tensor(test_source).to(device)\n",
      "/tmp/ipykernel_588706/4016173177.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_target = torch.tensor(test_target).to(device)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "test_gen = 10000\n",
    "test_dim = 10\n",
    "\n",
    "test_source, test_target = data_generator_monte_carlo(test_gen, test_dim)\n",
    "test_source = torch.tensor(test_source).to(device)\n",
    "test_target = torch.tensor(test_target).to(device)\n",
    "train_tensor = TensorDataset(test_source, test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义边界点的数量\n",
    "num_boundary_points = 10000  # 根据需要选择数量\n",
    "\n",
    "# 生成均匀分布的边界点\n",
    "boundary_points = np.random.uniform(-1, 1, size=(num_boundary_points, 10))\n",
    "\n",
    "# 将边界点限制在边界上\n",
    "boundary_points = np.where(boundary_points < -0.3, -1, boundary_points)\n",
    "boundary_points = np.where(boundary_points > 0.3, 1, boundary_points)\n",
    "\n",
    "# 创建一个包含边界点的数据集\n",
    "boundary_points = torch.tensor(boundary_points, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BASICnet(\n",
       "  (fc1): Linear(in_features=10, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc4): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (output): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BASICnet(10, 100)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:00<22:45,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 99977.4774234375 Save MSE Model: 22.5225765625\n",
      "Epoch: 0 MSE: 22.5225765625 MSE 1: 22.5225296875 MSE 2: 22.5225765625 MSE 3: 3.062847245018929e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 107/10000 [00:19<25:35,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 3.7898703124999997 Save MSE Model: 18.73270625\n",
      "Epoch: 105 MSE: 18.73270625 MSE 1: 22.5634625 MSE 2: 18.621153125 MSE 3: 0.111553857421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 138/10000 [00:24<26:31,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 3.196279687499999 Save MSE Model: 15.5364265625\n",
      "Epoch: 136 MSE: 15.5364265625 MSE 1: 22.5788015625 MSE 2: 15.3658546875 MSE 3: 0.1705721923828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 162/10000 [00:29<26:39,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 2.67931171875 Save MSE Model: 12.85711484375\n",
      "Epoch: 160 MSE: 12.85711484375 MSE 1: 22.5885453125 MSE 2: 12.610809375 MSE 3: 0.2463053955078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 183/10000 [00:33<26:57,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 2.17951796875 Save MSE Model: 10.677596875\n",
      "Epoch: 181 MSE: 10.677596875 MSE 1: 22.5966734375 MSE 2: 10.370725 MSE 3: 0.306872265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 205/10000 [00:36<25:26,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 1.7977531250000016 Save MSE Model: 8.87984375\n",
      "Epoch: 204 MSE: 8.87984375 MSE 1: 22.603728125 MSE 2: 8.52629140625 MSE 3: 0.3535520751953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 228/10000 [00:41<30:04,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 1.4937460937499996 Save MSE Model: 7.38609765625\n",
      "Epoch: 226 MSE: 7.38609765625 MSE 1: 22.608503125 MSE 2: 7.01028125 MSE 3: 0.3758163818359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 247/10000 [00:44<25:45,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 1.2727558593749997 Save MSE Model: 6.113341796875\n",
      "Epoch: 245 MSE: 6.113341796875 MSE 1: 22.61153125 MSE 2: 5.71823203125 MSE 3: 0.3951095947265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 270/10000 [00:49<27:16,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 1.050172265625 Save MSE Model: 5.06316953125\n",
      "Epoch: 268 MSE: 5.06316953125 MSE 1: 22.61401875 MSE 2: 4.683026171875 MSE 3: 0.380143359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 303/10000 [00:54<24:45,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.8509906249999997 Save MSE Model: 4.21217890625\n",
      "Epoch: 302 MSE: 4.21217890625 MSE 1: 22.61554375 MSE 2: 3.87653203125 MSE 3: 0.3356469970703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 355/10000 [01:04<25:12,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.7174078125000003 Save MSE Model: 3.49477109375\n",
      "Epoch: 354 MSE: 3.49477109375 MSE 1: 22.616071875 MSE 2: 3.1979537109375 MSE 3: 0.296817578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 420/10000 [01:15<27:48,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.5851013671874998 Save MSE Model: 2.9096697265625\n",
      "Epoch: 418 MSE: 2.9096697265625 MSE 1: 22.6160265625 MSE 2: 2.6379916015625 MSE 3: 0.271678076171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 491/10000 [01:27<25:41,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.4931158203125001 Save MSE Model: 2.41655390625\n",
      "Epoch: 490 MSE: 2.41655390625 MSE 1: 22.615403125 MSE 2: 2.161743359375 MSE 3: 0.2548104736328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 581/10000 [01:43<26:08,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.402801953125 Save MSE Model: 2.013751953125\n",
      "Epoch: 579 MSE: 2.013751953125 MSE 1: 22.614225 MSE 2: 1.7734599609375 MSE 3: 0.240292041015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 673/10000 [01:59<24:49,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.33838535156249994 Save MSE Model: 1.6753666015625\n",
      "Epoch: 671 MSE: 1.6753666015625 MSE 1: 22.612903125 MSE 2: 1.450770703125 MSE 3: 0.224595849609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 779/10000 [02:17<22:48,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.27941376953124997 Save MSE Model: 1.39595283203125\n",
      "Epoch: 778 MSE: 1.39595283203125 MSE 1: 22.611409375 MSE 2: 1.183913671875 MSE 3: 0.2120391845703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 889/10000 [02:38<29:58,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.2339605468749999 Save MSE Model: 1.16199228515625\n",
      "Epoch: 887 MSE: 1.16199228515625 MSE 1: 22.6097875 MSE 2: 0.9603978515625 MSE 3: 0.20159439697265624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1001/10000 [02:58<25:32,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.1946305664062501 Save MSE Model: 0.96736171875\n",
      "Epoch: 999 MSE: 0.96736171875 MSE 1: 22.60840625 MSE 2: 0.77617841796875 MSE 3: 0.1911832763671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 1132/10000 [03:20<22:20,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.16136835937499994 Save MSE Model: 0.805993359375\n",
      "Epoch: 1131 MSE: 0.805993359375 MSE 1: 22.6072234375 MSE 2: 0.625963232421875 MSE 3: 0.18003013916015626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1264/10000 [03:43<23:36,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.1351889160156251 Save MSE Model: 0.670804443359375\n",
      "Epoch: 1262 MSE: 0.670804443359375 MSE 1: 22.6058140625 MSE 2: 0.503984814453125 MSE 3: 0.16681964111328124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1415/10000 [04:09<23:44,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.112168017578125 Save MSE Model: 0.55863642578125\n",
      "Epoch: 1413 MSE: 0.55863642578125 MSE 1: 22.6043515625 MSE 2: 0.4087462646484375 MSE 3: 0.14989017333984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1607/10000 [04:41<22:42,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.09415361328124994 Save MSE Model: 0.4644828125\n",
      "Epoch: 1605 MSE: 0.4644828125 MSE 1: 22.60265625 MSE 2: 0.33277080078125 MSE 3: 0.1317120361328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1829/10000 [05:18<19:29,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.07748659667968749 Save MSE Model: 0.3869962158203125\n",
      "Epoch: 1828 MSE: 0.3869962158203125 MSE 1: 22.6011484375 MSE 2: 0.271539013671875 MSE 3: 0.1154572021484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2119/10000 [06:09<20:22,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.06456477050781251 Save MSE Model: 0.3224314453125\n",
      "Epoch: 2117 MSE: 0.3224314453125 MSE 1: 22.599846875 MSE 2: 0.221410400390625 MSE 3: 0.10102103881835937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2494/10000 [07:15<19:23,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.05396667480468753 Save MSE Model: 0.2684647705078125\n",
      "Epoch: 2492 MSE: 0.2684647705078125 MSE 1: 22.5982 MSE 2: 0.1811874755859375 MSE 3: 0.087277294921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2945/10000 [08:33<18:49,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.04485944824218749 Save MSE Model: 0.223605322265625\n",
      "Epoch: 2943 MSE: 0.223605322265625 MSE 1: 22.5965265625 MSE 2: 0.14854295654296876 MSE 3: 0.07506236572265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3514/10000 [10:12<18:58,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.03731833496093748 Save MSE Model: 0.1862869873046875\n",
      "Epoch: 3512 MSE: 0.1862869873046875 MSE 1: 22.59533125 MSE 2: 0.1210887939453125 MSE 3: 0.06519819946289063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4174/10000 [12:06<14:23,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve: 0.03108156738281251 Save MSE Model: 0.155205419921875\n",
      "Epoch: 4173 MSE: 0.155205419921875 MSE 1: 22.5941421875 MSE 2: 0.09815601806640625 MSE 3: 0.057049407958984374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4607/10000 [13:20<15:37,  5.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X24sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m l3 \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m X_bo\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X24sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m l \u001b[39m=\u001b[39m l2 \u001b[39m+\u001b[39m l3\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X24sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m l\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X24sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m mse \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m l\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X24sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m mse_1 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m l1\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/pntorch/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pntorch/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    155\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    156\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_loss = 100000\n",
    "dim = 10\n",
    "LR = 1e-3\n",
    "BATCHSIZE = 10000\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = StepLR(optimizer, step_size=1000, gamma=0.8)\n",
    "\n",
    "training_size = int(0.8 * len(train_tensor))\n",
    "validation_size = len(train_tensor) - training_size\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(train_tensor, [training_size, validation_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=BATCHSIZE, shuffle=False)\n",
    "\n",
    "boundary_loader = DataLoader(dataset=boundary_points, batch_size=BATCHSIZE, shuffle=True)\n",
    "total_iterations = 10000\n",
    "loss = nn.MSELoss(reduction='sum')\n",
    "loss_all, loss_1, loss_2, loss_3, loss_4 = [], [], [], [], []\n",
    "val_losses = []\n",
    "for epoch in trange(total_iterations):\n",
    "    mse, mse_1, mse_2, mse_3 = 0, 0, 0, 0\n",
    "    val_loss = 0\n",
    "    for X, psi_true in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X.requires_grad = True\n",
    "        psi_pred = model(X).squeeze()\n",
    "        l1 = loss(psi_pred, psi_true)\n",
    "        \n",
    "        d_psi = torch.autograd.grad(psi_pred, X, torch.ones_like(psi_pred), create_graph=True)[0]\n",
    "        d_psi_sum = torch.sum(d_psi, dim=1);\n",
    "        d_psi_2 = torch.autograd.grad(d_psi_sum, X, torch.ones_like(d_psi_sum), create_graph=True)[0]\n",
    "        d_psi_2_sum = torch.sum(d_psi_2, dim=1);\n",
    "        l2 = loss(d_psi_2_sum, psi_true)\n",
    "        \n",
    "        for X_bo in boundary_loader:\n",
    "            X_bo.requires_grad = True\n",
    "            X_bo = X_bo.to(device)\n",
    "            psi_pred_bo = model(X_bo).squeeze()\n",
    "            d_psi_bo = torch.autograd.grad(psi_pred_bo, X_bo, torch.ones_like(psi_pred_bo), create_graph=True)[0]\n",
    "            d_psi_bo_sum = torch.sum(d_psi_bo, dim=1);\n",
    "            d_psi_bo2 = torch.autograd.grad(d_psi_bo_sum, X_bo, torch.ones_like(d_psi_bo_sum), create_graph=True)[0]\n",
    "            d_psi_bo2_sum = torch.sum(d_psi_bo2, dim=1);\n",
    "            bc = torch.zeros_like(d_psi_bo2_sum)\n",
    "            l3 = loss(d_psi_bo2_sum, bc)\n",
    "\n",
    "        l1 /= X.shape[0]\n",
    "        l2 /= X.shape[0]\n",
    "        l3 /= X_bo.shape[0]\n",
    "        \n",
    "        l = l2 + l3\n",
    "        \n",
    "        l.backward()\n",
    "        mse += l.item()\n",
    "        mse_1 += l1.item()\n",
    "        mse_2 += l2.item()\n",
    "        mse_3 += l3.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    mse /= BATCHSIZE\n",
    "    mse_1 /= BATCHSIZE\n",
    "    mse_2 /= BATCHSIZE\n",
    "    mse_3 /= BATCHSIZE\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "    loss_all.append(mse)\n",
    "    loss_1.append(mse_1)\n",
    "    loss_2.append(mse_2)\n",
    "    loss_3.append(mse_3)\n",
    "    \n",
    "    if min_loss > mse*1.2:\n",
    "        improvement = min_loss - mse\n",
    "        min_loss = mse\n",
    "        torch.save(model.state_dict(), 'model.pth')\n",
    "        print('Improve: ' + str(improvement) + ' Save MSE Model: ' + str(mse))\n",
    "\n",
    "    # for X_val, psi_true_val in validation_loader:\n",
    "    #         X_val = X_val.to(device)\n",
    "    #         X_val.requires_grad = True\n",
    "    #         psi_true_val = psi_true_val.to(device)\n",
    "    #         psi_pred_val = model(X_val).squeeze()\n",
    "    \n",
    "    #         # 计算二阶微分\n",
    "    #         d_psi_val = torch.autograd.grad(psi_pred_val, X_val, torch.ones_like(psi_pred_val), create_graph=True)[0]\n",
    "    #         d_psi_2_val = torch.autograd.grad(d_psi_val, X_val, torch.ones_like(d_psi_val), create_graph=True)[0]\n",
    "    #         d_psi_2_sum_val = torch.sum(d_psi_2_val, dim=1)\n",
    "    #         # 计算自定义损失\n",
    "    #         val_loss += loss(d_psi_2_sum_val, psi_true_val)\n",
    "\n",
    "    # val_loss /= len(validation_loader.dataset)  # 计算验证损失的平均值\n",
    "    # val_losses.append(val_loss)\n",
    "    # print('Validation Loss: ' + str(val_loss))\n",
    "\n",
    "\n",
    "    # if epoch%10 == 0:\n",
    "        print('Epoch: ' + str(epoch) + ' MSE: ' + str(mse) + \n",
    "              ' MSE 1: ' + str(mse_1) + ' MSE 2: ' + str(mse_2) + \n",
    "              ' MSE 3: ' + str(mse_3))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.1844]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0489, -0.4484, -0.4159, -0.0293, -0.2300, -0.5179, -0.0168,  0.1121,\n",
      "          0.2104, -0.1248]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 10])\n",
      "Right Hand Eqution:  tensor([563.5513], device='cuda:0', grad_fn=<SWhereBackward0>)\n",
      "Left Hand Eqution:  tensor([499.2750], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "BO RHL :  tensor([0.], device='cuda:0', grad_fn=<SWhereBackward0>)\n",
      "BO LHL:  tensor([-31.9384], device='cuda:0', grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "target = X_val[2:3]\n",
    "target2 = X_bo[2:3]\n",
    "\n",
    "RHL = calculate_fx(target)\n",
    "VAL = model(target)\n",
    "\n",
    "BO = model(target2)\n",
    "RHL2 = calculate_fx(target2)\n",
    "\n",
    "\n",
    "grad = torch.autograd.grad(VAL, target, create_graph=True)\n",
    "grad_sum = torch.sum(grad[0], dim=1)\n",
    "grad_2 = torch.autograd.grad(grad_sum, target, create_graph=True)\n",
    "grad_2_sum = torch.sum(grad_2[0], dim=1)\n",
    "\n",
    "grad_bo = torch.autograd.grad(BO, target2, create_graph=True)\n",
    "grad_sum_bo = torch.sum(grad_bo[0], dim=1)\n",
    "grad_2_bo = torch.autograd.grad(grad_sum_bo, target2, create_graph=True)\n",
    "grad_2_sum_bo = torch.sum(grad_2_bo[0], dim=1)\n",
    "print(VAL)\n",
    "print(X_val[0:1])\n",
    "print(X_val[0:1].shape)\n",
    "print('Right Hand Eqution: ',RHL)\n",
    "print('Left Hand Eqution: ',grad_2_sum)\n",
    "\n",
    "print('BO RHL : ', RHL2)\n",
    "print('BO LHL: ',grad_2_sum_bo)\n",
    "# print(VAL)\n",
    "# print(VAL.shape)\n",
    "\n",
    "# print(grad_sum)\n",
    "# print(grad_2_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存整个模型\n",
    "# torch.save(model, 'model.pth')\n",
    "torch.load('model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pntorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
