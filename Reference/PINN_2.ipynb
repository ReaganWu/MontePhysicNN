{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm, trange\n",
    "from math import exp, sqrt, log\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import i0, i1, iv\n",
    "from numpy import random\n",
    "from torch.nn.functional import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The setup of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BASICnet(nn.Module):\n",
    "    def __init__(self, dim, width):\n",
    "        super(BASICnet, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.width = width\n",
    "\n",
    "        self.fc1 = nn.Linear(self.dim, self.width)\n",
    "        self.fc2 = nn.Linear(self.width, self.width)\n",
    "        self.fc3 = nn.Linear(self.width, self.width)\n",
    "        self.fc4 = nn.Linear(self.width, self.width)\n",
    "\n",
    "        self.output = nn.Linear(self.width, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # s = nn.ConstantPad2d(x, (0, self.dim - self.dim))\n",
    "        y = self.fc1(x)\n",
    "        y = torch.tanh(y)\n",
    "        y = self.fc2(y)\n",
    "        y = torch.tanh(y)\n",
    "        y = self.fc3(y)\n",
    "        y = torch.tanh(y)\n",
    "        y = self.fc4(y)\n",
    "        y = torch.tanh(y)\n",
    "        \n",
    "        output = self.output(y)\n",
    "        return output\n",
    "\n",
    "    def assign_value(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                nn.init.constant_(m.bias.data, 0.1)\n",
    "\n",
    "class TESTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TESTNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauculate equation (Righthand side of the equation, RHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model from the dataset and using montecarlo method to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def calculate_fx(X):\n",
    "    # Check if there are boundary cases with 1 and -1 in each row\n",
    "    has_boundary = torch.any((X == 1) | (X == -1), dim=-1)\n",
    "\n",
    "    # Create an initial fx tensor filled with the regular values\n",
    "    regular_fx = -160 * (torch.tensor(4 * np.pi, dtype=torch.float32).pow(2)) * torch.prod(torch.sin(4 * np.pi * X), dim=-1)\n",
    "    \n",
    "    # Where there are boundary cases, set fx to zero\n",
    "    fx = torch.where(has_boundary, torch.tensor(0.0, dtype=torch.float32, device=X.device), regular_fx)\n",
    "\n",
    "    return fx\n",
    "\n",
    "\n",
    "\n",
    "def data_generator_monte_carlo(Numberofgenpoints, dim, prob_special = 0.1):\n",
    "    source = torch.randn(size = (Numberofgenpoints, dim), requires_grad=True) # 生成一个大矩阵\n",
    "    source = normalize(source, p=2)\n",
    "    radius = torch.rand(size = (Numberofgenpoints, 1))\n",
    "    radius = torch.pow(torch.rand(size = (Numberofgenpoints, 1)), 1/dim)\n",
    "    source = source * radius\n",
    "\n",
    "    # 随即确认替换的行\n",
    "    num_replace_incol = torch.randint(1, Numberofgenpoints, size=(1,)).item()\n",
    "\n",
    "    for _ in range(num_replace_incol):\n",
    "        if random.random() < prob_special:\n",
    "            special_value = random.choice([1, -1])\n",
    "            row_index = torch.randint(0, Numberofgenpoints, size=(1,)).item()\n",
    "            source[row_index] = torch.full((dim, ), special_value)\n",
    "        else:\n",
    "            row_index = torch.randint(0, Numberofgenpoints, size=(1,)).item()\n",
    "            col_index = torch.randint(0, dim, size=(1,)).item()\n",
    "            replace_value = torch.randint(0, 2, size=(1,)).item() * 2 - 1\n",
    "            source[row_index, col_index] = replace_value\n",
    "\n",
    "    max_value = torch.max(source)\n",
    "    min_value = torch.min(source)\n",
    "\n",
    "    target = calculate_fx(source)\n",
    "    # set target as the requres_graade true\n",
    "\n",
    "    if max_value > 1 or min_value < -1:\n",
    "        raise ValueError\n",
    "    \n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经生成了包括边界条件的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_loss(input):\n",
    "    return torch.mean(input**2)\n",
    "\n",
    "def mse_loss(input, target):\n",
    "    return torch.nn.MSELoss()(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = 100\n",
    "test_dim = 10\n",
    "\n",
    "test_source, test_target = data_generator_monte_carlo(test_gen, test_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31501\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Dim = 10\n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 1000\n",
    "BATCH_SIZE = 1000\n",
    "loss_list = np.zeros(NUM_EPOCHS)\n",
    "test_loss = np.zeros(NUM_EPOCHS)\n",
    "max_value_loss = np.zeros(NUM_EPOCHS)\n",
    "min_value_loss = np.zeros(NUM_EPOCHS)\n",
    "\n",
    "net = BASICnet(dim=Dim, width=100)\n",
    "\n",
    "# Optimizer and scheduler define there\n",
    "Optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "Scheduler = StepLR(Optimizer, step_size=1000, gamma=0.8)\n",
    "\n",
    "# orignal print\n",
    "print(sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
    "# summary(net, (Dim,), device=\"cuda:0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "x = test_source\n",
    "x = x.to(\"cuda:0\")\n",
    "u = net(x).to(\"cuda:0\")\n",
    "u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n",
    "u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]\n",
    "# Calculate the PDE loss\n",
    "cx = calculate_fx(x)\n",
    "# pde_residual = u_xx - cx\n",
    "pde_loss = torch.mean((u_xx.mean(dim=1) - cx)**2)\n",
    "print(cx.shape)\n",
    "print(u_xx.shape)\n",
    "print(pde_loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pde_loss(u_net, x):\n",
    "#     u = u_net(x)\n",
    "#     u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]\n",
    "#     pde = u_x - calculate_fx(x)  # Define the PDE equation based on your problem\n",
    "#     return torch.mean(pde**2)\n",
    "\n",
    "def pde_loss(net, x):\n",
    "    u = net(x)\n",
    "    u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]\n",
    "    # Calculate the PDE loss\n",
    "    cx = calculate_fx(x)\n",
    "    # pde_residual = u_xx - cx\n",
    "    pde_loss = torch.mean((u_xx.mean(dim=1) - cx)**2)\n",
    "    return pde_loss\n",
    "\n",
    "\n",
    "def boundary_loss(u_net, x):\n",
    "    u = u_net(x)\n",
    "    boundary_points = torch.norm(x, dim=1) >= 1.0  # 找到边界点\n",
    "    boundary_values = u[boundary_points]  # 边界点的模型输出\n",
    "    \n",
    "    # 构建目标边界条件，都应该为0\n",
    "    target_boundary_values = torch.zeros_like(boundary_values)\n",
    "    \n",
    "    # 计算边界损失\n",
    "    boundary_residual = boundary_values - target_boundary_values\n",
    "    boundary_loss = torch.mean(boundary_residual**2)\n",
    "    return boundary_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reaganwu/miniconda3/envs/pntorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/reaganwu/miniconda3/envs/pntorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "  0%|          | 11/10000 [00:00<01:42, 97.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/10000, Total Loss: 74978.9219, MSE Loss: 74973.5156, PDE Loss: 74971.4062, Boundary Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 113/10000 [00:01<01:55, 85.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100/10000, Total Loss: 295227.7812, MSE Loss: 295221.0000, PDE Loss: 295198.1875, Boundary Loss: 0.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 209/10000 [00:02<01:27, 111.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200/10000, Total Loss: 159383.1562, MSE Loss: 159362.4219, PDE Loss: 159367.1406, Boundary Loss: 0.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 319/10000 [00:03<01:27, 110.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 300/10000, Total Loss: 99021.9062, MSE Loss: 99010.2656, PDE Loss: 99011.8984, Boundary Loss: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 418/10000 [00:04<01:21, 117.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 400/10000, Total Loss: 94079.4922, MSE Loss: 94066.6484, PDE Loss: 94070.0312, Boundary Loss: 0.0542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 524/10000 [00:04<01:15, 125.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500/10000, Total Loss: 198174.3125, MSE Loss: 198121.3438, PDE Loss: 198154.4531, Boundary Loss: 0.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 614/10000 [00:05<01:36, 97.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 600/10000, Total Loss: 313235.4688, MSE Loss: 313216.8125, PDE Loss: 313204.1250, Boundary Loss: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 723/10000 [00:06<01:21, 113.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 700/10000, Total Loss: 311863.4375, MSE Loss: 311831.1250, PDE Loss: 311832.2500, Boundary Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 814/10000 [00:07<01:20, 114.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 800/10000, Total Loss: 368237.3125, MSE Loss: 368209.5938, PDE Loss: 368200.4688, Boundary Loss: 0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 915/10000 [00:08<01:13, 123.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 900/10000, Total Loss: 251274.3438, MSE Loss: 251261.0469, PDE Loss: 251249.1875, Boundary Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1018/10000 [00:09<01:16, 117.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000/10000, Total Loss: 95174.2969, MSE Loss: 95176.6641, PDE Loss: 95164.7578, Boundary Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1117/10000 [00:10<01:07, 130.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1100/10000, Total Loss: 450951.6250, MSE Loss: 450907.5312, PDE Loss: 450906.5000, Boundary Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1222/10000 [00:10<01:11, 122.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1200/10000, Total Loss: 283265.2812, MSE Loss: 283237.5625, PDE Loss: 283236.9688, Boundary Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1311/10000 [00:11<01:19, 109.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1300/10000, Total Loss: 289925.0000, MSE Loss: 289902.2812, PDE Loss: 289895.9688, Boundary Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1419/10000 [00:12<01:13, 116.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1400/10000, Total Loss: 619944.2500, MSE Loss: 619895.6875, PDE Loss: 619882.2500, Boundary Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1518/10000 [00:13<01:11, 119.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1500/10000, Total Loss: 435823.5000, MSE Loss: 435781.7812, PDE Loss: 435779.9062, Boundary Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1617/10000 [00:14<01:08, 121.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1600/10000, Total Loss: 29784.2188, MSE Loss: 29782.4766, PDE Loss: 29781.1914, Boundary Loss: 0.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1716/10000 [00:15<01:11, 116.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1700/10000, Total Loss: 208279.7500, MSE Loss: 208252.1094, PDE Loss: 208258.8906, Boundary Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1819/10000 [00:16<01:08, 119.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1800/10000, Total Loss: 497960.5625, MSE Loss: 497906.4688, PDE Loss: 497910.7500, Boundary Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1916/10000 [00:17<01:14, 108.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1900/10000, Total Loss: 132555.0000, MSE Loss: 132539.0781, PDE Loss: 132541.7344, Boundary Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2013/10000 [00:17<01:07, 118.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000/10000, Total Loss: 148934.3281, MSE Loss: 148919.7969, PDE Loss: 148919.4219, Boundary Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 2126/10000 [00:18<01:04, 121.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2100/10000, Total Loss: 91164.7266, MSE Loss: 91152.9531, PDE Loss: 91155.6016, Boundary Loss: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2213/10000 [00:19<01:06, 116.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2200/10000, Total Loss: 138861.6250, MSE Loss: 138846.3594, PDE Loss: 138847.7344, Boundary Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2319/10000 [00:20<01:11, 107.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2300/10000, Total Loss: 177284.5938, MSE Loss: 177263.5781, PDE Loss: 177266.8750, Boundary Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2416/10000 [00:21<01:17, 97.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2400/10000, Total Loss: 790809.4375, MSE Loss: 790735.7500, PDE Loss: 790730.3750, Boundary Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2514/10000 [00:22<01:04, 116.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2500/10000, Total Loss: 188092.5938, MSE Loss: 188067.6250, PDE Loss: 188073.7812, Boundary Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2612/10000 [00:23<01:03, 115.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2600/10000, Total Loss: 660690.6875, MSE Loss: 660629.3750, PDE Loss: 660624.6250, Boundary Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2716/10000 [00:24<01:10, 103.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2700/10000, Total Loss: 133964.8594, MSE Loss: 133951.0938, PDE Loss: 133951.4688, Boundary Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2820/10000 [00:25<01:05, 109.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2800/10000, Total Loss: 689698.9375, MSE Loss: 689634.3750, PDE Loss: 689630.0000, Boundary Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2863/10000 [00:25<01:04, 110.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# 前向传播\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m out \u001b[39m=\u001b[39m net(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m mse_loss \u001b[39m=\u001b[39m mse_cost_function(out, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# loss based on PDE\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pntorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/reaganwu/Projects/MonteCarlo_Reagan/Reference/PINN_2.ipynb#X33sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/pntorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pntorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/pntorch/lib/python3.8/site-packages/torch/nn/functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   1847\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> 1848\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 定义批次大小和总Epoch数\n",
    "total_iterations = 10000\n",
    "# 定义输入数据的维度\n",
    "dim = 10\n",
    "# 定义数据生成器的数量\n",
    "gen_each_round = 100\n",
    "LR = 1e-3\n",
    "\n",
    "mse_cost_function = torch.nn.MSELoss() # Mean squared error\n",
    "# 初始化网络、优化器和学习率调度器\n",
    "net = TESTNet()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "scheduler = StepLR(Optimizer, step_size=1000, gamma=0.8)\n",
    "\n",
    "for epoch in trange(total_iterations):\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    data, target = data_generator_monte_carlo(gen_each_round, dim, prob_special=0.1)\n",
    "    # data = Variable(torch.from_numpy(data).float(), requires_grad=False).to(device)\n",
    "    # target = Variable(torch.from_numpy(target).float(), requires_grad=False).to(device)\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    \n",
    "    # 前向传播\n",
    "    out = net(data)\n",
    "    mse_loss = mse_cost_function(out, target)\n",
    "\n",
    "    # loss based on PDE\n",
    "    pde_loss_value = pde_loss(net, data)\n",
    "    # loss based on boundary\n",
    "    boundary_loss_value = boundary_loss(net, data)\n",
    "    total_loss = 0.0001*mse_loss + pde_loss_value + boundary_loss_value\n",
    "    # 反向传播和优化\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    # 累积总损失\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "\n",
    "    # # 打印当前Epoch的平均损失\n",
    "    # average_loss = total_loss / gen_each_round\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Iteration {epoch}/{total_iterations}, Total Loss: {total_loss.item():.4f}, MSE Loss: {mse_loss.item():.4f}, PDE Loss: {pde_loss_value.item():.4f}, Boundary Loss: {boundary_loss_value.item():.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfgafg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pntorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
